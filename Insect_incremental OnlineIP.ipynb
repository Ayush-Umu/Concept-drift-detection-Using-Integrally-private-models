{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b06104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from skmultiflow.drift_detection import PageHinkley, ADWIN\n",
    "from skmultiflow.data import DataStream\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , Lambda, Flatten\n",
    "from tensorflow.keras.optimizers import Adam ,RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import  backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import entropy\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396489a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_model(inp, out): #get initial model\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(10, input_dim=inp, kernel_initializer='normal', activation='relu'),\n",
    "        Dense(out, activation='softmax')\n",
    "        ])\n",
    "    #optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819eda27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_model_2(inp, out):\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(10, input_dim=inp, kernel_initializer='normal', activation='relu'),\n",
    "        Dense(20, activation='relu'),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(out, activation='softmax')\n",
    "        ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fbf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DP_get_initial_model(inp, out): #get initial model\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(10, input_dim=inp, kernel_initializer='normal', activation='relu'),\n",
    "        Dense(out, activation='softmax')\n",
    "        ])\n",
    "    #optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d9be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DP_get_initial_model_2(inp, out): #get initial model\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(10, input_dim=inp, kernel_initializer='normal', activation='relu'),\n",
    "        Dense(20, activation='relu'),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(out, activation='softmax')\n",
    "        ])\n",
    "    #optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd1384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_comparison1(node1, node2, epsilon=0.05): #this function is to see if the nodes are atmost epsilon distance apart\n",
    "  for x, y in zip(node1,node2):\n",
    "    #print(x,y)\n",
    "    if isinstance(x, list):\n",
    "        if((np.linalg.norm(np.array(x)-np.array(y))/len(x))<=epsilon):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if(math.sqrt((x-y)*(x-y))<=epsilon):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5837965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_comparison(node1, node2):\n",
    "  for x, y in zip(node1,node2):\n",
    "    #print(x,y)\n",
    "    if isinstance(x, list):\n",
    "        if(sorted(x)==sorted(y)):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        if(x==y):\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c5e3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_comparison(layer1, layer2): #compare same layers in two different DNNs\n",
    "  for node1 in layer1:\n",
    "    present=False\n",
    "    for node2 in layer2:\n",
    "      if (node_comparison1(node1, node2)):\n",
    "        present=True\n",
    "    if present==False:\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92700b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_models(Model_weights1, Model_weights2): # compare two deep neural networks based on their weights\n",
    "  for i in range(0,len(Model_weights1), 2):\n",
    "    layer1=[]\n",
    "    layer2=[]\n",
    "    for j in range(len(Model_weights1[i+1].T)):\n",
    "      Node1=[]\n",
    "      Node2=[]\n",
    "      Node1.append(list(Model_weights1[i].T[j]))\n",
    "      Node1.append(Model_weights1[i+1][j])\n",
    "      if (i+2<len(Model_weights1)):\n",
    "        Node1.append(list(Model_weights1[i+2][j]))\n",
    "      Node2.append(list(Model_weights2[i].T[j]))\n",
    "      Node2.append(Model_weights2[i+1][j])\n",
    "      if (i+2<len(Model_weights2)):\n",
    "        Node2.append(list(Model_weights2[i+2][j]))\n",
    "      layer1.append(Node1)\n",
    "      layer2.append(Node2)\n",
    "    if (layer_comparison(layer1, layer2)):\n",
    "      continue\n",
    "    else:\n",
    "      return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7646b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is used to average out all the models in the epsilon range\n",
    "#the problem is different here than compared with model comparison. Shape not important.\n",
    "def get_avg_weights(models_weights, inp_shape, out_shape):\n",
    "    avg_sum=get_initial_model(inp_shape, out_shape).get_weights()\n",
    "    #print(avg_sum)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                for k in range(len(avg_sum[i][j])):\n",
    "                    avg_sum[i][j][k]=0\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=0\n",
    "    #print(avg_sum)\n",
    "    \n",
    "    for i in range(len(models_weights)):\n",
    "        for j in range(0, len(avg_sum),2):\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #if(isinstance(avg_sum[j][0], np.ndarray)):\n",
    "            for k in range(len(avg_sum[j])):\n",
    "                avg_sum[j][k]=[avg_sum[j][k][l]+models_weights[i][j][k][l] for l in range(len(avg_sum[j][k]))]\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #else: gayab kr diya\n",
    "            print('andr aara h')\n",
    "            for k in range(len(avg_sum[j+1])):\n",
    "                avg_sum[j+1][k]=avg_sum[j+1][k]+models_weights[i][j+1][k]\n",
    "    \n",
    "    mean_size=len(models_weights)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                #print(\"yhn tk\")\n",
    "                avg_sum[i][j]=[avg_sum[i][j][k]/mean_size for k in range(len(avg_sum[i][j]))]\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=avg_sum[i+1][j]/mean_size\n",
    "    print(\"Done\")\n",
    "    return avg_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfba8501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is used to average out all the models in the epsilon range\n",
    "#the problem is different here than compared with model comparison. Shape not important.\n",
    "def get_avg_weights_2(models_weights, inp_shape, out_shape):\n",
    "    avg_sum=get_initial_model_2(inp_shape, 6).get_weights()\n",
    "    #print(avg_sum)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                for k in range(len(avg_sum[i][j])):\n",
    "                    avg_sum[i][j][k]=0\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=0\n",
    "    #print(avg_sum)\n",
    "    for i in range(len(models_weights)):\n",
    "        for j in range(0, len(avg_sum),2):\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            #if(isinstance(avg_sum[j][0], np.ndarray)):\n",
    "            for k in range(len(avg_sum[j])):\n",
    "                avg_sum[j][k]=[avg_sum[j][k][l]+models_weights[i][j][k][l] for l in range(len(avg_sum[j][k]))]\n",
    "            #print(isinstance(avg_sum[j], np.ndarray))\n",
    "            \n",
    "            for k in range(len(avg_sum[j+1])):\n",
    "                avg_sum[j+1][k]=avg_sum[j+1][k]+models_weights[i][j+1][k]\n",
    "    print(\"yhn tk\")\n",
    "    mean_size=len(models_weights)\n",
    "    print(mean_size)\n",
    "    for i in range(0,len(avg_sum),2):\n",
    "        if (i+2<=len(avg_sum)):\n",
    "            for j in range(len(avg_sum[i])):\n",
    "                #print(\"yhn tk\")\n",
    "                avg_sum[i][j]=[avg_sum[i][j][k]/mean_size for k in range(len(avg_sum[i][j]))]\n",
    "            for j in range(len(avg_sum[i+1])):\n",
    "                avg_sum[i+1][j]=avg_sum[i+1][j]/mean_size\n",
    "    print(\"Done\")\n",
    "    return avg_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2d00af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom functions for f1, precision and recall\n",
    "\n",
    "from keras import backend as K\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f422b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to check if the two samples are different:\n",
    "def return_samples(Positive, Negative, data, N):\n",
    "    datasets=[]\n",
    "    positiveN=int((Positive.shape[0]/data.shape[0])*N)\n",
    "    negativeN=int(N-positiveN)\n",
    "    print(negativeN)\n",
    "    while (Positive.empty==False and Negative.empty==False):\n",
    "        df1=Positive.sample(min(positiveN, len(Positive)))\n",
    "        Positive.drop(df1.index, inplace=True)\n",
    "        \"\"\"\n",
    "        drop_df1=np.random.choice(df1.index,(int)(min(positiveN, math.ceil(len(Positive))/2)), replace=False)\n",
    "        if len(Positive)<positiveN:\n",
    "            Positive.drop(df1.index, inplace=True)\n",
    "        else:\n",
    "            Positive.drop(drop_df1, inplace=True)\n",
    "        #print(len(Positive))\n",
    "        \"\"\"\n",
    "        df2=Negative.sample(min(negativeN, len(Negative)))\n",
    "        Negative.drop(df2.index, inplace=True)\n",
    "        \"\"\"\n",
    "        drop_df2 = np.random.choice(df2.index,(int)(min(negativeN, math.ceil(len(Negative))/2)))\n",
    "        if len(Negative)<negativeN:\n",
    "            Negative.drop(df2.index, inplace = True)\n",
    "        else:\n",
    "            Negative.drop(drop_df2, inplace=True)\n",
    "        \"\"\"\n",
    "        dataset=df1.append(df2, ignore_index=True)\n",
    "        dataset.sample(frac = 1)\n",
    "        dataset.sample(frac = 1)\n",
    "        dataset.sample(frac = 1)\n",
    "        datasets.append(dataset)\n",
    "    print(\"returned datasets\")\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71865325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate sampele which are plausible deniable\n",
    "#there exists a data lets say data\n",
    "def generate_samples(data, num_samples, N):\n",
    "    samples=[]\n",
    "    intersection=[]\n",
    "    while num_samples>0:    \n",
    "        Positive = data[data[target_variable]==0]\n",
    "        Negative = data[data[target_variable]==1]\n",
    "        positiveN=int((Positive.shape[0]/data.shape[0])*N)\n",
    "        negativeN=int(N-positiveN)\n",
    "        df1=Positive.sample(min(positiveN, len(Positive)))\n",
    "        #Positive.drop(df1.index, inplace=True)\n",
    "        df2=Negative.sample(min(negativeN, len(Negative)))\n",
    "        #Negative.drop(df2.index, inplace=True)\n",
    "        sample=df1.append(df2, ignore_index=False)\n",
    "        samples.append(sample)\n",
    "        num_samples-=1\n",
    "\n",
    "    intersection=list(set(samples[0].index).intersection(samples[1].index))\n",
    "    for i in range(2,len(samples)):\n",
    "        intersection=list(set(samples[i].index).intersection(intersection))\n",
    "    if intersection:\n",
    "        rnum = random.randint(0, len(samples)-1)\n",
    "        samples[rnum].drop(intersection)\n",
    "        print(\"some intersection\")\n",
    "    print(\"finished\")\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a463580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate sampele which are plausible deniable multiclass\n",
    "#there exists a data lets say data\n",
    "def generate_samples_multi(data, num_samples, N):\n",
    "    samples=[]\n",
    "    intersection=[]\n",
    "    \n",
    "    len_clas=[]\n",
    "    data_cls=[]\n",
    "    target_variable='Class'\n",
    "    num_classes=data[target_variable].unique\n",
    "    labels = list(pd.unique(data[target_variable]))\n",
    "    #print(data)\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        data_cls.append(data[data[target_variable]==labels[i]])\n",
    "        len_clas.append(int(((data_cls[i].shape[0]*data.shape[0])/data[data[target_variable]==labels[i]].shape[0])))\n",
    "    #print(data_cls)\n",
    "    #print(len_clas)\n",
    "    while num_samples>0:  \n",
    "        for i in range(len(labels)):\n",
    "            if i==0:\n",
    "                df=data_cls[i].sample(min(len(data_cls[i]), len_clas[i]))\n",
    "            else:\n",
    "                df1=data_cls[i].sample(min(len(data_cls[i]), len_clas[i]))\n",
    "                df=df.append(df1, ignore_index = True)\n",
    "        samples.append(df)\n",
    "        num_samples-=1\n",
    "    intersection=list(set(samples[0].index).intersection(samples[1].index))\n",
    "    for i in range(2,len(samples)):\n",
    "        intersection=list(set(samples[i].index).intersection(intersection))\n",
    "    if intersection:\n",
    "        rnum = 0 #here intentionally done 0 fas poker has enough number of 0 class\n",
    "        samples[rnum].drop(intersection)\n",
    "        print(\"some intersection\")\n",
    "    print(\"finished\")\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bc5c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do we need to find all the models or only the mean recommended models?\n",
    "def epsilon_mean_recommendation(add_weights,data):\n",
    "    mean_model_weights=[]\n",
    "    for i in range(len(add_weights)):\n",
    "        mean_model_weights.append(get_avg_weights(add_weights[i],data.shape[1]-1, 6))\n",
    "    mean_models=[]\n",
    "    mean_model_train_metrics=[]\n",
    "    mean_model_loss=[]\n",
    "    mean_model_acc=[]\n",
    "    mean_model_test_metrics=[]\n",
    "    mean_model_test_loss=[]\n",
    "    mean_model_test_acc=[]\n",
    "    y = to_categorical(data[target_variable], num_classes=6)\n",
    "    X = data.drop(columns=target_variable)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    for i in range(len(add_weights)):\n",
    "        init_model=get_initial_model(X_test.shape[1], 6)\n",
    "        init_model.set_weights(mean_model_weights[i])\n",
    "        mean_model_train_metrics.append(init_model.evaluate(X_train, y_train))\n",
    "        mean_model_loss.append(mean_model_train_metrics[i][0])\n",
    "        mean_model_acc.append(mean_model_train_metrics[i][1])\n",
    "        mean_model_test_metrics.append(init_model.evaluate(X_test, y_test))\n",
    "        mean_model_test_loss.append(mean_model_test_metrics[i][0])\n",
    "        mean_model_test_acc.append(mean_model_test_metrics[i][1])\n",
    "    return mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcd1308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do we need to find all the models or only the mean recommended models?\n",
    "def epsilon_mean_recommendation_2(add_weights,data):\n",
    "    mean_model_weights=[]\n",
    "    for i in range(len(add_weights)):\n",
    "        mean_model_weights.append(get_avg_weights_2(add_weights[i],data.shape[1]-1, 6))\n",
    "    mean_models=[]\n",
    "    mean_model_train_metrics=[]\n",
    "    mean_model_loss=[]\n",
    "    mean_model_acc=[]\n",
    "    mean_model_test_metrics=[]\n",
    "    mean_model_test_loss=[]\n",
    "    mean_model_test_acc=[]\n",
    "    y = to_categorical(data[target_variable], num_classes=6)\n",
    "    X = data.drop(columns=target_variable)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    for i in range(len(add_weights)):\n",
    "        init_model=get_initial_model_2(X_test.shape[1], 6)\n",
    "        init_model.set_weights(mean_model_weights[i])\n",
    "        mean_model_train_metrics.append(init_model.evaluate(X_train, y_train))\n",
    "        mean_model_loss.append(mean_model_train_metrics[i][0])\n",
    "        mean_model_acc.append(mean_model_train_metrics[i][1])\n",
    "        mean_model_test_metrics.append(init_model.evaluate(X_test, y_test))\n",
    "        mean_model_test_loss.append(mean_model_test_metrics[i][0])\n",
    "        mean_model_test_acc.append(mean_model_test_metrics[i][1])\n",
    "    return mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ee64188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drift_detection(models, incoming_data):\n",
    "    predictions = []\n",
    "    prediction_probe=[]\n",
    "    \n",
    "    \n",
    "    y_test=to_categorical(incoming_data[target_variable], num_classes=6)\n",
    "    #print(y_test)\n",
    "    X_test=incoming_data.drop(columns=target_variable)\n",
    "    \n",
    "    init_model=get_initial_model(incoming_data.shape[1]-1, 6)\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        init_model.set_weights(models[i])\n",
    "        predictions.append(init_model.predict(X_test))\n",
    "    prediction_probe = np.mean(predictions, axis = 0)\n",
    "    entro = entropy(prediction_probe, base=2, axis=1)\n",
    "    \n",
    "    entropy_list = entro.tolist()\n",
    "    \n",
    "    return prediction_probe, entropy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ebcf3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drift_detection_2(models, incoming_data):\n",
    "    predictions = []\n",
    "    prediction_probe=[]\n",
    "    \n",
    "    \n",
    "    y_test=to_categorical(incoming_data[target_variable], num_classes=6)\n",
    "    #print(y_test)\n",
    "    X_test=incoming_data.drop(columns=target_variable)\n",
    "    \n",
    "    init_model=get_initial_model_2(incoming_data.shape[1]-1, 6)\n",
    "    \n",
    "    for i in range(len(models)):\n",
    "        init_model.set_weights(models[i])\n",
    "        predictions.append(init_model.predict(X_test))\n",
    "    prediction_probe = np.mean(predictions, axis = 0)\n",
    "    entro = entropy(prediction_probe, base=2, axis=1)\n",
    "    \n",
    "    entropy_list = entro.tolist()\n",
    "    \n",
    "    return prediction_probe, entropy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7c02612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_train_data(train_data, incoming_data):\n",
    "    train_data.drop(index=train_data.index[:len(incoming_data)], inplace=True)\n",
    "    train_data=train_data.append(incoming_data, ignore_index=True)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e30aa780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "some intersection\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./artificial/insects/INSECTS-incremental_balanced_norm.csv\", sep=',')\n",
    "\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#dataset = pd.DataFrame(scaler.fit_transform(dataset), columns=dataset.columns)\n",
    "#target_variable=\n",
    "#dataset[54] = dataset[54]-1\n",
    "#experiments for ADWIN unlimited\n",
    "\n",
    "#try with no retraining\n",
    "\n",
    "#Now lets see for No training\n",
    "\n",
    "from skmultiflow.data import DataStream\n",
    "stream = DataStream(dataset)\n",
    "\n",
    "two_percent = int(stream.n_remaining_samples()*0.02)\n",
    "five_percent = int(stream.n_remaining_samples()*0.05)\n",
    "initial_data = stream.next_sample(int(stream.n_remaining_samples()*0.10))\n",
    "\n",
    "data_init=pd.DataFrame(initial_data[0], columns=dataset.columns[:-1])\n",
    "data_init['Class']=initial_data[1]\n",
    "target_variable='Class'\n",
    "\n",
    "print(data_init['Class'][5])\n",
    "epsilon = 0.1\n",
    "N = int(data_init.shape[0]*0.45)\n",
    "samples = generate_samples_multi(data_init.copy(), 50, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d21ddf13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6311 - accuracy: 0.2941 - val_loss: 3.1958 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1926 - accuracy: 0.4355 - val_loss: 4.9266 - val_accuracy: 0.0026\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0680 - accuracy: 0.5263 - val_loss: 5.7322 - val_accuracy: 0.0096\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0038 - accuracy: 0.5482 - val_loss: 6.1553 - val_accuracy: 0.0955\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9554 - accuracy: 0.5476 - val_loss: 6.7084 - val_accuracy: 0.0465\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9229 - accuracy: 0.5785 - val_loss: 6.8137 - val_accuracy: 0.0359\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9076 - accuracy: 0.5895 - val_loss: 6.9860 - val_accuracy: 0.0403\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8953 - accuracy: 0.5930 - val_loss: 7.3091 - val_accuracy: 0.0298\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8855 - accuracy: 0.5912 - val_loss: 7.1463 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8785 - accuracy: 0.5934 - val_loss: 7.3410 - val_accuracy: 0.0280\n",
      "0.5934210419654846\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6186 - accuracy: 0.3178 - val_loss: 3.0791 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1673 - accuracy: 0.4586 - val_loss: 4.8645 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0605 - accuracy: 0.5509 - val_loss: 5.7420 - val_accuracy: 0.0377\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9985 - accuracy: 0.5531 - val_loss: 6.3574 - val_accuracy: 0.0640\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9487 - accuracy: 0.5647 - val_loss: 6.5686 - val_accuracy: 0.0675\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9195 - accuracy: 0.5853 - val_loss: 6.7954 - val_accuracy: 0.0421\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9036 - accuracy: 0.5956 - val_loss: 7.0698 - val_accuracy: 0.0570\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8939 - accuracy: 0.5954 - val_loss: 7.1999 - val_accuracy: 0.0280\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8846 - accuracy: 0.6000 - val_loss: 7.1898 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8762 - accuracy: 0.6022 - val_loss: 7.3478 - val_accuracy: 0.0359\n",
      "0.6021929979324341\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6081 - accuracy: 0.3191 - val_loss: 3.0247 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1553 - accuracy: 0.4502 - val_loss: 4.7734 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0571 - accuracy: 0.5138 - val_loss: 5.6895 - val_accuracy: 0.0149\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0016 - accuracy: 0.5612 - val_loss: 6.0716 - val_accuracy: 0.0859\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9542 - accuracy: 0.5750 - val_loss: 6.4505 - val_accuracy: 0.0517\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9237 - accuracy: 0.5831 - val_loss: 6.7308 - val_accuracy: 0.0535\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9065 - accuracy: 0.5919 - val_loss: 6.7294 - val_accuracy: 0.0456\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8937 - accuracy: 0.5996 - val_loss: 6.8015 - val_accuracy: 0.0307\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8824 - accuracy: 0.5976 - val_loss: 7.2054 - val_accuracy: 0.0333\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8720 - accuracy: 0.6046 - val_loss: 7.2750 - val_accuracy: 0.0184\n",
      "0.6046052575111389\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6198 - accuracy: 0.2923 - val_loss: 3.0619 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1925 - accuracy: 0.4417 - val_loss: 4.9043 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0778 - accuracy: 0.5066 - val_loss: 5.6058 - val_accuracy: 0.0044\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0228 - accuracy: 0.5452 - val_loss: 6.1707 - val_accuracy: 0.0272\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9676 - accuracy: 0.5575 - val_loss: 6.3655 - val_accuracy: 0.0535\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9342 - accuracy: 0.5846 - val_loss: 6.5973 - val_accuracy: 0.0386\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9148 - accuracy: 0.5956 - val_loss: 6.6046 - val_accuracy: 0.0307\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9005 - accuracy: 0.5967 - val_loss: 6.5961 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8916 - accuracy: 0.6009 - val_loss: 6.8320 - val_accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8822 - accuracy: 0.5989 - val_loss: 6.8771 - val_accuracy: 0.0289\n",
      "0.5989035367965698\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6195 - accuracy: 0.3156 - val_loss: 3.0316 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1891 - accuracy: 0.4318 - val_loss: 4.6662 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0819 - accuracy: 0.4939 - val_loss: 5.6330 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0340 - accuracy: 0.5379 - val_loss: 6.0191 - val_accuracy: 0.0131\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9811 - accuracy: 0.5537 - val_loss: 6.4428 - val_accuracy: 0.0245\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9451 - accuracy: 0.5686 - val_loss: 6.6355 - val_accuracy: 0.0280\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9227 - accuracy: 0.5860 - val_loss: 6.7127 - val_accuracy: 0.0429\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9061 - accuracy: 0.5947 - val_loss: 6.9444 - val_accuracy: 0.0394\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8962 - accuracy: 0.5936 - val_loss: 6.8344 - val_accuracy: 0.0429\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8879 - accuracy: 0.5956 - val_loss: 7.3326 - val_accuracy: 0.0158\n",
      "0.5956140160560608\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6168 - accuracy: 0.2991 - val_loss: 3.1794 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1738 - accuracy: 0.4636 - val_loss: 4.8330 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0579 - accuracy: 0.5305 - val_loss: 5.6344 - val_accuracy: 0.0053\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9933 - accuracy: 0.5700 - val_loss: 6.1268 - val_accuracy: 0.0684\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9550 - accuracy: 0.5686 - val_loss: 6.5309 - val_accuracy: 0.0377\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9301 - accuracy: 0.5829 - val_loss: 6.7398 - val_accuracy: 0.0351\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9155 - accuracy: 0.5879 - val_loss: 6.7905 - val_accuracy: 0.0394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9039 - accuracy: 0.5877 - val_loss: 6.8742 - val_accuracy: 0.0263\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8934 - accuracy: 0.5910 - val_loss: 7.1066 - val_accuracy: 0.0254\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8844 - accuracy: 0.6004 - val_loss: 7.0755 - val_accuracy: 0.0307\n",
      "0.6004385948181152\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6524 - accuracy: 0.2743 - val_loss: 3.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2187 - accuracy: 0.4248 - val_loss: 4.6184 - val_accuracy: 0.0123\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0975 - accuracy: 0.4715 - val_loss: 5.5615 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0646 - accuracy: 0.5059 - val_loss: 5.8997 - val_accuracy: 0.0140\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0358 - accuracy: 0.5399 - val_loss: 6.2272 - val_accuracy: 0.0140\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9971 - accuracy: 0.5675 - val_loss: 6.5121 - val_accuracy: 0.0263\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9643 - accuracy: 0.5827 - val_loss: 6.6714 - val_accuracy: 0.0377\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9422 - accuracy: 0.5860 - val_loss: 6.8413 - val_accuracy: 0.0158\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9293 - accuracy: 0.5928 - val_loss: 6.8268 - val_accuracy: 0.0237\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9161 - accuracy: 0.5921 - val_loss: 7.0358 - val_accuracy: 0.0324\n",
      "0.5921052694320679\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6394 - accuracy: 0.3068 - val_loss: 3.0664 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2163 - accuracy: 0.4314 - val_loss: 4.8285 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0928 - accuracy: 0.4811 - val_loss: 5.5808 - val_accuracy: 0.0289\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0618 - accuracy: 0.5018 - val_loss: 6.0778 - val_accuracy: 0.0237\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0329 - accuracy: 0.5377 - val_loss: 6.3244 - val_accuracy: 0.0508\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9979 - accuracy: 0.5643 - val_loss: 6.7140 - val_accuracy: 0.0079\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9620 - accuracy: 0.5715 - val_loss: 7.1479 - val_accuracy: 0.0482\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9321 - accuracy: 0.5829 - val_loss: 7.2130 - val_accuracy: 0.0280\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9188 - accuracy: 0.5925 - val_loss: 7.1213 - val_accuracy: 0.0245\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9052 - accuracy: 0.5978 - val_loss: 7.4053 - val_accuracy: 0.0228\n",
      "0.597806990146637\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6500 - accuracy: 0.3026 - val_loss: 3.0656 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2213 - accuracy: 0.4305 - val_loss: 4.8524 - val_accuracy: 0.0123\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0811 - accuracy: 0.5121 - val_loss: 5.6292 - val_accuracy: 0.0272\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0207 - accuracy: 0.5450 - val_loss: 6.2444 - val_accuracy: 0.0657\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9692 - accuracy: 0.5577 - val_loss: 6.7866 - val_accuracy: 0.0517\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9362 - accuracy: 0.5730 - val_loss: 6.7937 - val_accuracy: 0.0219\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9216 - accuracy: 0.5792 - val_loss: 6.8330 - val_accuracy: 0.0377\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9086 - accuracy: 0.5844 - val_loss: 7.0650 - val_accuracy: 0.0245\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9016 - accuracy: 0.5888 - val_loss: 7.2141 - val_accuracy: 0.0245\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8926 - accuracy: 0.5873 - val_loss: 7.2573 - val_accuracy: 0.0289\n",
      "0.5872806906700134\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6388 - accuracy: 0.2882 - val_loss: 3.1441 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2028 - accuracy: 0.4221 - val_loss: 4.8427 - val_accuracy: 0.0096\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0851 - accuracy: 0.4991 - val_loss: 5.6978 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0409 - accuracy: 0.5564 - val_loss: 6.0687 - val_accuracy: 0.0938\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9902 - accuracy: 0.5535 - val_loss: 6.5540 - val_accuracy: 0.0850\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9440 - accuracy: 0.5627 - val_loss: 7.0320 - val_accuracy: 0.0719\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9223 - accuracy: 0.5787 - val_loss: 7.0296 - val_accuracy: 0.0359\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9067 - accuracy: 0.5980 - val_loss: 7.0264 - val_accuracy: 0.0289\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8968 - accuracy: 0.5943 - val_loss: 7.1744 - val_accuracy: 0.0324\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8879 - accuracy: 0.5961 - val_loss: 7.1499 - val_accuracy: 0.0149\n",
      "0.5960526466369629\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6095 - accuracy: 0.2987 - val_loss: 3.0467 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1728 - accuracy: 0.4333 - val_loss: 4.8608 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0722 - accuracy: 0.5020 - val_loss: 5.7189 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0213 - accuracy: 0.5342 - val_loss: 6.0961 - val_accuracy: 0.0131\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9645 - accuracy: 0.5702 - val_loss: 6.4535 - val_accuracy: 0.0684\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9287 - accuracy: 0.5768 - val_loss: 6.6898 - val_accuracy: 0.0508\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9115 - accuracy: 0.5917 - val_loss: 6.9757 - val_accuracy: 0.0465\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9018 - accuracy: 0.5919 - val_loss: 7.0580 - val_accuracy: 0.0316\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8888 - accuracy: 0.5956 - val_loss: 7.1252 - val_accuracy: 0.0228\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8804 - accuracy: 0.6018 - val_loss: 7.4483 - val_accuracy: 0.0298\n",
      "0.601754367351532\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6278 - accuracy: 0.2982 - val_loss: 3.0170 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1870 - accuracy: 0.4395 - val_loss: 4.7246 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0726 - accuracy: 0.5055 - val_loss: 5.8370 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0161 - accuracy: 0.5513 - val_loss: 6.1355 - val_accuracy: 0.0438\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9643 - accuracy: 0.5649 - val_loss: 6.4844 - val_accuracy: 0.0272\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9313 - accuracy: 0.5818 - val_loss: 6.4155 - val_accuracy: 0.0394\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9148 - accuracy: 0.5882 - val_loss: 6.5570 - val_accuracy: 0.0403\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9016 - accuracy: 0.5932 - val_loss: 6.5758 - val_accuracy: 0.0272\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8922 - accuracy: 0.5971 - val_loss: 6.5033 - val_accuracy: 0.0254\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8830 - accuracy: 0.5976 - val_loss: 6.5976 - val_accuracy: 0.0342\n",
      "0.5975877046585083\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6371 - accuracy: 0.2925 - val_loss: 3.0561 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2076 - accuracy: 0.4287 - val_loss: 4.7272 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0904 - accuracy: 0.4901 - val_loss: 5.5130 - val_accuracy: 0.0079\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0449 - accuracy: 0.5309 - val_loss: 5.9623 - val_accuracy: 0.0798\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9923 - accuracy: 0.5559 - val_loss: 6.0358 - val_accuracy: 0.0491\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9471 - accuracy: 0.5811 - val_loss: 6.2409 - val_accuracy: 0.0684\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9235 - accuracy: 0.5871 - val_loss: 6.6728 - val_accuracy: 0.0605\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9060 - accuracy: 0.5901 - val_loss: 6.7001 - val_accuracy: 0.0578\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8974 - accuracy: 0.5939 - val_loss: 7.0423 - val_accuracy: 0.0403\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8861 - accuracy: 0.6013 - val_loss: 7.1081 - val_accuracy: 0.0359\n",
      "0.6013157963752747\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6388 - accuracy: 0.3156 - val_loss: 3.0527 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2062 - accuracy: 0.4230 - val_loss: 4.8884 - val_accuracy: 0.0158\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0873 - accuracy: 0.4781 - val_loss: 5.5541 - val_accuracy: 0.0245\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0471 - accuracy: 0.5178 - val_loss: 5.9750 - val_accuracy: 0.0316\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0034 - accuracy: 0.5550 - val_loss: 6.1558 - val_accuracy: 0.0552\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9562 - accuracy: 0.5605 - val_loss: 6.7357 - val_accuracy: 0.0333\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9277 - accuracy: 0.5831 - val_loss: 6.9871 - val_accuracy: 0.0289\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9118 - accuracy: 0.5853 - val_loss: 7.2820 - val_accuracy: 0.0386\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8975 - accuracy: 0.5963 - val_loss: 7.4104 - val_accuracy: 0.0482\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8876 - accuracy: 0.6002 - val_loss: 7.5291 - val_accuracy: 0.0394\n",
      "0.6002193093299866\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6283 - accuracy: 0.3011 - val_loss: 3.0511 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1836 - accuracy: 0.4250 - val_loss: 4.7758 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0786 - accuracy: 0.4844 - val_loss: 5.6574 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0494 - accuracy: 0.5118 - val_loss: 5.9090 - val_accuracy: 8.7642e-04\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0147 - accuracy: 0.5421 - val_loss: 6.3184 - val_accuracy: 8.7642e-04\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9743 - accuracy: 0.5632 - val_loss: 6.3409 - val_accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9380 - accuracy: 0.5904 - val_loss: 6.6848 - val_accuracy: 0.0333\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9206 - accuracy: 0.5899 - val_loss: 6.7895 - val_accuracy: 0.0272\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9082 - accuracy: 0.5952 - val_loss: 6.9193 - val_accuracy: 0.0263\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8953 - accuracy: 0.6011 - val_loss: 7.0191 - val_accuracy: 0.0210\n",
      "0.601096510887146\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6331 - accuracy: 0.3175 - val_loss: 3.0656 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1934 - accuracy: 0.4377 - val_loss: 4.7428 - val_accuracy: 0.0088\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0768 - accuracy: 0.5031 - val_loss: 5.5375 - val_accuracy: 0.0026\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0243 - accuracy: 0.5447 - val_loss: 5.9754 - val_accuracy: 0.0833\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9749 - accuracy: 0.5548 - val_loss: 6.2177 - val_accuracy: 0.0596\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9396 - accuracy: 0.5796 - val_loss: 6.6287 - val_accuracy: 0.0359\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9206 - accuracy: 0.5846 - val_loss: 6.7796 - val_accuracy: 0.0316\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9069 - accuracy: 0.5974 - val_loss: 7.2826 - val_accuracy: 0.0386\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8972 - accuracy: 0.5956 - val_loss: 7.5197 - val_accuracy: 0.0298\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8861 - accuracy: 0.6002 - val_loss: 7.4365 - val_accuracy: 0.0307\n",
      "0.6002193093299866\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 3ms/step - loss: 1.6098 - accuracy: 0.2974 - val_loss: 3.0441 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1737 - accuracy: 0.4458 - val_loss: 4.8053 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0752 - accuracy: 0.4943 - val_loss: 5.5770 - val_accuracy: 0.0210\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0306 - accuracy: 0.5390 - val_loss: 5.9819 - val_accuracy: 0.0429\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9745 - accuracy: 0.5564 - val_loss: 6.3559 - val_accuracy: 0.0596\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9369 - accuracy: 0.5721 - val_loss: 6.5494 - val_accuracy: 0.0403\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9139 - accuracy: 0.5860 - val_loss: 6.8600 - val_accuracy: 0.0394\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9004 - accuracy: 0.5954 - val_loss: 6.8410 - val_accuracy: 0.0447\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8918 - accuracy: 0.5961 - val_loss: 7.0620 - val_accuracy: 0.0421\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8838 - accuracy: 0.5947 - val_loss: 6.9805 - val_accuracy: 0.0342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5947368144989014\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6343 - accuracy: 0.3024 - val_loss: 3.1235 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1931 - accuracy: 0.4351 - val_loss: 4.8958 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0726 - accuracy: 0.5191 - val_loss: 5.6272 - val_accuracy: 0.0245\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0088 - accuracy: 0.5491 - val_loss: 6.4176 - val_accuracy: 0.0587\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9596 - accuracy: 0.5649 - val_loss: 6.7153 - val_accuracy: 0.0762\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9315 - accuracy: 0.5796 - val_loss: 7.0856 - val_accuracy: 0.0429\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9168 - accuracy: 0.5789 - val_loss: 7.1515 - val_accuracy: 0.0324\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9036 - accuracy: 0.5899 - val_loss: 7.3234 - val_accuracy: 0.0403\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8964 - accuracy: 0.5923 - val_loss: 7.2934 - val_accuracy: 0.0421\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8853 - accuracy: 0.5952 - val_loss: 7.4514 - val_accuracy: 0.0272\n",
      "0.5951754450798035\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6333 - accuracy: 0.2939 - val_loss: 3.0363 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1783 - accuracy: 0.4471 - val_loss: 4.7704 - val_accuracy: 0.0061\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0607 - accuracy: 0.5300 - val_loss: 5.7699 - val_accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9964 - accuracy: 0.5673 - val_loss: 5.9668 - val_accuracy: 0.0535\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9503 - accuracy: 0.5735 - val_loss: 6.4362 - val_accuracy: 0.0333\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9236 - accuracy: 0.5820 - val_loss: 6.6294 - val_accuracy: 0.0412\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9092 - accuracy: 0.5925 - val_loss: 6.8201 - val_accuracy: 0.0447\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8978 - accuracy: 0.5893 - val_loss: 7.0552 - val_accuracy: 0.0272\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8881 - accuracy: 0.5985 - val_loss: 7.0044 - val_accuracy: 0.0394\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8803 - accuracy: 0.5974 - val_loss: 7.0222 - val_accuracy: 0.0123\n",
      "0.5973684191703796\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6121 - accuracy: 0.3061 - val_loss: 3.0502 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1786 - accuracy: 0.4513 - val_loss: 4.7534 - val_accuracy: 0.0053\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0644 - accuracy: 0.5254 - val_loss: 5.4136 - val_accuracy: 0.1122\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0043 - accuracy: 0.5596 - val_loss: 6.0914 - val_accuracy: 0.0754\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9562 - accuracy: 0.5640 - val_loss: 6.4745 - val_accuracy: 0.0482\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9323 - accuracy: 0.5822 - val_loss: 6.8789 - val_accuracy: 0.0333\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9141 - accuracy: 0.5840 - val_loss: 6.9060 - val_accuracy: 0.0272\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9019 - accuracy: 0.5888 - val_loss: 6.9189 - val_accuracy: 0.0316\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8940 - accuracy: 0.5939 - val_loss: 7.1724 - val_accuracy: 0.0298\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8862 - accuracy: 0.5991 - val_loss: 7.2853 - val_accuracy: 0.0263\n",
      "0.5991228222846985\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6261 - accuracy: 0.3171 - val_loss: 2.9581 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1755 - accuracy: 0.4728 - val_loss: 4.8168 - val_accuracy: 0.0079\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0472 - accuracy: 0.5386 - val_loss: 5.6008 - val_accuracy: 0.0219\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9844 - accuracy: 0.5601 - val_loss: 6.2490 - val_accuracy: 0.0543\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9442 - accuracy: 0.5651 - val_loss: 6.3307 - val_accuracy: 0.0324\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9210 - accuracy: 0.5846 - val_loss: 6.6668 - val_accuracy: 0.0473\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9069 - accuracy: 0.5908 - val_loss: 6.6893 - val_accuracy: 0.0316\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8961 - accuracy: 0.5936 - val_loss: 6.9788 - val_accuracy: 0.0342\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8849 - accuracy: 0.5943 - val_loss: 6.8602 - val_accuracy: 0.0245\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8767 - accuracy: 0.6037 - val_loss: 7.1546 - val_accuracy: 0.0359\n",
      "0.6037280559539795\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6406 - accuracy: 0.3022 - val_loss: 2.9817 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2034 - accuracy: 0.4224 - val_loss: 5.0146 - val_accuracy: 0.0044\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0834 - accuracy: 0.4912 - val_loss: 5.9323 - val_accuracy: 0.0105\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0357 - accuracy: 0.5287 - val_loss: 6.4456 - val_accuracy: 0.0789\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9851 - accuracy: 0.5454 - val_loss: 6.5721 - val_accuracy: 0.0780\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9445 - accuracy: 0.5656 - val_loss: 7.1514 - val_accuracy: 0.0596\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9226 - accuracy: 0.5897 - val_loss: 7.1396 - val_accuracy: 0.0561\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9094 - accuracy: 0.5923 - val_loss: 6.9563 - val_accuracy: 0.0447\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8983 - accuracy: 0.5928 - val_loss: 7.3850 - val_accuracy: 0.0473\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8888 - accuracy: 0.5963 - val_loss: 7.4829 - val_accuracy: 0.0412\n",
      "0.5962719321250916\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6465 - accuracy: 0.2971 - val_loss: 3.0970 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2271 - accuracy: 0.4193 - val_loss: 4.9221 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0959 - accuracy: 0.4614 - val_loss: 5.6265 - val_accuracy: 0.0245\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0605 - accuracy: 0.4906 - val_loss: 6.1180 - val_accuracy: 0.0219\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0328 - accuracy: 0.5360 - val_loss: 6.5012 - val_accuracy: 0.0219\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9994 - accuracy: 0.5526 - val_loss: 6.6856 - val_accuracy: 0.0465\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9597 - accuracy: 0.5680 - val_loss: 6.7745 - val_accuracy: 0.0701\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9367 - accuracy: 0.5739 - val_loss: 6.8750 - val_accuracy: 0.0412\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9204 - accuracy: 0.5860 - val_loss: 7.2388 - val_accuracy: 0.0491\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9092 - accuracy: 0.5917 - val_loss: 7.3750 - val_accuracy: 0.0456\n",
      "0.5916666388511658\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6397 - accuracy: 0.2954 - val_loss: 3.0857 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2041 - accuracy: 0.4450 - val_loss: 4.7781 - val_accuracy: 0.0026\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0777 - accuracy: 0.5129 - val_loss: 5.7583 - val_accuracy: 0.0140\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0174 - accuracy: 0.5487 - val_loss: 6.1544 - val_accuracy: 0.0456\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9611 - accuracy: 0.5741 - val_loss: 6.6350 - val_accuracy: 0.0429\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9350 - accuracy: 0.5842 - val_loss: 6.7145 - val_accuracy: 0.0237\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9195 - accuracy: 0.5871 - val_loss: 6.6285 - val_accuracy: 0.0307\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9086 - accuracy: 0.5923 - val_loss: 6.8943 - val_accuracy: 0.0421\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9004 - accuracy: 0.5910 - val_loss: 6.9641 - val_accuracy: 0.0202\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8910 - accuracy: 0.5976 - val_loss: 7.0926 - val_accuracy: 0.0263\n",
      "0.5975877046585083\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6492 - accuracy: 0.3070 - val_loss: 2.9234 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2034 - accuracy: 0.4311 - val_loss: 4.8245 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0908 - accuracy: 0.4654 - val_loss: 5.5585 - val_accuracy: 0.0096\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0538 - accuracy: 0.5090 - val_loss: 6.0576 - val_accuracy: 0.0096\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0204 - accuracy: 0.5432 - val_loss: 6.2622 - val_accuracy: 0.0289\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9766 - accuracy: 0.5741 - val_loss: 6.6605 - val_accuracy: 0.0394\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9472 - accuracy: 0.5761 - val_loss: 6.6355 - val_accuracy: 0.0403\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9316 - accuracy: 0.5853 - val_loss: 7.0141 - val_accuracy: 0.0228\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9167 - accuracy: 0.5842 - val_loss: 7.1366 - val_accuracy: 0.0421\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9072 - accuracy: 0.5956 - val_loss: 7.2141 - val_accuracy: 0.0359\n",
      "0.5956140160560608\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6372 - accuracy: 0.3039 - val_loss: 3.1429 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2164 - accuracy: 0.4217 - val_loss: 4.9132 - val_accuracy: 0.0026\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0916 - accuracy: 0.4636 - val_loss: 5.8105 - val_accuracy: 0.0061\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0574 - accuracy: 0.5103 - val_loss: 6.2319 - val_accuracy: 0.0219\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0234 - accuracy: 0.5397 - val_loss: 6.5085 - val_accuracy: 0.0815\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9852 - accuracy: 0.5586 - val_loss: 6.8079 - val_accuracy: 0.0552\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9501 - accuracy: 0.5715 - val_loss: 6.9807 - val_accuracy: 0.0289\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9273 - accuracy: 0.5864 - val_loss: 7.4010 - val_accuracy: 0.0421\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9144 - accuracy: 0.5906 - val_loss: 7.5538 - val_accuracy: 0.0359\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9023 - accuracy: 0.5980 - val_loss: 7.6419 - val_accuracy: 0.0333\n",
      "0.5980263352394104\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6346 - accuracy: 0.2925 - val_loss: 3.1245 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1936 - accuracy: 0.4311 - val_loss: 4.7358 - val_accuracy: 0.0044\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0855 - accuracy: 0.4978 - val_loss: 5.6890 - val_accuracy: 0.0044\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0489 - accuracy: 0.5206 - val_loss: 6.0875 - val_accuracy: 0.0596\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0055 - accuracy: 0.5568 - val_loss: 6.5491 - val_accuracy: 0.0079\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9627 - accuracy: 0.5752 - val_loss: 6.7652 - val_accuracy: 0.0359\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9373 - accuracy: 0.5785 - val_loss: 6.8218 - val_accuracy: 0.0429\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9215 - accuracy: 0.5831 - val_loss: 7.3603 - val_accuracy: 0.0394\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9086 - accuracy: 0.5910 - val_loss: 7.4454 - val_accuracy: 0.0254\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9010 - accuracy: 0.5928 - val_loss: 7.5569 - val_accuracy: 0.0412\n",
      "0.5927631855010986\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6109 - accuracy: 0.3086 - val_loss: 3.1680 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1722 - accuracy: 0.4357 - val_loss: 4.7866 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0748 - accuracy: 0.4998 - val_loss: 5.8059 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0241 - accuracy: 0.5469 - val_loss: 6.1125 - val_accuracy: 0.0771\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9707 - accuracy: 0.5704 - val_loss: 6.3216 - val_accuracy: 0.0403\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9351 - accuracy: 0.5809 - val_loss: 6.6085 - val_accuracy: 0.0368\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9169 - accuracy: 0.5873 - val_loss: 6.5445 - val_accuracy: 0.0394\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9062 - accuracy: 0.5936 - val_loss: 6.7618 - val_accuracy: 0.0307\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8943 - accuracy: 0.5985 - val_loss: 6.8122 - val_accuracy: 0.0228\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8866 - accuracy: 0.5971 - val_loss: 7.1111 - val_accuracy: 0.0421\n",
      "0.597149133682251\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6460 - accuracy: 0.3022 - val_loss: 3.0904 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2036 - accuracy: 0.4257 - val_loss: 4.8646 - val_accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0809 - accuracy: 0.4987 - val_loss: 5.8516 - val_accuracy: 0.0342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0349 - accuracy: 0.5419 - val_loss: 6.2557 - val_accuracy: 0.0596\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9860 - accuracy: 0.5423 - val_loss: 6.4647 - val_accuracy: 0.0789\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9449 - accuracy: 0.5700 - val_loss: 6.8435 - val_accuracy: 0.0745\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9241 - accuracy: 0.5781 - val_loss: 7.0407 - val_accuracy: 0.0324\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9111 - accuracy: 0.5936 - val_loss: 7.2737 - val_accuracy: 0.0421\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9005 - accuracy: 0.5941 - val_loss: 7.3481 - val_accuracy: 0.0263\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8929 - accuracy: 0.5961 - val_loss: 7.5767 - val_accuracy: 0.0473\n",
      "0.5960526466369629\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6374 - accuracy: 0.3285 - val_loss: 2.9728 - val_accuracy: 8.7642e-04\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1951 - accuracy: 0.4522 - val_loss: 4.9044 - val_accuracy: 0.0026\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0702 - accuracy: 0.5167 - val_loss: 5.7687 - val_accuracy: 0.0692\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0087 - accuracy: 0.5447 - val_loss: 6.1563 - val_accuracy: 0.0789\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9575 - accuracy: 0.5697 - val_loss: 6.6276 - val_accuracy: 0.0517\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9285 - accuracy: 0.5816 - val_loss: 6.8541 - val_accuracy: 0.0237\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9141 - accuracy: 0.5862 - val_loss: 6.6559 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9023 - accuracy: 0.5921 - val_loss: 7.0571 - val_accuracy: 0.0289\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8933 - accuracy: 0.5985 - val_loss: 6.9562 - val_accuracy: 0.0447\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8826 - accuracy: 0.5993 - val_loss: 7.2452 - val_accuracy: 0.0333\n",
      "0.5993421077728271\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6376 - accuracy: 0.3055 - val_loss: 2.9845 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2066 - accuracy: 0.4298 - val_loss: 4.7153 - val_accuracy: 0.0026\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0871 - accuracy: 0.4833 - val_loss: 5.6183 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0513 - accuracy: 0.5221 - val_loss: 6.0510 - val_accuracy: 0.0394\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0127 - accuracy: 0.5502 - val_loss: 6.3465 - val_accuracy: 0.0605\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9665 - accuracy: 0.5640 - val_loss: 6.6634 - val_accuracy: 0.0587\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9364 - accuracy: 0.5827 - val_loss: 6.9931 - val_accuracy: 0.0561\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9139 - accuracy: 0.5921 - val_loss: 7.2690 - val_accuracy: 0.0316\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9018 - accuracy: 0.5921 - val_loss: 7.2971 - val_accuracy: 0.0359\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8908 - accuracy: 0.6055 - val_loss: 7.3171 - val_accuracy: 0.0219\n",
      "0.6054824590682983\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6274 - accuracy: 0.3136 - val_loss: 3.0136 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1796 - accuracy: 0.4599 - val_loss: 4.7317 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0689 - accuracy: 0.5287 - val_loss: 5.5869 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0217 - accuracy: 0.5463 - val_loss: 5.8213 - val_accuracy: 0.0815\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9716 - accuracy: 0.5610 - val_loss: 6.2622 - val_accuracy: 0.0745\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9423 - accuracy: 0.5649 - val_loss: 6.4929 - val_accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9234 - accuracy: 0.5871 - val_loss: 6.5602 - val_accuracy: 0.0307\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9090 - accuracy: 0.5879 - val_loss: 6.7953 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8973 - accuracy: 0.5934 - val_loss: 6.9435 - val_accuracy: 0.0263\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8892 - accuracy: 0.5993 - val_loss: 6.9691 - val_accuracy: 0.0096\n",
      "0.5993421077728271\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6236 - accuracy: 0.3035 - val_loss: 3.0772 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1759 - accuracy: 0.4559 - val_loss: 4.7647 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0632 - accuracy: 0.5285 - val_loss: 5.7289 - val_accuracy: 0.0035\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0069 - accuracy: 0.5658 - val_loss: 6.1997 - val_accuracy: 0.0394\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9632 - accuracy: 0.5658 - val_loss: 6.5204 - val_accuracy: 0.0403\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9385 - accuracy: 0.5814 - val_loss: 6.7201 - val_accuracy: 0.0237\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9203 - accuracy: 0.5822 - val_loss: 6.9143 - val_accuracy: 0.0280\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9098 - accuracy: 0.5899 - val_loss: 6.9624 - val_accuracy: 0.0359\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8998 - accuracy: 0.5939 - val_loss: 6.9263 - val_accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8906 - accuracy: 0.5967 - val_loss: 7.1780 - val_accuracy: 0.0210\n",
      "0.5967105031013489\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6275 - accuracy: 0.2976 - val_loss: 2.8966 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1783 - accuracy: 0.4465 - val_loss: 4.7973 - val_accuracy: 0.0096\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0793 - accuracy: 0.4917 - val_loss: 5.7601 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0365 - accuracy: 0.5382 - val_loss: 6.0689 - val_accuracy: 0.0596\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9893 - accuracy: 0.5645 - val_loss: 6.4288 - val_accuracy: 0.0465\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9552 - accuracy: 0.5770 - val_loss: 6.5011 - val_accuracy: 0.0482\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9313 - accuracy: 0.5914 - val_loss: 6.8553 - val_accuracy: 0.0280\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9149 - accuracy: 0.5890 - val_loss: 7.4186 - val_accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9036 - accuracy: 0.5961 - val_loss: 7.4007 - val_accuracy: 0.0175\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8968 - accuracy: 0.5947 - val_loss: 7.4742 - val_accuracy: 0.0324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5947368144989014\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 2ms/step - loss: 1.6227 - accuracy: 0.3254 - val_loss: 3.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1745 - accuracy: 0.4509 - val_loss: 4.8728 - val_accuracy: 0.0114\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0624 - accuracy: 0.5156 - val_loss: 5.8195 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0026 - accuracy: 0.5493 - val_loss: 6.2508 - val_accuracy: 0.0447\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9548 - accuracy: 0.5686 - val_loss: 6.4476 - val_accuracy: 0.0543\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9323 - accuracy: 0.5759 - val_loss: 6.5493 - val_accuracy: 0.0438\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9150 - accuracy: 0.5853 - val_loss: 6.9692 - val_accuracy: 0.0517\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9023 - accuracy: 0.5925 - val_loss: 6.9810 - val_accuracy: 0.0552\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8931 - accuracy: 0.5947 - val_loss: 7.0076 - val_accuracy: 0.0307\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8835 - accuracy: 0.5985 - val_loss: 7.1515 - val_accuracy: 0.0359\n",
      "0.5984649062156677\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6215 - accuracy: 0.3189 - val_loss: 3.1146 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1718 - accuracy: 0.4612 - val_loss: 4.8390 - val_accuracy: 0.0175\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0544 - accuracy: 0.5518 - val_loss: 5.8488 - val_accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9859 - accuracy: 0.5555 - val_loss: 6.3780 - val_accuracy: 0.0736\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9433 - accuracy: 0.5612 - val_loss: 6.5207 - val_accuracy: 0.0657\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9183 - accuracy: 0.5934 - val_loss: 6.8539 - val_accuracy: 0.0701\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9045 - accuracy: 0.5825 - val_loss: 6.9082 - val_accuracy: 0.0272\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8934 - accuracy: 0.5993 - val_loss: 7.1711 - val_accuracy: 0.0175\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8824 - accuracy: 0.6031 - val_loss: 7.3147 - val_accuracy: 0.0245\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8763 - accuracy: 0.5996 - val_loss: 7.4234 - val_accuracy: 0.0280\n",
      "0.5995613932609558\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6142 - accuracy: 0.3129 - val_loss: 3.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1738 - accuracy: 0.4379 - val_loss: 4.7681 - val_accuracy: 0.0131\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0748 - accuracy: 0.5268 - val_loss: 5.6127 - val_accuracy: 0.0307\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0333 - accuracy: 0.5548 - val_loss: 6.1351 - val_accuracy: 0.0368\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9864 - accuracy: 0.5649 - val_loss: 6.3325 - val_accuracy: 0.0894\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9472 - accuracy: 0.5713 - val_loss: 6.7056 - val_accuracy: 0.0824\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9212 - accuracy: 0.5868 - val_loss: 6.8969 - val_accuracy: 0.0202\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9097 - accuracy: 0.5969 - val_loss: 6.9120 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8952 - accuracy: 0.5971 - val_loss: 7.0944 - val_accuracy: 0.0096\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8860 - accuracy: 0.6037 - val_loss: 7.2456 - val_accuracy: 0.0245\n",
      "0.6037280559539795\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6176 - accuracy: 0.3164 - val_loss: 2.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1715 - accuracy: 0.4322 - val_loss: 4.7469 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0783 - accuracy: 0.4776 - val_loss: 5.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0436 - accuracy: 0.5191 - val_loss: 5.8783 - val_accuracy: 0.0719\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9972 - accuracy: 0.5522 - val_loss: 6.4122 - val_accuracy: 0.0675\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9517 - accuracy: 0.5711 - val_loss: 6.7247 - val_accuracy: 0.0508\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9257 - accuracy: 0.5798 - val_loss: 6.9232 - val_accuracy: 0.0657\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9083 - accuracy: 0.5923 - val_loss: 7.1643 - val_accuracy: 0.0280\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8964 - accuracy: 0.6004 - val_loss: 7.2269 - val_accuracy: 0.0359\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8869 - accuracy: 0.6046 - val_loss: 7.6230 - val_accuracy: 0.0351\n",
      "0.6046052575111389\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6317 - accuracy: 0.3127 - val_loss: 3.1643 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2015 - accuracy: 0.4305 - val_loss: 4.6875 - val_accuracy: 0.0140\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0776 - accuracy: 0.5090 - val_loss: 5.7808 - val_accuracy: 0.0070\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0141 - accuracy: 0.5570 - val_loss: 6.1589 - val_accuracy: 0.0736\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9571 - accuracy: 0.5566 - val_loss: 6.9822 - val_accuracy: 0.0351\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9291 - accuracy: 0.5750 - val_loss: 6.7173 - val_accuracy: 0.0622\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9100 - accuracy: 0.5846 - val_loss: 6.8938 - val_accuracy: 0.0324\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8955 - accuracy: 0.5925 - val_loss: 6.9854 - val_accuracy: 0.0394\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8859 - accuracy: 0.5982 - val_loss: 7.2104 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8785 - accuracy: 0.6053 - val_loss: 7.3498 - val_accuracy: 0.0289\n",
      "0.6052631735801697\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6205 - accuracy: 0.3121 - val_loss: 3.0891 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1777 - accuracy: 0.4373 - val_loss: 4.7035 - val_accuracy: 0.0114\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0784 - accuracy: 0.5039 - val_loss: 5.6435 - val_accuracy: 0.0105\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0347 - accuracy: 0.5450 - val_loss: 6.1765 - val_accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9878 - accuracy: 0.5656 - val_loss: 6.6377 - val_accuracy: 0.0175\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9508 - accuracy: 0.5807 - val_loss: 6.6427 - val_accuracy: 0.0859\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9288 - accuracy: 0.5752 - val_loss: 6.8018 - val_accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9162 - accuracy: 0.5868 - val_loss: 6.9903 - val_accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9060 - accuracy: 0.5919 - val_loss: 6.9518 - val_accuracy: 0.0228\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8940 - accuracy: 0.5921 - val_loss: 7.1311 - val_accuracy: 0.0210\n",
      "0.5921052694320679\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6215 - accuracy: 0.3112 - val_loss: 3.0196 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1684 - accuracy: 0.4741 - val_loss: 4.8708 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0511 - accuracy: 0.5294 - val_loss: 5.7199 - val_accuracy: 0.0578\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9823 - accuracy: 0.5555 - val_loss: 6.3041 - val_accuracy: 0.0780\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9407 - accuracy: 0.5662 - val_loss: 6.5043 - val_accuracy: 0.0289\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9202 - accuracy: 0.5829 - val_loss: 6.6940 - val_accuracy: 0.0473\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9033 - accuracy: 0.6007 - val_loss: 6.6221 - val_accuracy: 0.0377\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8942 - accuracy: 0.5967 - val_loss: 6.8887 - val_accuracy: 0.0377\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8856 - accuracy: 0.5987 - val_loss: 7.1203 - val_accuracy: 0.0210\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8776 - accuracy: 0.6020 - val_loss: 7.0288 - val_accuracy: 0.0149\n",
      "0.6019737124443054\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6208 - accuracy: 0.3029 - val_loss: 3.2074 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1837 - accuracy: 0.4314 - val_loss: 4.8233 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0821 - accuracy: 0.4691 - val_loss: 5.7116 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0466 - accuracy: 0.5320 - val_loss: 6.2728 - val_accuracy: 0.0079\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0061 - accuracy: 0.5658 - val_loss: 6.6410 - val_accuracy: 0.0263\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9603 - accuracy: 0.5673 - val_loss: 6.6744 - val_accuracy: 0.0421\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9319 - accuracy: 0.5809 - val_loss: 7.1017 - val_accuracy: 0.0289\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9143 - accuracy: 0.5910 - val_loss: 7.1730 - val_accuracy: 0.0447\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9027 - accuracy: 0.5934 - val_loss: 7.2705 - val_accuracy: 0.0263\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8913 - accuracy: 0.5996 - val_loss: 7.6700 - val_accuracy: 0.0307\n",
      "0.5995613932609558\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6191 - accuracy: 0.3105 - val_loss: 3.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1738 - accuracy: 0.4213 - val_loss: 4.8457 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0781 - accuracy: 0.4789 - val_loss: 5.6163 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0432 - accuracy: 0.5250 - val_loss: 6.1128 - val_accuracy: 0.0482\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0007 - accuracy: 0.5533 - val_loss: 6.5575 - val_accuracy: 0.0508\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9567 - accuracy: 0.5671 - val_loss: 6.8627 - val_accuracy: 0.0412\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9311 - accuracy: 0.5715 - val_loss: 6.8870 - val_accuracy: 0.0245\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9135 - accuracy: 0.5923 - val_loss: 7.2948 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9003 - accuracy: 0.6009 - val_loss: 7.6462 - val_accuracy: 0.0578\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8915 - accuracy: 0.5939 - val_loss: 7.7801 - val_accuracy: 0.0289\n",
      "0.5938596725463867\n",
      "if any\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6167 - accuracy: 0.3026 - val_loss: 3.0618 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1676 - accuracy: 0.4487 - val_loss: 4.8759 - val_accuracy: 0.0421\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0651 - accuracy: 0.5000 - val_loss: 5.7236 - val_accuracy: 0.0429\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0147 - accuracy: 0.5572 - val_loss: 6.2964 - val_accuracy: 0.0692\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9638 - accuracy: 0.5566 - val_loss: 6.6799 - val_accuracy: 0.0640\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9331 - accuracy: 0.5689 - val_loss: 6.7312 - val_accuracy: 0.0228\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9143 - accuracy: 0.5862 - val_loss: 7.2771 - val_accuracy: 0.0386\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9021 - accuracy: 0.5925 - val_loss: 7.1524 - val_accuracy: 0.0298\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8928 - accuracy: 0.5958 - val_loss: 7.4261 - val_accuracy: 0.0482\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8846 - accuracy: 0.6015 - val_loss: 7.3788 - val_accuracy: 0.0307\n",
      "0.6015350818634033\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6258 - accuracy: 0.3248 - val_loss: 2.9814 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1764 - accuracy: 0.4395 - val_loss: 4.9416 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0662 - accuracy: 0.5114 - val_loss: 5.5286 - val_accuracy: 0.0210\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0057 - accuracy: 0.5550 - val_loss: 5.8014 - val_accuracy: 0.0824\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9547 - accuracy: 0.5708 - val_loss: 6.1727 - val_accuracy: 0.0316\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9255 - accuracy: 0.5855 - val_loss: 6.4804 - val_accuracy: 0.0289\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9066 - accuracy: 0.5932 - val_loss: 6.5385 - val_accuracy: 0.0237\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8947 - accuracy: 0.5974 - val_loss: 6.8515 - val_accuracy: 0.0149\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8823 - accuracy: 0.5991 - val_loss: 7.0318 - val_accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8736 - accuracy: 0.6044 - val_loss: 7.1068 - val_accuracy: 0.0324\n",
      "0.6043859720230103\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6438 - accuracy: 0.2884 - val_loss: 3.0034 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2144 - accuracy: 0.4237 - val_loss: 4.8572 - val_accuracy: 0.0070\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0886 - accuracy: 0.4849 - val_loss: 5.7054 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0475 - accuracy: 0.5357 - val_loss: 6.2088 - val_accuracy: 0.0123\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0011 - accuracy: 0.5614 - val_loss: 6.4231 - val_accuracy: 0.0289\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9558 - accuracy: 0.5783 - val_loss: 6.8806 - val_accuracy: 0.0377\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9306 - accuracy: 0.5840 - val_loss: 7.0530 - val_accuracy: 0.0535\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9146 - accuracy: 0.5864 - val_loss: 7.1087 - val_accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9032 - accuracy: 0.5943 - val_loss: 7.5023 - val_accuracy: 0.0272\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8950 - accuracy: 0.6026 - val_loss: 7.4825 - val_accuracy: 0.0263\n",
      "0.6026315689086914\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6418 - accuracy: 0.2939 - val_loss: 3.1069 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2024 - accuracy: 0.4292 - val_loss: 4.8711 - val_accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0747 - accuracy: 0.5158 - val_loss: 5.8650 - val_accuracy: 0.0412\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0162 - accuracy: 0.5529 - val_loss: 6.2926 - val_accuracy: 0.0955\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9652 - accuracy: 0.5561 - val_loss: 6.6939 - val_accuracy: 0.0745\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9349 - accuracy: 0.5669 - val_loss: 6.8646 - val_accuracy: 0.0149\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9141 - accuracy: 0.5893 - val_loss: 7.0568 - val_accuracy: 0.0289\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9011 - accuracy: 0.5947 - val_loss: 7.1889 - val_accuracy: 0.0272\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8908 - accuracy: 0.5985 - val_loss: 7.0490 - val_accuracy: 0.0149\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8836 - accuracy: 0.6035 - val_loss: 7.2189 - val_accuracy: 0.0280\n",
      "0.6035087704658508\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6179 - accuracy: 0.3055 - val_loss: 3.0393 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1717 - accuracy: 0.4436 - val_loss: 4.7649 - val_accuracy: 0.0657\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0788 - accuracy: 0.4866 - val_loss: 5.6259 - val_accuracy: 0.0289\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0379 - accuracy: 0.5395 - val_loss: 6.2932 - val_accuracy: 0.0140\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9931 - accuracy: 0.5623 - val_loss: 6.6795 - val_accuracy: 0.0771\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9543 - accuracy: 0.5623 - val_loss: 7.0565 - val_accuracy: 0.0736\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9276 - accuracy: 0.5794 - val_loss: 7.2521 - val_accuracy: 0.0517\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9135 - accuracy: 0.5893 - val_loss: 7.1898 - val_accuracy: 0.0561\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8993 - accuracy: 0.6000 - val_loss: 7.4702 - val_accuracy: 0.0386\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8900 - accuracy: 0.5993 - val_loss: 7.5510 - val_accuracy: 0.0342\n",
      "0.5993421077728271\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6359 - accuracy: 0.2899 - val_loss: 3.0366 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2011 - accuracy: 0.4364 - val_loss: 4.7697 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0860 - accuracy: 0.4809 - val_loss: 5.5417 - val_accuracy: 0.0044\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0369 - accuracy: 0.5421 - val_loss: 6.2020 - val_accuracy: 0.0421\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9876 - accuracy: 0.5511 - val_loss: 6.5782 - val_accuracy: 0.0649\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9472 - accuracy: 0.5708 - val_loss: 6.7897 - val_accuracy: 0.0324\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9268 - accuracy: 0.5748 - val_loss: 6.8150 - val_accuracy: 0.0473\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9130 - accuracy: 0.5857 - val_loss: 6.9285 - val_accuracy: 0.0228\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9019 - accuracy: 0.5925 - val_loss: 7.0756 - val_accuracy: 0.0175\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8919 - accuracy: 0.5969 - val_loss: 7.3464 - val_accuracy: 0.0228\n",
      "0.5969298481941223\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6189 - accuracy: 0.3007 - val_loss: 3.0388 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1708 - accuracy: 0.4511 - val_loss: 4.7430 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0543 - accuracy: 0.5193 - val_loss: 5.7646 - val_accuracy: 0.0044\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9943 - accuracy: 0.5550 - val_loss: 6.2829 - val_accuracy: 0.0798\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9510 - accuracy: 0.5721 - val_loss: 6.4695 - val_accuracy: 0.0543\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9254 - accuracy: 0.5787 - val_loss: 6.7588 - val_accuracy: 0.0526\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9096 - accuracy: 0.5844 - val_loss: 6.7535 - val_accuracy: 0.0307\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8992 - accuracy: 0.5899 - val_loss: 6.9053 - val_accuracy: 0.0403\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8889 - accuracy: 0.5919 - val_loss: 7.0693 - val_accuracy: 0.0403\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8842 - accuracy: 0.5956 - val_loss: 7.3577 - val_accuracy: 0.0193\n",
      "0.5956140160560608\n",
      "yhn tk\n",
      "2\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhn tk\n",
      "1\n",
      "Done\n",
      "125/125 [==============================] - 0s 738us/step - loss: 2.2664 - accuracy: 0.4835\n",
      "54/54 [==============================] - 0s 711us/step - loss: 2.1558 - accuracy: 0.5003\n",
      "125/125 [==============================] - 0s 739us/step - loss: 2.2032 - accuracy: 0.4810\n",
      "54/54 [==============================] - 0s 726us/step - loss: 2.1015 - accuracy: 0.4915\n",
      "125/125 [==============================] - 0s 717us/step - loss: 2.1555 - accuracy: 0.4860\n",
      "54/54 [==============================] - 0s 720us/step - loss: 2.0521 - accuracy: 0.4974\n",
      "125/125 [==============================] - 0s 730us/step - loss: 2.2348 - accuracy: 0.4787\n",
      "54/54 [==============================] - 0s 705us/step - loss: 2.1241 - accuracy: 0.4939\n",
      "125/125 [==============================] - 0s 717us/step - loss: 2.1601 - accuracy: 0.4860\n",
      "54/54 [==============================] - 0s 736us/step - loss: 2.0489 - accuracy: 0.5044\n",
      "179/179 [==============================] - 0s 624us/step\n",
      "179/179 [==============================] - 0s 530us/step\n",
      "179/179 [==============================] - 0s 575us/step\n",
      "179/179 [==============================] - 0s 584us/step\n",
      "179/179 [==============================] - 0s 590us/step\n"
     ]
    }
   ],
   "source": [
    "# adding dense layer\n",
    "# adding dense layer\n",
    "initial_model= get_initial_model_2(dataset.shape[1]-1, 6)\n",
    "Models=[]\n",
    "val_acc=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "ind=0\n",
    "add_weights=[]\n",
    "true_values=[]\n",
    "while ind<len(samples):\n",
    "  \n",
    "  train_data=samples[ind]\n",
    "  ind=ind+1\n",
    "  \n",
    "  \n",
    "  ann_model=get_initial_model_2(dataset.shape[1]-1, 6) #same intial weights\n",
    "  ann_model.set_weights(initial_model.get_weights())\n",
    "  X_train=train_data.drop(columns=[target_variable])\n",
    "  \n",
    "\n",
    "  y_train=to_categorical(train_data[target_variable], num_classes = 6)\n",
    "    \n",
    "  ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy') # metrics=['accuracy']\n",
    "  history = ann_model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "  print(history.history['accuracy'][-1])\n",
    "\n",
    "  present=False\n",
    "  for i in range(len(Models)):\n",
    "    if (check_models(Models[i][0], ann_model.get_weights())):\n",
    "      print(\"if any\")\n",
    "      Models[i][1]=Models[i][1]+1\n",
    "      add_weights[i].append(ann_model.get_weights())\n",
    "      break;\n",
    "  if present==False:\n",
    "    add_weights.append([ann_model.get_weights()])\n",
    "    Models.append([ann_model.get_weights(), 1])\n",
    "    \n",
    "\n",
    "len(Models)   \n",
    "#here use only top 5-10 integrally private models.\n",
    "#add_weights=add_weights[top_5]\n",
    "A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "recommended_models=[]\n",
    "for i in range(len(A)):\n",
    "    recommended_models.append(add_weights[A[i]])\n",
    "#add_weights=add_weights[A]\n",
    "\n",
    "# Now trying to generate Streaming settings for the dataset\n",
    "# lets find the outputs from all the \n",
    "mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss = epsilon_mean_recommendation_2(recommended_models, data_init)\n",
    "\n",
    "y_pred_total = []\n",
    "y_pred_uncertainty_total = []\n",
    "\n",
    "y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_init.copy())\n",
    "\n",
    "y_pred_total.append(y_pred)\n",
    "y_pred_uncertainty_total.append(y_pred_uncertainty)\n",
    "\n",
    "true_values.append(data_init.copy()[target_variable])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47f1b97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d2130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 586us/step\n",
      "179/179 [==============================] - 0s 567us/step\n",
      "179/179 [==============================] - 0s 536us/step\n",
      "179/179 [==============================] - 0s 548us/step\n",
      "179/179 [==============================] - 0s 540us/step\n",
      "36/36 [==============================] - 0s 646us/step\n",
      "36/36 [==============================] - 0s 625us/step\n",
      "36/36 [==============================] - 0s 630us/step\n",
      "36/36 [==============================] - 0s 622us/step\n",
      "36/36 [==============================] - 0s 638us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 602us/step\n",
      "179/179 [==============================] - 0s 560us/step\n",
      "179/179 [==============================] - 0s 550us/step\n",
      "179/179 [==============================] - 0s 570us/step\n",
      "179/179 [==============================] - 0s 586us/step\n",
      "36/36 [==============================] - 0s 654us/step\n",
      "36/36 [==============================] - 0s 631us/step\n",
      "36/36 [==============================] - 0s 617us/step\n",
      "36/36 [==============================] - 0s 645us/step\n",
      "36/36 [==============================] - 0s 639us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 597us/step\n",
      "179/179 [==============================] - 0s 581us/step\n",
      "179/179 [==============================] - 0s 579us/step\n",
      "179/179 [==============================] - 0s 573us/step\n",
      "179/179 [==============================] - 0s 553us/step\n",
      "36/36 [==============================] - 0s 677us/step\n",
      "36/36 [==============================] - 0s 629us/step\n",
      "36/36 [==============================] - 0s 658us/step\n",
      "36/36 [==============================] - 0s 610us/step\n",
      "36/36 [==============================] - 0s 591us/step\n",
      "1140\n",
      "drift has been detected models must be retrained\n",
      "some intersection\n",
      "finished\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 2ms/step - loss: 1.6414 - accuracy: 0.3129 - val_loss: 3.1828 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1973 - accuracy: 0.4215 - val_loss: 5.0136 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0844 - accuracy: 0.4844 - val_loss: 5.7853 - val_accuracy: 0.0079\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0486 - accuracy: 0.5193 - val_loss: 6.0920 - val_accuracy: 0.0456\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0158 - accuracy: 0.5535 - val_loss: 6.6475 - val_accuracy: 0.0245\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9758 - accuracy: 0.5735 - val_loss: 6.9479 - val_accuracy: 0.0377\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9480 - accuracy: 0.5857 - val_loss: 7.0865 - val_accuracy: 0.0280\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9292 - accuracy: 0.5895 - val_loss: 7.2441 - val_accuracy: 0.0394\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9166 - accuracy: 0.5868 - val_loss: 7.4620 - val_accuracy: 0.0421\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9033 - accuracy: 0.5954 - val_loss: 7.6980 - val_accuracy: 0.0491\n",
      "0.5953947305679321\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6345 - accuracy: 0.2998 - val_loss: 3.0217 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1943 - accuracy: 0.4208 - val_loss: 4.7369 - val_accuracy: 0.0105\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0849 - accuracy: 0.4781 - val_loss: 5.7567 - val_accuracy: 0.0035\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0524 - accuracy: 0.5178 - val_loss: 6.2910 - val_accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0144 - accuracy: 0.5572 - val_loss: 6.4831 - val_accuracy: 0.0105\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9696 - accuracy: 0.5825 - val_loss: 6.8169 - val_accuracy: 0.0175\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9407 - accuracy: 0.5829 - val_loss: 6.8839 - val_accuracy: 0.0473\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9226 - accuracy: 0.5846 - val_loss: 7.2643 - val_accuracy: 0.0280\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9094 - accuracy: 0.5925 - val_loss: 7.5328 - val_accuracy: 0.0429\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9008 - accuracy: 0.5996 - val_loss: 7.7180 - val_accuracy: 0.0316\n",
      "0.5995613932609558\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6275 - accuracy: 0.3110 - val_loss: 3.0319 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1947 - accuracy: 0.4346 - val_loss: 4.7374 - val_accuracy: 0.0026\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0722 - accuracy: 0.5035 - val_loss: 5.4824 - val_accuracy: 0.0482\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0088 - accuracy: 0.5450 - val_loss: 6.0110 - val_accuracy: 0.0465\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9517 - accuracy: 0.5708 - val_loss: 6.3860 - val_accuracy: 0.0552\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9253 - accuracy: 0.5754 - val_loss: 6.3204 - val_accuracy: 0.0324\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9079 - accuracy: 0.5958 - val_loss: 6.4912 - val_accuracy: 0.0272\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8976 - accuracy: 0.5899 - val_loss: 6.7590 - val_accuracy: 0.0237\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8856 - accuracy: 0.6013 - val_loss: 6.6633 - val_accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8785 - accuracy: 0.5987 - val_loss: 7.0068 - val_accuracy: 0.0167\n",
      "0.5986841917037964\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6364 - accuracy: 0.3055 - val_loss: 3.0902 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1966 - accuracy: 0.4265 - val_loss: 4.7682 - val_accuracy: 0.0254\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0833 - accuracy: 0.4809 - val_loss: 5.7100 - val_accuracy: 0.0079\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0464 - accuracy: 0.5270 - val_loss: 6.1209 - val_accuracy: 0.0771\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0088 - accuracy: 0.5410 - val_loss: 6.5526 - val_accuracy: 0.0386\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9679 - accuracy: 0.5570 - val_loss: 6.8361 - val_accuracy: 0.0359\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9434 - accuracy: 0.5739 - val_loss: 6.8596 - val_accuracy: 0.0482\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9239 - accuracy: 0.5886 - val_loss: 7.1217 - val_accuracy: 0.0394\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9124 - accuracy: 0.5879 - val_loss: 7.5223 - val_accuracy: 0.0482\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9026 - accuracy: 0.5914 - val_loss: 7.5249 - val_accuracy: 0.0438\n",
      "0.5914473533630371\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6465 - accuracy: 0.2864 - val_loss: 2.9511 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2075 - accuracy: 0.4219 - val_loss: 4.7312 - val_accuracy: 0.0158\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0864 - accuracy: 0.4739 - val_loss: 5.6302 - val_accuracy: 0.0079\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0548 - accuracy: 0.4947 - val_loss: 6.1732 - val_accuracy: 0.0114\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0210 - accuracy: 0.5406 - val_loss: 6.5390 - val_accuracy: 0.0508\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9828 - accuracy: 0.5651 - val_loss: 6.7861 - val_accuracy: 0.0587\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9520 - accuracy: 0.5822 - val_loss: 6.9878 - val_accuracy: 0.0596\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9324 - accuracy: 0.5860 - val_loss: 7.1223 - val_accuracy: 0.0640\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9174 - accuracy: 0.5899 - val_loss: 7.4066 - val_accuracy: 0.0377\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9049 - accuracy: 0.5939 - val_loss: 7.4443 - val_accuracy: 0.0421\n",
      "0.5938596725463867\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6310 - accuracy: 0.3079 - val_loss: 3.0218 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1912 - accuracy: 0.4204 - val_loss: 4.7219 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0887 - accuracy: 0.4827 - val_loss: 5.5031 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0583 - accuracy: 0.5149 - val_loss: 5.8197 - val_accuracy: 0.0421\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0281 - accuracy: 0.5452 - val_loss: 6.1441 - val_accuracy: 0.0105\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9920 - accuracy: 0.5695 - val_loss: 6.4653 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9567 - accuracy: 0.5833 - val_loss: 6.6074 - val_accuracy: 0.0175\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9333 - accuracy: 0.5912 - val_loss: 6.8432 - val_accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9185 - accuracy: 0.5912 - val_loss: 7.1442 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9078 - accuracy: 0.5906 - val_loss: 7.4304 - val_accuracy: 0.0263\n",
      "0.5905701518058777\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6053 - accuracy: 0.3099 - val_loss: 3.0559 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1637 - accuracy: 0.4450 - val_loss: 4.8594 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0758 - accuracy: 0.4838 - val_loss: 5.6285 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0396 - accuracy: 0.5496 - val_loss: 6.2404 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9953 - accuracy: 0.5616 - val_loss: 6.6550 - val_accuracy: 0.0228\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9558 - accuracy: 0.5761 - val_loss: 6.8872 - val_accuracy: 0.0517\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9306 - accuracy: 0.5844 - val_loss: 6.9682 - val_accuracy: 0.0631\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9145 - accuracy: 0.5860 - val_loss: 6.9494 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8987 - accuracy: 0.6002 - val_loss: 7.1762 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8866 - accuracy: 0.6018 - val_loss: 7.1660 - val_accuracy: 0.0289\n",
      "0.601754367351532\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6231 - accuracy: 0.2914 - val_loss: 3.0826 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1853 - accuracy: 0.4463 - val_loss: 4.8474 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0772 - accuracy: 0.5011 - val_loss: 5.7154 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0282 - accuracy: 0.5458 - val_loss: 6.2024 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9829 - accuracy: 0.5695 - val_loss: 6.1151 - val_accuracy: 0.0482\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9475 - accuracy: 0.5783 - val_loss: 6.2809 - val_accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9239 - accuracy: 0.5857 - val_loss: 6.7572 - val_accuracy: 0.0324\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9094 - accuracy: 0.5917 - val_loss: 6.6984 - val_accuracy: 0.0245\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8974 - accuracy: 0.5934 - val_loss: 6.7819 - val_accuracy: 0.0254\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8892 - accuracy: 0.5987 - val_loss: 6.9664 - val_accuracy: 0.0228\n",
      "0.5986841917037964\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6119 - accuracy: 0.3088 - val_loss: 3.1934 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1667 - accuracy: 0.4309 - val_loss: 4.8279 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0748 - accuracy: 0.5182 - val_loss: 5.7334 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0361 - accuracy: 0.5531 - val_loss: 6.1278 - val_accuracy: 0.0719\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9881 - accuracy: 0.5594 - val_loss: 6.5116 - val_accuracy: 0.0938\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9476 - accuracy: 0.5700 - val_loss: 6.7898 - val_accuracy: 0.0649\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9261 - accuracy: 0.5787 - val_loss: 6.9030 - val_accuracy: 0.0859\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9113 - accuracy: 0.5827 - val_loss: 7.1875 - val_accuracy: 0.0517\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9009 - accuracy: 0.5890 - val_loss: 7.2075 - val_accuracy: 0.0429\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8918 - accuracy: 0.6009 - val_loss: 7.3146 - val_accuracy: 0.0272\n",
      "0.6008771657943726\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6066 - accuracy: 0.3061 - val_loss: 3.1310 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1585 - accuracy: 0.4572 - val_loss: 4.8276 - val_accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0585 - accuracy: 0.5226 - val_loss: 5.4734 - val_accuracy: 0.1104\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9999 - accuracy: 0.5491 - val_loss: 6.1534 - val_accuracy: 0.0692\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9479 - accuracy: 0.5737 - val_loss: 6.5218 - val_accuracy: 0.0543\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9240 - accuracy: 0.5752 - val_loss: 6.7137 - val_accuracy: 0.0316\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9062 - accuracy: 0.5901 - val_loss: 6.8805 - val_accuracy: 0.0552\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8941 - accuracy: 0.5914 - val_loss: 6.8872 - val_accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8857 - accuracy: 0.5954 - val_loss: 7.0314 - val_accuracy: 0.0500\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8739 - accuracy: 0.6031 - val_loss: 7.2355 - val_accuracy: 0.0465\n",
      "0.6030701994895935\n",
      "33\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6145 - accuracy: 0.3057 - val_loss: 2.9964 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1782 - accuracy: 0.4344 - val_loss: 4.9426 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0834 - accuracy: 0.4783 - val_loss: 5.3968 - val_accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0490 - accuracy: 0.5261 - val_loss: 6.0322 - val_accuracy: 0.0079\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0159 - accuracy: 0.5511 - val_loss: 6.2803 - val_accuracy: 0.0684\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9712 - accuracy: 0.5675 - val_loss: 6.4858 - val_accuracy: 0.0727\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9386 - accuracy: 0.5787 - val_loss: 6.8577 - val_accuracy: 0.0324\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9179 - accuracy: 0.5886 - val_loss: 6.9319 - val_accuracy: 0.0316\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9049 - accuracy: 0.5954 - val_loss: 6.9537 - val_accuracy: 0.0316\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8958 - accuracy: 0.5993 - val_loss: 7.4488 - val_accuracy: 0.0342\n",
      "0.5993421077728271\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6390 - accuracy: 0.3110 - val_loss: 3.0995 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2153 - accuracy: 0.4259 - val_loss: 4.7028 - val_accuracy: 0.0140\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0871 - accuracy: 0.5121 - val_loss: 5.5665 - val_accuracy: 0.0798\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0254 - accuracy: 0.5572 - val_loss: 6.1373 - val_accuracy: 0.0815\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9681 - accuracy: 0.5509 - val_loss: 6.6505 - val_accuracy: 0.0657\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9349 - accuracy: 0.5689 - val_loss: 6.9260 - val_accuracy: 0.0421\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9130 - accuracy: 0.5862 - val_loss: 7.0344 - val_accuracy: 0.0587\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9019 - accuracy: 0.5919 - val_loss: 7.2525 - val_accuracy: 0.0228\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8925 - accuracy: 0.5921 - val_loss: 7.2746 - val_accuracy: 0.0158\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8832 - accuracy: 0.5982 - val_loss: 7.4457 - val_accuracy: 0.0228\n",
      "0.5982456207275391\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6527 - accuracy: 0.2875 - val_loss: 2.9966 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2342 - accuracy: 0.4213 - val_loss: 4.7879 - val_accuracy: 0.0079\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0980 - accuracy: 0.4537 - val_loss: 5.6237 - val_accuracy: 0.0026\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0605 - accuracy: 0.5066 - val_loss: 6.0528 - val_accuracy: 0.0140\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0333 - accuracy: 0.5395 - val_loss: 6.3381 - val_accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9928 - accuracy: 0.5651 - val_loss: 6.5396 - val_accuracy: 0.0280\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9568 - accuracy: 0.5743 - val_loss: 6.5905 - val_accuracy: 0.0333\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9358 - accuracy: 0.5814 - val_loss: 6.9953 - val_accuracy: 0.0403\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9252 - accuracy: 0.5833 - val_loss: 6.8668 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9146 - accuracy: 0.5895 - val_loss: 7.3479 - val_accuracy: 0.0316\n",
      "0.5894736647605896\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6400 - accuracy: 0.2954 - val_loss: 3.0321 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1964 - accuracy: 0.4592 - val_loss: 5.0253 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0688 - accuracy: 0.5151 - val_loss: 5.6873 - val_accuracy: 0.0745\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0131 - accuracy: 0.5478 - val_loss: 6.6399 - val_accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9599 - accuracy: 0.5636 - val_loss: 6.5925 - val_accuracy: 0.0833\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9279 - accuracy: 0.5831 - val_loss: 7.1712 - val_accuracy: 0.0377\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9142 - accuracy: 0.5827 - val_loss: 7.1975 - val_accuracy: 0.0447\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8997 - accuracy: 0.5974 - val_loss: 7.2403 - val_accuracy: 0.0429\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8899 - accuracy: 0.5985 - val_loss: 7.1905 - val_accuracy: 0.0316\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8827 - accuracy: 0.5998 - val_loss: 7.4134 - val_accuracy: 0.0272\n",
      "0.5997806787490845\n",
      "if any\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6379 - accuracy: 0.2893 - val_loss: 3.0396 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1968 - accuracy: 0.4342 - val_loss: 5.0674 - val_accuracy: 0.0114\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0601 - accuracy: 0.4934 - val_loss: 5.7677 - val_accuracy: 0.0859\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9944 - accuracy: 0.5507 - val_loss: 6.6508 - val_accuracy: 0.0202\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9443 - accuracy: 0.5737 - val_loss: 6.7028 - val_accuracy: 0.0745\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9223 - accuracy: 0.5831 - val_loss: 7.2510 - val_accuracy: 0.0263\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9094 - accuracy: 0.5833 - val_loss: 7.1113 - val_accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8953 - accuracy: 0.5941 - val_loss: 7.3682 - val_accuracy: 0.0517\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8859 - accuracy: 0.5943 - val_loss: 7.4819 - val_accuracy: 0.0368\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8798 - accuracy: 0.6007 - val_loss: 7.5457 - val_accuracy: 0.0403\n",
      "0.6006578803062439\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6279 - accuracy: 0.2932 - val_loss: 2.9748 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1978 - accuracy: 0.4316 - val_loss: 4.6077 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0757 - accuracy: 0.5077 - val_loss: 5.4638 - val_accuracy: 0.0149\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0062 - accuracy: 0.5404 - val_loss: 5.9663 - val_accuracy: 0.0570\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9465 - accuracy: 0.5614 - val_loss: 6.5833 - val_accuracy: 0.0622\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9164 - accuracy: 0.5809 - val_loss: 6.5866 - val_accuracy: 0.0456\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9016 - accuracy: 0.5860 - val_loss: 6.7813 - val_accuracy: 0.0500\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8923 - accuracy: 0.5967 - val_loss: 6.8868 - val_accuracy: 0.0202\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8808 - accuracy: 0.5958 - val_loss: 7.0970 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8768 - accuracy: 0.5998 - val_loss: 7.3937 - val_accuracy: 0.0131\n",
      "0.5997806787490845\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6349 - accuracy: 0.3046 - val_loss: 3.1150 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2048 - accuracy: 0.4336 - val_loss: 4.7954 - val_accuracy: 0.0061\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0901 - accuracy: 0.4936 - val_loss: 5.5554 - val_accuracy: 0.0079\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0454 - accuracy: 0.5292 - val_loss: 5.9920 - val_accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9988 - accuracy: 0.5542 - val_loss: 6.1487 - val_accuracy: 0.0202\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9652 - accuracy: 0.5757 - val_loss: 6.3773 - val_accuracy: 0.0245\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9419 - accuracy: 0.5761 - val_loss: 6.5117 - val_accuracy: 0.0491\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9226 - accuracy: 0.5868 - val_loss: 6.7476 - val_accuracy: 0.0377\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9120 - accuracy: 0.5906 - val_loss: 6.7108 - val_accuracy: 0.0368\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8999 - accuracy: 0.5974 - val_loss: 6.9812 - val_accuracy: 0.0298\n",
      "0.5973684191703796\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6343 - accuracy: 0.3118 - val_loss: 3.1719 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1962 - accuracy: 0.4254 - val_loss: 4.8532 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0707 - accuracy: 0.5239 - val_loss: 5.8382 - val_accuracy: 0.0465\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0083 - accuracy: 0.5658 - val_loss: 6.3613 - val_accuracy: 0.0868\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9543 - accuracy: 0.5612 - val_loss: 6.7537 - val_accuracy: 0.0640\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9265 - accuracy: 0.5825 - val_loss: 7.0073 - val_accuracy: 0.0561\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9100 - accuracy: 0.5868 - val_loss: 7.1598 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8963 - accuracy: 0.5925 - val_loss: 7.2197 - val_accuracy: 0.0202\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8870 - accuracy: 0.5976 - val_loss: 7.3687 - val_accuracy: 0.0228\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8808 - accuracy: 0.5974 - val_loss: 7.4512 - val_accuracy: 0.0237\n",
      "0.5973684191703796\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 2ms/step - loss: 1.6352 - accuracy: 0.3048 - val_loss: 3.1222 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1912 - accuracy: 0.4366 - val_loss: 4.8238 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0768 - accuracy: 0.5173 - val_loss: 5.6647 - val_accuracy: 0.0447\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0262 - accuracy: 0.5428 - val_loss: 6.3073 - val_accuracy: 0.0482\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9699 - accuracy: 0.5636 - val_loss: 6.7253 - val_accuracy: 0.0517\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9339 - accuracy: 0.5737 - val_loss: 6.8415 - val_accuracy: 0.0649\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9128 - accuracy: 0.5871 - val_loss: 6.9750 - val_accuracy: 0.0473\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8994 - accuracy: 0.5928 - val_loss: 7.1749 - val_accuracy: 0.0298\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8931 - accuracy: 0.5989 - val_loss: 7.2005 - val_accuracy: 0.0394\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8807 - accuracy: 0.6004 - val_loss: 7.3598 - val_accuracy: 0.0403\n",
      "0.6004385948181152\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6246 - accuracy: 0.3086 - val_loss: 2.9959 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1828 - accuracy: 0.4292 - val_loss: 4.7645 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0827 - accuracy: 0.4658 - val_loss: 5.4463 - val_accuracy: 0.0026\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0493 - accuracy: 0.5235 - val_loss: 5.9037 - val_accuracy: 0.0920\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0113 - accuracy: 0.5673 - val_loss: 6.4035 - val_accuracy: 0.0500\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9633 - accuracy: 0.5697 - val_loss: 6.7322 - val_accuracy: 0.0491\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9313 - accuracy: 0.5774 - val_loss: 6.9172 - val_accuracy: 0.0342\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9142 - accuracy: 0.5941 - val_loss: 6.9676 - val_accuracy: 0.0421\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8989 - accuracy: 0.5934 - val_loss: 7.2806 - val_accuracy: 0.0526\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8902 - accuracy: 0.6022 - val_loss: 7.3084 - val_accuracy: 0.0447\n",
      "0.6021929979324341\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6384 - accuracy: 0.3090 - val_loss: 3.0648 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2012 - accuracy: 0.4357 - val_loss: 4.8462 - val_accuracy: 0.0175\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0748 - accuracy: 0.5143 - val_loss: 5.9249 - val_accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0196 - accuracy: 0.5465 - val_loss: 6.6031 - val_accuracy: 0.0219\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9703 - accuracy: 0.5658 - val_loss: 6.6940 - val_accuracy: 0.0754\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9362 - accuracy: 0.5706 - val_loss: 6.9185 - val_accuracy: 0.0482\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9179 - accuracy: 0.5906 - val_loss: 7.2445 - val_accuracy: 0.0289\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9033 - accuracy: 0.5965 - val_loss: 7.4191 - val_accuracy: 0.0280\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8950 - accuracy: 0.5989 - val_loss: 7.2511 - val_accuracy: 0.0263\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8867 - accuracy: 0.5974 - val_loss: 7.4581 - val_accuracy: 0.0429\n",
      "0.5973684191703796\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6429 - accuracy: 0.2888 - val_loss: 3.0937 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2094 - accuracy: 0.4331 - val_loss: 4.8575 - val_accuracy: 0.0044\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0844 - accuracy: 0.4794 - val_loss: 5.8711 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0515 - accuracy: 0.5140 - val_loss: 6.1747 - val_accuracy: 0.0263\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0154 - accuracy: 0.5461 - val_loss: 6.6783 - val_accuracy: 0.0517\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9745 - accuracy: 0.5588 - val_loss: 6.9342 - val_accuracy: 0.0237\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9436 - accuracy: 0.5739 - val_loss: 6.8282 - val_accuracy: 0.0280\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9266 - accuracy: 0.5866 - val_loss: 7.1697 - val_accuracy: 0.0307\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9132 - accuracy: 0.5895 - val_loss: 7.4099 - val_accuracy: 0.0280\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9008 - accuracy: 0.5939 - val_loss: 7.6269 - val_accuracy: 0.0316\n",
      "0.5938596725463867\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6328 - accuracy: 0.3035 - val_loss: 3.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2022 - accuracy: 0.4261 - val_loss: 4.6707 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0869 - accuracy: 0.4816 - val_loss: 5.6916 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0430 - accuracy: 0.5246 - val_loss: 6.1069 - val_accuracy: 0.0289\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9936 - accuracy: 0.5621 - val_loss: 6.4685 - val_accuracy: 0.0613\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9491 - accuracy: 0.5706 - val_loss: 6.6690 - val_accuracy: 0.0465\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9253 - accuracy: 0.5862 - val_loss: 6.6139 - val_accuracy: 0.0447\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9078 - accuracy: 0.5849 - val_loss: 6.7107 - val_accuracy: 0.0517\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8977 - accuracy: 0.5917 - val_loss: 6.9542 - val_accuracy: 0.0473\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8894 - accuracy: 0.6018 - val_loss: 6.9505 - val_accuracy: 0.0386\n",
      "0.601754367351532\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6317 - accuracy: 0.3042 - val_loss: 3.0717 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1910 - accuracy: 0.4287 - val_loss: 4.7681 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0770 - accuracy: 0.5072 - val_loss: 5.7653 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0197 - accuracy: 0.5445 - val_loss: 6.1156 - val_accuracy: 0.1008\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9700 - accuracy: 0.5610 - val_loss: 6.6451 - val_accuracy: 0.0710\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9377 - accuracy: 0.5763 - val_loss: 6.9206 - val_accuracy: 0.0465\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9180 - accuracy: 0.5897 - val_loss: 6.7772 - val_accuracy: 0.0368\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9072 - accuracy: 0.5895 - val_loss: 7.0628 - val_accuracy: 0.0377\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8978 - accuracy: 0.5928 - val_loss: 7.0505 - val_accuracy: 0.0351\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8883 - accuracy: 0.5928 - val_loss: 7.0682 - val_accuracy: 0.0359\n",
      "0.5927631855010986\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6435 - accuracy: 0.3079 - val_loss: 2.9379 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2169 - accuracy: 0.4322 - val_loss: 4.5753 - val_accuracy: 0.0578\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0890 - accuracy: 0.4860 - val_loss: 5.5503 - val_accuracy: 0.0237\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0512 - accuracy: 0.5169 - val_loss: 6.1074 - val_accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0146 - accuracy: 0.5450 - val_loss: 6.3368 - val_accuracy: 0.0053\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9757 - accuracy: 0.5708 - val_loss: 6.5965 - val_accuracy: 0.0228\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9495 - accuracy: 0.5811 - val_loss: 6.4393 - val_accuracy: 0.0254\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9322 - accuracy: 0.5866 - val_loss: 6.8036 - val_accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9200 - accuracy: 0.5879 - val_loss: 7.0415 - val_accuracy: 0.0245\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9097 - accuracy: 0.5908 - val_loss: 7.3996 - val_accuracy: 0.0210\n",
      "0.5907894968986511\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6341 - accuracy: 0.3015 - val_loss: 2.9840 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2064 - accuracy: 0.4270 - val_loss: 4.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0872 - accuracy: 0.4965 - val_loss: 5.5297 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0446 - accuracy: 0.5300 - val_loss: 6.1000 - val_accuracy: 8.7642e-04\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0006 - accuracy: 0.5607 - val_loss: 6.3335 - val_accuracy: 0.0175\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9603 - accuracy: 0.5838 - val_loss: 6.5512 - val_accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9306 - accuracy: 0.5842 - val_loss: 6.7889 - val_accuracy: 0.0202\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9140 - accuracy: 0.5936 - val_loss: 6.9214 - val_accuracy: 0.0210\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9011 - accuracy: 0.6013 - val_loss: 7.0139 - val_accuracy: 0.0245\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8907 - accuracy: 0.5958 - val_loss: 7.2487 - val_accuracy: 0.0140\n",
      "0.5958333611488342\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6334 - accuracy: 0.2991 - val_loss: 3.1853 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2035 - accuracy: 0.4382 - val_loss: 5.0454 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0890 - accuracy: 0.4844 - val_loss: 5.8718 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0534 - accuracy: 0.5118 - val_loss: 6.3592 - val_accuracy: 8.7642e-04\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0153 - accuracy: 0.5491 - val_loss: 6.8566 - val_accuracy: 0.0018\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9699 - accuracy: 0.5779 - val_loss: 6.8465 - val_accuracy: 0.0316\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9371 - accuracy: 0.5811 - val_loss: 7.0796 - val_accuracy: 0.0526\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9233 - accuracy: 0.5862 - val_loss: 7.4365 - val_accuracy: 0.0456\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9086 - accuracy: 0.5895 - val_loss: 7.5483 - val_accuracy: 0.0447\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8981 - accuracy: 0.5954 - val_loss: 7.7674 - val_accuracy: 0.0158\n",
      "0.5953947305679321\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6113 - accuracy: 0.2985 - val_loss: 3.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1577 - accuracy: 0.4623 - val_loss: 4.8659 - val_accuracy: 0.0070\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0478 - accuracy: 0.5417 - val_loss: 5.7779 - val_accuracy: 0.0622\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9833 - accuracy: 0.5621 - val_loss: 6.2417 - val_accuracy: 0.0745\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9427 - accuracy: 0.5754 - val_loss: 6.4729 - val_accuracy: 0.0465\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9212 - accuracy: 0.5781 - val_loss: 6.8435 - val_accuracy: 0.0237\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9071 - accuracy: 0.5882 - val_loss: 6.7836 - val_accuracy: 0.0491\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8972 - accuracy: 0.5871 - val_loss: 7.0391 - val_accuracy: 0.0254\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8883 - accuracy: 0.5930 - val_loss: 7.0079 - val_accuracy: 0.0210\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8796 - accuracy: 0.6020 - val_loss: 7.2083 - val_accuracy: 0.0351\n",
      "0.6019737124443054\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6361 - accuracy: 0.2921 - val_loss: 3.0510 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2035 - accuracy: 0.4305 - val_loss: 4.8970 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0751 - accuracy: 0.5145 - val_loss: 5.8546 - val_accuracy: 0.0403\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0133 - accuracy: 0.5542 - val_loss: 6.2928 - val_accuracy: 0.0824\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9623 - accuracy: 0.5594 - val_loss: 6.5424 - val_accuracy: 0.0324\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9304 - accuracy: 0.5787 - val_loss: 6.9008 - val_accuracy: 0.0482\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9129 - accuracy: 0.5844 - val_loss: 7.0387 - val_accuracy: 0.0289\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9010 - accuracy: 0.5860 - val_loss: 7.1776 - val_accuracy: 0.0307\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8916 - accuracy: 0.5934 - val_loss: 7.1142 - val_accuracy: 0.0359\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8838 - accuracy: 0.6009 - val_loss: 7.1544 - val_accuracy: 0.0280\n",
      "0.6008771657943726\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6258 - accuracy: 0.3072 - val_loss: 3.1528 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1798 - accuracy: 0.4419 - val_loss: 4.8243 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0812 - accuracy: 0.4864 - val_loss: 5.6322 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0417 - accuracy: 0.5393 - val_loss: 6.1766 - val_accuracy: 0.0053\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0014 - accuracy: 0.5643 - val_loss: 6.5883 - val_accuracy: 0.0053\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9685 - accuracy: 0.5796 - val_loss: 6.5858 - val_accuracy: 0.0123\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9440 - accuracy: 0.5846 - val_loss: 6.5681 - val_accuracy: 0.0158\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9291 - accuracy: 0.5884 - val_loss: 6.6328 - val_accuracy: 0.0219\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9156 - accuracy: 0.5928 - val_loss: 6.6707 - val_accuracy: 0.0228\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9063 - accuracy: 0.5919 - val_loss: 6.9471 - val_accuracy: 0.0193\n",
      "0.5918859839439392\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6372 - accuracy: 0.2879 - val_loss: 2.9663 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2064 - accuracy: 0.4232 - val_loss: 4.8532 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0871 - accuracy: 0.4772 - val_loss: 5.5565 - val_accuracy: 0.0035\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0456 - accuracy: 0.5327 - val_loss: 6.1326 - val_accuracy: 0.0088\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9963 - accuracy: 0.5612 - val_loss: 6.5128 - val_accuracy: 0.0280\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9538 - accuracy: 0.5783 - val_loss: 6.7714 - val_accuracy: 0.0727\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9300 - accuracy: 0.5811 - val_loss: 6.8924 - val_accuracy: 0.0403\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9159 - accuracy: 0.5860 - val_loss: 7.1208 - val_accuracy: 0.0289\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9035 - accuracy: 0.5873 - val_loss: 7.5627 - val_accuracy: 0.0465\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8983 - accuracy: 0.5934 - val_loss: 7.4321 - val_accuracy: 0.0482\n",
      "0.5934210419654846\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6275 - accuracy: 0.3202 - val_loss: 3.0829 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1815 - accuracy: 0.4739 - val_loss: 4.8993 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0628 - accuracy: 0.5292 - val_loss: 5.7612 - val_accuracy: 0.0026\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9999 - accuracy: 0.5465 - val_loss: 6.2636 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9509 - accuracy: 0.5592 - val_loss: 6.7533 - val_accuracy: 0.0526\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9233 - accuracy: 0.5842 - val_loss: 7.0817 - val_accuracy: 0.0307\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9086 - accuracy: 0.5893 - val_loss: 6.9014 - val_accuracy: 0.0394\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8944 - accuracy: 0.5943 - val_loss: 7.2276 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8844 - accuracy: 0.5993 - val_loss: 7.5684 - val_accuracy: 0.0368\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8785 - accuracy: 0.6059 - val_loss: 7.3678 - val_accuracy: 0.0342\n",
      "0.6059210300445557\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6120 - accuracy: 0.3088 - val_loss: 3.1343 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1709 - accuracy: 0.4362 - val_loss: 4.8946 - val_accuracy: 0.0026\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0742 - accuracy: 0.5018 - val_loss: 5.7522 - val_accuracy: 0.0070\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0332 - accuracy: 0.5581 - val_loss: 6.0111 - val_accuracy: 0.0561\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9888 - accuracy: 0.5535 - val_loss: 6.5995 - val_accuracy: 0.0394\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9481 - accuracy: 0.5610 - val_loss: 6.7081 - val_accuracy: 0.0272\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9230 - accuracy: 0.5851 - val_loss: 6.9183 - val_accuracy: 0.0745\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9085 - accuracy: 0.5857 - val_loss: 7.0297 - val_accuracy: 0.0254\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8982 - accuracy: 0.5910 - val_loss: 7.2147 - val_accuracy: 0.0245\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8866 - accuracy: 0.6004 - val_loss: 7.1979 - val_accuracy: 0.0202\n",
      "0.6004385948181152\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6367 - accuracy: 0.2963 - val_loss: 3.0178 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1966 - accuracy: 0.4268 - val_loss: 4.7936 - val_accuracy: 0.0079\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0816 - accuracy: 0.4868 - val_loss: 5.5605 - val_accuracy: 0.0096\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0438 - accuracy: 0.5204 - val_loss: 6.1839 - val_accuracy: 0.0158\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9981 - accuracy: 0.5467 - val_loss: 6.4173 - val_accuracy: 0.0771\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9556 - accuracy: 0.5654 - val_loss: 6.5791 - val_accuracy: 0.0543\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9312 - accuracy: 0.5825 - val_loss: 7.2391 - val_accuracy: 0.0438\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9162 - accuracy: 0.5855 - val_loss: 7.1699 - val_accuracy: 0.0465\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9050 - accuracy: 0.5928 - val_loss: 7.3069 - val_accuracy: 0.0447\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8958 - accuracy: 0.5950 - val_loss: 7.2278 - val_accuracy: 0.0473\n",
      "0.5949561595916748\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6204 - accuracy: 0.3039 - val_loss: 2.9784 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1765 - accuracy: 0.4289 - val_loss: 4.6899 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0841 - accuracy: 0.4647 - val_loss: 5.5345 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0547 - accuracy: 0.5221 - val_loss: 6.0178 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0196 - accuracy: 0.5421 - val_loss: 6.4127 - val_accuracy: 0.0123\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9773 - accuracy: 0.5757 - val_loss: 6.6806 - val_accuracy: 0.0202\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9428 - accuracy: 0.5820 - val_loss: 6.8544 - val_accuracy: 0.0316\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9245 - accuracy: 0.5860 - val_loss: 7.0083 - val_accuracy: 0.0491\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9108 - accuracy: 0.5921 - val_loss: 7.4119 - val_accuracy: 0.0333\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9006 - accuracy: 0.5945 - val_loss: 7.6022 - val_accuracy: 0.0447\n",
      "0.5945175290107727\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6205 - accuracy: 0.2930 - val_loss: 2.9982 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1785 - accuracy: 0.4261 - val_loss: 4.6539 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0811 - accuracy: 0.4974 - val_loss: 5.5026 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0315 - accuracy: 0.5399 - val_loss: 5.8034 - val_accuracy: 0.0491\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9776 - accuracy: 0.5654 - val_loss: 6.2931 - val_accuracy: 0.0815\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9419 - accuracy: 0.5645 - val_loss: 6.5579 - val_accuracy: 0.0561\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9203 - accuracy: 0.5877 - val_loss: 6.8003 - val_accuracy: 0.0272\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9091 - accuracy: 0.5921 - val_loss: 6.6111 - val_accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8975 - accuracy: 0.5954 - val_loss: 6.7555 - val_accuracy: 0.0351\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8914 - accuracy: 0.5982 - val_loss: 6.8659 - val_accuracy: 0.0333\n",
      "0.5982456207275391\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6325 - accuracy: 0.3086 - val_loss: 3.1646 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2036 - accuracy: 0.4373 - val_loss: 4.8726 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0883 - accuracy: 0.4917 - val_loss: 5.6982 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0397 - accuracy: 0.5300 - val_loss: 6.1721 - val_accuracy: 0.0149\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9879 - accuracy: 0.5621 - val_loss: 6.4995 - val_accuracy: 0.0245\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9437 - accuracy: 0.5787 - val_loss: 6.4139 - val_accuracy: 0.0491\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9219 - accuracy: 0.5844 - val_loss: 6.5238 - val_accuracy: 0.0394\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9041 - accuracy: 0.5925 - val_loss: 6.6699 - val_accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8947 - accuracy: 0.5947 - val_loss: 6.6984 - val_accuracy: 0.0403\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8834 - accuracy: 0.6007 - val_loss: 7.2901 - val_accuracy: 0.0324\n",
      "0.6006578803062439\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 3ms/step - loss: 1.6367 - accuracy: 0.3070 - val_loss: 3.1020 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1927 - accuracy: 0.4366 - val_loss: 4.8538 - val_accuracy: 0.0202\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0727 - accuracy: 0.5143 - val_loss: 5.8183 - val_accuracy: 0.0438\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0141 - accuracy: 0.5408 - val_loss: 6.2268 - val_accuracy: 0.0911\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9641 - accuracy: 0.5572 - val_loss: 6.6900 - val_accuracy: 0.0613\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9342 - accuracy: 0.5719 - val_loss: 6.9980 - val_accuracy: 0.0351\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9155 - accuracy: 0.5833 - val_loss: 6.9751 - val_accuracy: 0.0543\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9021 - accuracy: 0.5884 - val_loss: 7.3034 - val_accuracy: 0.0421\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8931 - accuracy: 0.5961 - val_loss: 7.4938 - val_accuracy: 0.0342\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8861 - accuracy: 0.5941 - val_loss: 7.5641 - val_accuracy: 0.0508\n",
      "0.5940789580345154\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6053 - accuracy: 0.3050 - val_loss: 3.1310 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1649 - accuracy: 0.4404 - val_loss: 4.8893 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0674 - accuracy: 0.5305 - val_loss: 5.4340 - val_accuracy: 0.0736\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0181 - accuracy: 0.5559 - val_loss: 6.0293 - val_accuracy: 0.0412\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9649 - accuracy: 0.5537 - val_loss: 6.5322 - val_accuracy: 0.0833\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9324 - accuracy: 0.5682 - val_loss: 6.7557 - val_accuracy: 0.0885\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9145 - accuracy: 0.5803 - val_loss: 6.7407 - val_accuracy: 0.0526\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9023 - accuracy: 0.5893 - val_loss: 6.9851 - val_accuracy: 0.0447\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8914 - accuracy: 0.5950 - val_loss: 7.2405 - val_accuracy: 0.0394\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8850 - accuracy: 0.5919 - val_loss: 7.1118 - val_accuracy: 0.0289\n",
      "0.5918859839439392\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6489 - accuracy: 0.3044 - val_loss: 2.9748 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2166 - accuracy: 0.4226 - val_loss: 4.7581 - val_accuracy: 0.0070\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0919 - accuracy: 0.4691 - val_loss: 5.6329 - val_accuracy: 0.0245\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0612 - accuracy: 0.5053 - val_loss: 6.0875 - val_accuracy: 0.0228\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0279 - accuracy: 0.5303 - val_loss: 6.5657 - val_accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9818 - accuracy: 0.5675 - val_loss: 6.7199 - val_accuracy: 0.0649\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9469 - accuracy: 0.5761 - val_loss: 6.9442 - val_accuracy: 0.0491\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9265 - accuracy: 0.5873 - val_loss: 7.1389 - val_accuracy: 0.0605\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9119 - accuracy: 0.5846 - val_loss: 7.6778 - val_accuracy: 0.0465\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9023 - accuracy: 0.5982 - val_loss: 7.5181 - val_accuracy: 0.0368\n",
      "0.5982456207275391\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6362 - accuracy: 0.2925 - val_loss: 3.1469 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2002 - accuracy: 0.4287 - val_loss: 4.9209 - val_accuracy: 0.0070\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0834 - accuracy: 0.5046 - val_loss: 5.7594 - val_accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0406 - accuracy: 0.5393 - val_loss: 6.1945 - val_accuracy: 0.0456\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9964 - accuracy: 0.5612 - val_loss: 6.5976 - val_accuracy: 0.0517\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9541 - accuracy: 0.5675 - val_loss: 6.7563 - val_accuracy: 0.0210\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9317 - accuracy: 0.5803 - val_loss: 7.1702 - val_accuracy: 0.0465\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9167 - accuracy: 0.5882 - val_loss: 7.3103 - val_accuracy: 0.0465\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9062 - accuracy: 0.5906 - val_loss: 7.4516 - val_accuracy: 0.0482\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8965 - accuracy: 0.5954 - val_loss: 7.5049 - val_accuracy: 0.0491\n",
      "0.5953947305679321\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6357 - accuracy: 0.3070 - val_loss: 3.0566 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2077 - accuracy: 0.4257 - val_loss: 4.7716 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0869 - accuracy: 0.4818 - val_loss: 5.5212 - val_accuracy: 0.0342\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0357 - accuracy: 0.5346 - val_loss: 6.2143 - val_accuracy: 0.0500\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9751 - accuracy: 0.5601 - val_loss: 6.4048 - val_accuracy: 0.0789\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9361 - accuracy: 0.5754 - val_loss: 6.7691 - val_accuracy: 0.0386\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9167 - accuracy: 0.5846 - val_loss: 6.9263 - val_accuracy: 0.0245\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9024 - accuracy: 0.5950 - val_loss: 7.2305 - val_accuracy: 0.0210\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8920 - accuracy: 0.5974 - val_loss: 7.2827 - val_accuracy: 0.0377\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8843 - accuracy: 0.5978 - val_loss: 7.1801 - val_accuracy: 0.0193\n",
      "0.597806990146637\n",
      "if any\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6354 - accuracy: 0.3107 - val_loss: 3.0519 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2150 - accuracy: 0.4191 - val_loss: 4.5780 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0961 - accuracy: 0.4820 - val_loss: 5.6510 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0575 - accuracy: 0.5206 - val_loss: 6.0670 - val_accuracy: 0.0053\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0195 - accuracy: 0.5529 - val_loss: 6.5421 - val_accuracy: 0.0035\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9875 - accuracy: 0.5684 - val_loss: 6.5557 - val_accuracy: 0.0123\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9599 - accuracy: 0.5814 - val_loss: 6.4743 - val_accuracy: 0.0149\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9379 - accuracy: 0.5893 - val_loss: 6.7194 - val_accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9237 - accuracy: 0.5888 - val_loss: 6.6704 - val_accuracy: 0.0245\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9102 - accuracy: 0.5914 - val_loss: 7.0957 - val_accuracy: 0.0202\n",
      "0.5914473533630371\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6352 - accuracy: 0.3037 - val_loss: 3.0663 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2104 - accuracy: 0.4366 - val_loss: 4.7650 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0853 - accuracy: 0.4978 - val_loss: 5.5792 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0379 - accuracy: 0.5322 - val_loss: 6.2335 - val_accuracy: 0.0035\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9894 - accuracy: 0.5531 - val_loss: 6.3482 - val_accuracy: 0.0114\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9490 - accuracy: 0.5807 - val_loss: 6.5672 - val_accuracy: 0.0298\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9257 - accuracy: 0.5849 - val_loss: 6.5942 - val_accuracy: 0.0456\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9098 - accuracy: 0.5888 - val_loss: 6.5747 - val_accuracy: 0.0377\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8973 - accuracy: 0.5910 - val_loss: 6.8104 - val_accuracy: 0.0351\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8879 - accuracy: 0.5996 - val_loss: 6.8752 - val_accuracy: 0.0237\n",
      "0.5995613932609558\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6401 - accuracy: 0.2711 - val_loss: 3.0012 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2175 - accuracy: 0.4228 - val_loss: 4.7638 - val_accuracy: 0.0105\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0908 - accuracy: 0.4862 - val_loss: 5.6969 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0539 - accuracy: 0.5046 - val_loss: 5.9869 - val_accuracy: 0.0061\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0205 - accuracy: 0.5329 - val_loss: 6.4060 - val_accuracy: 0.0254\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9787 - accuracy: 0.5711 - val_loss: 6.6876 - val_accuracy: 0.0412\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9436 - accuracy: 0.5807 - val_loss: 7.0493 - val_accuracy: 0.0307\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9236 - accuracy: 0.5893 - val_loss: 7.0242 - val_accuracy: 0.0359\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9129 - accuracy: 0.5928 - val_loss: 7.2966 - val_accuracy: 0.0394\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9012 - accuracy: 0.5980 - val_loss: 7.5176 - val_accuracy: 0.0237\n",
      "0.5980263352394104\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6339 - accuracy: 0.2945 - val_loss: 3.1833 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1994 - accuracy: 0.4241 - val_loss: 4.9879 - val_accuracy: 0.0053\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0900 - accuracy: 0.4748 - val_loss: 5.6788 - val_accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0535 - accuracy: 0.5167 - val_loss: 6.3234 - val_accuracy: 0.0149\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0151 - accuracy: 0.5419 - val_loss: 6.6609 - val_accuracy: 0.0324\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9706 - accuracy: 0.5577 - val_loss: 6.6232 - val_accuracy: 0.0815\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 0.9393 - accuracy: 0.5860 - val_loss: 6.7086 - val_accuracy: 0.0508\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9226 - accuracy: 0.5855 - val_loss: 7.3790 - val_accuracy: 0.0429\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9120 - accuracy: 0.5895 - val_loss: 7.3982 - val_accuracy: 0.0438\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8997 - accuracy: 0.5930 - val_loss: 7.5209 - val_accuracy: 0.0412\n",
      "0.5929824709892273\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6377 - accuracy: 0.3066 - val_loss: 3.0408 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2052 - accuracy: 0.4303 - val_loss: 4.7395 - val_accuracy: 0.0219\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0871 - accuracy: 0.4851 - val_loss: 5.6466 - val_accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0513 - accuracy: 0.5140 - val_loss: 6.0779 - val_accuracy: 0.0272\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0173 - accuracy: 0.5476 - val_loss: 6.4003 - val_accuracy: 0.0482\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9778 - accuracy: 0.5684 - val_loss: 6.6339 - val_accuracy: 0.0298\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9468 - accuracy: 0.5862 - val_loss: 6.9975 - val_accuracy: 0.0228\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9273 - accuracy: 0.5893 - val_loss: 7.2581 - val_accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9152 - accuracy: 0.5899 - val_loss: 7.4813 - val_accuracy: 0.0316\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9043 - accuracy: 0.5961 - val_loss: 7.6061 - val_accuracy: 0.0210\n",
      "0.5960526466369629\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6376 - accuracy: 0.2961 - val_loss: 3.1376 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2065 - accuracy: 0.4757 - val_loss: 4.8038 - val_accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0587 - accuracy: 0.5627 - val_loss: 5.8649 - val_accuracy: 0.0622\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9909 - accuracy: 0.5550 - val_loss: 6.4998 - val_accuracy: 0.0333\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9460 - accuracy: 0.5581 - val_loss: 6.5896 - val_accuracy: 0.0657\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9206 - accuracy: 0.5774 - val_loss: 6.7762 - val_accuracy: 0.0202\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9080 - accuracy: 0.5923 - val_loss: 6.7304 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8962 - accuracy: 0.5934 - val_loss: 6.7805 - val_accuracy: 0.0210\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8879 - accuracy: 0.5910 - val_loss: 7.0739 - val_accuracy: 0.0359\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8804 - accuracy: 0.6050 - val_loss: 6.8308 - val_accuracy: 0.0140\n",
      "0.605043888092041\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6384 - accuracy: 0.3123 - val_loss: 3.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1978 - accuracy: 0.4590 - val_loss: 4.9282 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0727 - accuracy: 0.5090 - val_loss: 5.8339 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0089 - accuracy: 0.5531 - val_loss: 6.3081 - val_accuracy: 0.0692\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9552 - accuracy: 0.5697 - val_loss: 6.5372 - val_accuracy: 0.0394\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9266 - accuracy: 0.5789 - val_loss: 7.2904 - val_accuracy: 0.0289\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9127 - accuracy: 0.5908 - val_loss: 7.0194 - val_accuracy: 0.0307\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8996 - accuracy: 0.5921 - val_loss: 7.1702 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8891 - accuracy: 0.5934 - val_loss: 7.4770 - val_accuracy: 0.0342\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8823 - accuracy: 0.6004 - val_loss: 7.4772 - val_accuracy: 0.0254\n",
      "0.6004385948181152\n",
      "if any\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6196 - accuracy: 0.3110 - val_loss: 2.9888 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1779 - accuracy: 0.4191 - val_loss: 4.8320 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0835 - accuracy: 0.4656 - val_loss: 5.6165 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0487 - accuracy: 0.5274 - val_loss: 6.1442 - val_accuracy: 8.7642e-04\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0080 - accuracy: 0.5553 - val_loss: 6.1547 - val_accuracy: 0.1131\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9654 - accuracy: 0.5645 - val_loss: 6.4885 - val_accuracy: 0.0947\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9328 - accuracy: 0.5814 - val_loss: 6.8489 - val_accuracy: 0.0543\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9135 - accuracy: 0.5890 - val_loss: 7.0179 - val_accuracy: 0.0438\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9002 - accuracy: 0.5954 - val_loss: 7.2654 - val_accuracy: 0.0324\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8891 - accuracy: 0.6002 - val_loss: 7.2326 - val_accuracy: 0.0342\n",
      "0.6002193093299866\n",
      "yhn tk\n",
      "4\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:85: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhn tk\n",
      "1\n",
      "Done\n",
      "125/125 [==============================] - 0s 715us/step - loss: 2.2626 - accuracy: 0.4865\n",
      "54/54 [==============================] - 0s 703us/step - loss: 2.1625 - accuracy: 0.4944\n",
      "125/125 [==============================] - 0s 742us/step - loss: 2.2273 - accuracy: 0.4960\n",
      "54/54 [==============================] - 0s 732us/step - loss: 2.1302 - accuracy: 0.5056\n",
      "125/125 [==============================] - 0s 690us/step - loss: 2.3276 - accuracy: 0.4902\n",
      "54/54 [==============================] - 0s 694us/step - loss: 2.2222 - accuracy: 0.4950\n",
      "125/125 [==============================] - 0s 666us/step - loss: 2.2951 - accuracy: 0.4900\n",
      "54/54 [==============================] - 0s 687us/step - loss: 2.1886 - accuracy: 0.4997\n",
      "125/125 [==============================] - 0s 679us/step - loss: 2.2661 - accuracy: 0.4897\n",
      "54/54 [==============================] - 0s 687us/step - loss: 2.1639 - accuracy: 0.4980\n",
      "36/36 [==============================] - 0s 602us/step\n",
      "36/36 [==============================] - 0s 646us/step\n",
      "36/36 [==============================] - 0s 592us/step\n",
      "36/36 [==============================] - 0s 619us/step\n",
      "36/36 [==============================] - 0s 623us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 625us/step\n",
      "179/179 [==============================] - 0s 563us/step\n",
      "179/179 [==============================] - 0s 523us/step\n",
      "179/179 [==============================] - 0s 530us/step\n",
      "179/179 [==============================] - 0s 534us/step\n",
      "36/36 [==============================] - 0s 676us/step\n",
      "36/36 [==============================] - 0s 639us/step\n",
      "36/36 [==============================] - 0s 604us/step\n",
      "36/36 [==============================] - 0s 599us/step\n",
      "36/36 [==============================] - 0s 628us/step\n",
      "1140\n",
      "drift has been detected models must be retrained\n",
      "some intersection\n",
      "finished\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6257 - accuracy: 0.3107 - val_loss: 3.1218 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1688 - accuracy: 0.4555 - val_loss: 4.9219 - val_accuracy: 0.0061\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0558 - accuracy: 0.5206 - val_loss: 5.6521 - val_accuracy: 0.1034\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9909 - accuracy: 0.5511 - val_loss: 6.3856 - val_accuracy: 0.0745\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9436 - accuracy: 0.5697 - val_loss: 6.9195 - val_accuracy: 0.0622\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9203 - accuracy: 0.5763 - val_loss: 6.8432 - val_accuracy: 0.0342\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9062 - accuracy: 0.5882 - val_loss: 6.9905 - val_accuracy: 0.0456\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8943 - accuracy: 0.5969 - val_loss: 7.3099 - val_accuracy: 0.0368\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8842 - accuracy: 0.5952 - val_loss: 7.2459 - val_accuracy: 0.0386\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8774 - accuracy: 0.5961 - val_loss: 7.5409 - val_accuracy: 0.0465\n",
      "0.5960526466369629\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6495 - accuracy: 0.3033 - val_loss: 2.9604 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2174 - accuracy: 0.4346 - val_loss: 4.7597 - val_accuracy: 0.0070\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0822 - accuracy: 0.5279 - val_loss: 5.5686 - val_accuracy: 0.0359\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0235 - accuracy: 0.5447 - val_loss: 6.3548 - val_accuracy: 0.0131\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9671 - accuracy: 0.5678 - val_loss: 6.6069 - val_accuracy: 0.0333\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9327 - accuracy: 0.5737 - val_loss: 6.9752 - val_accuracy: 0.0263\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9164 - accuracy: 0.5860 - val_loss: 6.9212 - val_accuracy: 0.0237\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9044 - accuracy: 0.5963 - val_loss: 7.0968 - val_accuracy: 0.0368\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8970 - accuracy: 0.5925 - val_loss: 7.1553 - val_accuracy: 0.0280\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8858 - accuracy: 0.6046 - val_loss: 7.3393 - val_accuracy: 0.0202\n",
      "0.6046052575111389\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6238 - accuracy: 0.3167 - val_loss: 2.9455 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1787 - accuracy: 0.4237 - val_loss: 4.7455 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0635 - accuracy: 0.5414 - val_loss: 5.7113 - val_accuracy: 0.0175\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0061 - accuracy: 0.5531 - val_loss: 6.1714 - val_accuracy: 0.0824\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9543 - accuracy: 0.5629 - val_loss: 6.5961 - val_accuracy: 0.0429\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9247 - accuracy: 0.5811 - val_loss: 6.9261 - val_accuracy: 0.0552\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9051 - accuracy: 0.5914 - val_loss: 7.0090 - val_accuracy: 0.0377\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8923 - accuracy: 0.5952 - val_loss: 7.1028 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8831 - accuracy: 0.6020 - val_loss: 7.3467 - val_accuracy: 0.0272\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8751 - accuracy: 0.6035 - val_loss: 7.4254 - val_accuracy: 0.0140\n",
      "0.6035087704658508\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6078 - accuracy: 0.3134 - val_loss: 3.1354 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1700 - accuracy: 0.4336 - val_loss: 5.0004 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0646 - accuracy: 0.5287 - val_loss: 5.6554 - val_accuracy: 0.0421\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0038 - accuracy: 0.5463 - val_loss: 6.0557 - val_accuracy: 0.0868\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9530 - accuracy: 0.5610 - val_loss: 6.4703 - val_accuracy: 0.0692\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9243 - accuracy: 0.5794 - val_loss: 6.7713 - val_accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9082 - accuracy: 0.5914 - val_loss: 6.7758 - val_accuracy: 0.0263\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8949 - accuracy: 0.5971 - val_loss: 6.7715 - val_accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8886 - accuracy: 0.5996 - val_loss: 6.9021 - val_accuracy: 0.0263\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8789 - accuracy: 0.5987 - val_loss: 7.4425 - val_accuracy: 0.0307\n",
      "0.5986841917037964\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 2ms/step - loss: 1.6501 - accuracy: 0.2958 - val_loss: 3.1207 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2285 - accuracy: 0.4221 - val_loss: 4.6600 - val_accuracy: 0.0202\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0937 - accuracy: 0.4811 - val_loss: 5.6322 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0552 - accuracy: 0.5167 - val_loss: 6.0847 - val_accuracy: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0123 - accuracy: 0.5524 - val_loss: 6.6034 - val_accuracy: 0.0254\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9701 - accuracy: 0.5759 - val_loss: 6.4993 - val_accuracy: 0.0403\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9422 - accuracy: 0.5838 - val_loss: 6.8241 - val_accuracy: 0.0280\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9243 - accuracy: 0.5879 - val_loss: 6.9247 - val_accuracy: 0.0193\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9110 - accuracy: 0.5908 - val_loss: 7.1192 - val_accuracy: 0.0219\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8999 - accuracy: 0.5954 - val_loss: 7.1830 - val_accuracy: 0.0263\n",
      "0.5953947305679321\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6159 - accuracy: 0.3105 - val_loss: 3.1604 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1681 - accuracy: 0.4353 - val_loss: 4.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0683 - accuracy: 0.5224 - val_loss: 5.8097 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0234 - accuracy: 0.5537 - val_loss: 6.1355 - val_accuracy: 0.0333\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9771 - accuracy: 0.5682 - val_loss: 6.3967 - val_accuracy: 0.0789\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9430 - accuracy: 0.5713 - val_loss: 6.7944 - val_accuracy: 0.0508\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9227 - accuracy: 0.5761 - val_loss: 6.8004 - val_accuracy: 0.0254\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9066 - accuracy: 0.5912 - val_loss: 6.8716 - val_accuracy: 0.0307\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8967 - accuracy: 0.5936 - val_loss: 7.0224 - val_accuracy: 0.0219\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8869 - accuracy: 0.5982 - val_loss: 7.2020 - val_accuracy: 0.0351\n",
      "0.5982456207275391\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6402 - accuracy: 0.3024 - val_loss: 3.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2025 - accuracy: 0.4246 - val_loss: 4.8548 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0871 - accuracy: 0.4779 - val_loss: 5.7087 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0541 - accuracy: 0.5042 - val_loss: 6.1274 - val_accuracy: 0.0123\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0155 - accuracy: 0.5520 - val_loss: 6.4701 - val_accuracy: 0.0482\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9697 - accuracy: 0.5719 - val_loss: 6.7866 - val_accuracy: 0.0386\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9346 - accuracy: 0.5840 - val_loss: 7.1903 - val_accuracy: 0.0105\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9168 - accuracy: 0.5956 - val_loss: 7.1922 - val_accuracy: 0.0421\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9090 - accuracy: 0.5914 - val_loss: 7.5754 - val_accuracy: 0.0342\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8936 - accuracy: 0.6002 - val_loss: 7.5849 - val_accuracy: 0.0307\n",
      "0.6002193093299866\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6177 - accuracy: 0.2991 - val_loss: 3.0582 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1678 - accuracy: 0.4640 - val_loss: 4.7592 - val_accuracy: 0.0044\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0499 - accuracy: 0.5432 - val_loss: 5.7212 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9907 - accuracy: 0.5634 - val_loss: 6.2649 - val_accuracy: 0.0535\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9490 - accuracy: 0.5671 - val_loss: 6.5372 - val_accuracy: 0.0394\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9268 - accuracy: 0.5763 - val_loss: 6.5301 - val_accuracy: 0.0517\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9121 - accuracy: 0.5816 - val_loss: 6.6985 - val_accuracy: 0.0438\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9018 - accuracy: 0.5840 - val_loss: 6.6672 - val_accuracy: 0.0359\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8936 - accuracy: 0.5910 - val_loss: 6.8804 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8855 - accuracy: 0.5930 - val_loss: 7.2090 - val_accuracy: 0.0289\n",
      "0.5929824709892273\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6185 - accuracy: 0.2989 - val_loss: 3.0495 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1861 - accuracy: 0.4360 - val_loss: 4.8384 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0719 - accuracy: 0.4939 - val_loss: 5.5772 - val_accuracy: 0.0053\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0185 - accuracy: 0.5388 - val_loss: 6.1126 - val_accuracy: 0.0149\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9616 - accuracy: 0.5660 - val_loss: 6.3420 - val_accuracy: 0.0386\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9294 - accuracy: 0.5787 - val_loss: 6.4751 - val_accuracy: 0.0508\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9109 - accuracy: 0.5899 - val_loss: 6.7750 - val_accuracy: 0.0491\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8992 - accuracy: 0.5982 - val_loss: 6.8063 - val_accuracy: 0.0508\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8900 - accuracy: 0.5930 - val_loss: 6.9927 - val_accuracy: 0.0403\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8820 - accuracy: 0.5976 - val_loss: 7.1634 - val_accuracy: 0.0429\n",
      "0.5975877046585083\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6408 - accuracy: 0.3035 - val_loss: 2.9707 - val_accuracy: 8.7642e-04\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2015 - accuracy: 0.4322 - val_loss: 4.8150 - val_accuracy: 0.0096\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0880 - accuracy: 0.4895 - val_loss: 5.7099 - val_accuracy: 0.0131\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0460 - accuracy: 0.5219 - val_loss: 6.1437 - val_accuracy: 0.0053\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9960 - accuracy: 0.5673 - val_loss: 6.4610 - val_accuracy: 0.0088\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9526 - accuracy: 0.5818 - val_loss: 6.6011 - val_accuracy: 0.0491\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9284 - accuracy: 0.5855 - val_loss: 6.9666 - val_accuracy: 0.0272\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9158 - accuracy: 0.5846 - val_loss: 7.1390 - val_accuracy: 0.0263\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9043 - accuracy: 0.5950 - val_loss: 7.1229 - val_accuracy: 0.0237\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8966 - accuracy: 0.5928 - val_loss: 7.2064 - val_accuracy: 0.0114\n",
      "0.5927631855010986\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6291 - accuracy: 0.2925 - val_loss: 2.9858 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1844 - accuracy: 0.4250 - val_loss: 4.7820 - val_accuracy: 0.0140\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0780 - accuracy: 0.4842 - val_loss: 5.7605 - val_accuracy: 0.0114\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0425 - accuracy: 0.5215 - val_loss: 6.2750 - val_accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0025 - accuracy: 0.5522 - val_loss: 6.4943 - val_accuracy: 0.0517\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9638 - accuracy: 0.5682 - val_loss: 6.6608 - val_accuracy: 0.0964\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9395 - accuracy: 0.5704 - val_loss: 7.1576 - val_accuracy: 0.0333\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9222 - accuracy: 0.5827 - val_loss: 7.0751 - val_accuracy: 0.0254\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9092 - accuracy: 0.5888 - val_loss: 7.5428 - val_accuracy: 0.0412\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8998 - accuracy: 0.5923 - val_loss: 7.5188 - val_accuracy: 0.0298\n",
      "0.5923245549201965\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6079 - accuracy: 0.3092 - val_loss: 3.1442 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1626 - accuracy: 0.4605 - val_loss: 5.0270 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0723 - accuracy: 0.5011 - val_loss: 5.6111 - val_accuracy: 0.0351\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0322 - accuracy: 0.5579 - val_loss: 6.1316 - val_accuracy: 0.0692\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9878 - accuracy: 0.5682 - val_loss: 6.3184 - val_accuracy: 0.1104\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9475 - accuracy: 0.5721 - val_loss: 6.7319 - val_accuracy: 0.0806\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9225 - accuracy: 0.5846 - val_loss: 7.1127 - val_accuracy: 0.0359\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9062 - accuracy: 0.5976 - val_loss: 7.1343 - val_accuracy: 0.0613\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8955 - accuracy: 0.5980 - val_loss: 7.3265 - val_accuracy: 0.0368\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8841 - accuracy: 0.5998 - val_loss: 7.4694 - val_accuracy: 0.0351\n",
      "0.5997806787490845\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6379 - accuracy: 0.3035 - val_loss: 3.0534 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1977 - accuracy: 0.4274 - val_loss: 4.9144 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0798 - accuracy: 0.4978 - val_loss: 5.6238 - val_accuracy: 0.0482\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0266 - accuracy: 0.5458 - val_loss: 6.2536 - val_accuracy: 0.0535\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9738 - accuracy: 0.5621 - val_loss: 6.7414 - val_accuracy: 0.0727\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9346 - accuracy: 0.5735 - val_loss: 6.7182 - val_accuracy: 0.0666\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9198 - accuracy: 0.5798 - val_loss: 7.0418 - val_accuracy: 0.0561\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9029 - accuracy: 0.5906 - val_loss: 7.3230 - val_accuracy: 0.0403\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8946 - accuracy: 0.5919 - val_loss: 7.3511 - val_accuracy: 0.0535\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8868 - accuracy: 0.5958 - val_loss: 7.2862 - val_accuracy: 0.0465\n",
      "0.5958333611488342\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6479 - accuracy: 0.2967 - val_loss: 2.9556 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2093 - accuracy: 0.4217 - val_loss: 4.7523 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0886 - accuracy: 0.4864 - val_loss: 5.4825 - val_accuracy: 0.0245\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0543 - accuracy: 0.5169 - val_loss: 6.0119 - val_accuracy: 0.0219\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0179 - accuracy: 0.5397 - val_loss: 6.2490 - val_accuracy: 0.0447\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9760 - accuracy: 0.5711 - val_loss: 6.6190 - val_accuracy: 0.0394\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9463 - accuracy: 0.5882 - val_loss: 6.6014 - val_accuracy: 0.0473\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9290 - accuracy: 0.5884 - val_loss: 6.9309 - val_accuracy: 0.0316\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9158 - accuracy: 0.5912 - val_loss: 7.2487 - val_accuracy: 0.0272\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9057 - accuracy: 0.5923 - val_loss: 7.4795 - val_accuracy: 0.0324\n",
      "0.5923245549201965\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6263 - accuracy: 0.3044 - val_loss: 3.1493 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1862 - accuracy: 0.4243 - val_loss: 4.9694 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0771 - accuracy: 0.5175 - val_loss: 5.6368 - val_accuracy: 0.0351\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0314 - accuracy: 0.5408 - val_loss: 6.0750 - val_accuracy: 0.0412\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9839 - accuracy: 0.5590 - val_loss: 6.3946 - val_accuracy: 0.0920\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9462 - accuracy: 0.5581 - val_loss: 6.5192 - val_accuracy: 0.0947\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9205 - accuracy: 0.5770 - val_loss: 6.9651 - val_accuracy: 0.0526\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9085 - accuracy: 0.5853 - val_loss: 6.8854 - val_accuracy: 0.0245\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8951 - accuracy: 0.5923 - val_loss: 6.6563 - val_accuracy: 0.0359\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8838 - accuracy: 0.6002 - val_loss: 6.7510 - val_accuracy: 0.0079\n",
      "0.6002193093299866\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6382 - accuracy: 0.3309 - val_loss: 3.0842 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2025 - accuracy: 0.4465 - val_loss: 4.8133 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0772 - accuracy: 0.5101 - val_loss: 5.7219 - val_accuracy: 0.0228\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0319 - accuracy: 0.5425 - val_loss: 6.1706 - val_accuracy: 0.0053\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9930 - accuracy: 0.5649 - val_loss: 6.3080 - val_accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9614 - accuracy: 0.5809 - val_loss: 6.4695 - val_accuracy: 0.0228\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9407 - accuracy: 0.5836 - val_loss: 6.5888 - val_accuracy: 0.0280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9241 - accuracy: 0.5871 - val_loss: 6.6314 - val_accuracy: 0.0237\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9078 - accuracy: 0.5899 - val_loss: 7.0136 - val_accuracy: 0.0333\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8998 - accuracy: 0.6004 - val_loss: 7.0699 - val_accuracy: 0.0298\n",
      "0.6004385948181152\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6404 - accuracy: 0.3219 - val_loss: 3.0534 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2091 - accuracy: 0.4272 - val_loss: 4.6058 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0901 - accuracy: 0.4912 - val_loss: 5.5615 - val_accuracy: 0.0053\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0435 - accuracy: 0.5274 - val_loss: 5.9097 - val_accuracy: 0.0841\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9954 - accuracy: 0.5575 - val_loss: 6.2147 - val_accuracy: 0.0631\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9557 - accuracy: 0.5700 - val_loss: 6.5067 - val_accuracy: 0.0333\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9302 - accuracy: 0.5862 - val_loss: 6.6698 - val_accuracy: 0.0324\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9150 - accuracy: 0.5912 - val_loss: 6.8707 - val_accuracy: 0.0438\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9049 - accuracy: 0.5906 - val_loss: 6.8926 - val_accuracy: 0.0342\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8957 - accuracy: 0.5961 - val_loss: 7.0522 - val_accuracy: 0.0403\n",
      "0.5960526466369629\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6378 - accuracy: 0.3050 - val_loss: 3.0817 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2042 - accuracy: 0.4283 - val_loss: 4.7471 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0820 - accuracy: 0.4763 - val_loss: 5.5332 - val_accuracy: 0.0412\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0397 - accuracy: 0.5325 - val_loss: 6.0086 - val_accuracy: 0.0298\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9860 - accuracy: 0.5711 - val_loss: 6.5401 - val_accuracy: 0.0561\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9434 - accuracy: 0.5774 - val_loss: 6.9629 - val_accuracy: 0.0289\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9238 - accuracy: 0.5897 - val_loss: 7.2409 - val_accuracy: 0.0456\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9091 - accuracy: 0.5941 - val_loss: 7.1709 - val_accuracy: 0.0473\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8990 - accuracy: 0.5932 - val_loss: 7.3979 - val_accuracy: 0.0333\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8905 - accuracy: 0.6013 - val_loss: 7.4307 - val_accuracy: 0.0307\n",
      "0.6013157963752747\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6225 - accuracy: 0.3344 - val_loss: 3.0295 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1799 - accuracy: 0.4270 - val_loss: 4.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0768 - accuracy: 0.4761 - val_loss: 5.5575 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0279 - accuracy: 0.5425 - val_loss: 6.2923 - val_accuracy: 0.0114\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9732 - accuracy: 0.5542 - val_loss: 6.6040 - val_accuracy: 0.0324\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9372 - accuracy: 0.5757 - val_loss: 6.8177 - val_accuracy: 0.0403\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9158 - accuracy: 0.5849 - val_loss: 6.9850 - val_accuracy: 0.0394\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9019 - accuracy: 0.5928 - val_loss: 7.0013 - val_accuracy: 0.0272\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8892 - accuracy: 0.5971 - val_loss: 7.2040 - val_accuracy: 0.0386\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8802 - accuracy: 0.5993 - val_loss: 7.4633 - val_accuracy: 0.0289\n",
      "0.5993421077728271\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6399 - accuracy: 0.2844 - val_loss: 3.0136 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2199 - accuracy: 0.4173 - val_loss: 4.6973 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0847 - accuracy: 0.5035 - val_loss: 5.4950 - val_accuracy: 0.0096\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0204 - accuracy: 0.5498 - val_loss: 6.1423 - val_accuracy: 0.0307\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9667 - accuracy: 0.5636 - val_loss: 6.3182 - val_accuracy: 0.0613\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9360 - accuracy: 0.5873 - val_loss: 6.4364 - val_accuracy: 0.0526\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9185 - accuracy: 0.5829 - val_loss: 6.6910 - val_accuracy: 0.0386\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9029 - accuracy: 0.5939 - val_loss: 6.9173 - val_accuracy: 0.0386\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8954 - accuracy: 0.5943 - val_loss: 6.9245 - val_accuracy: 0.0324\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8828 - accuracy: 0.5961 - val_loss: 6.8475 - val_accuracy: 0.0289\n",
      "0.5960526466369629\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6268 - accuracy: 0.3088 - val_loss: 3.0202 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1822 - accuracy: 0.4184 - val_loss: 4.6721 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0836 - accuracy: 0.4772 - val_loss: 5.6354 - val_accuracy: 0.0035\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0529 - accuracy: 0.5129 - val_loss: 5.9356 - val_accuracy: 0.0158\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0134 - accuracy: 0.5590 - val_loss: 6.4801 - val_accuracy: 0.0096\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9676 - accuracy: 0.5857 - val_loss: 6.7917 - val_accuracy: 0.0263\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9331 - accuracy: 0.5914 - val_loss: 7.0988 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9139 - accuracy: 0.5877 - val_loss: 7.1128 - val_accuracy: 0.0254\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8984 - accuracy: 0.5963 - val_loss: 7.2786 - val_accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8857 - accuracy: 0.6022 - val_loss: 7.5338 - val_accuracy: 0.0473\n",
      "0.6021929979324341\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6154 - accuracy: 0.3004 - val_loss: 3.2224 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1917 - accuracy: 0.4362 - val_loss: 4.8977 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0838 - accuracy: 0.5035 - val_loss: 5.6916 - val_accuracy: 0.0026\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0312 - accuracy: 0.5469 - val_loss: 6.1459 - val_accuracy: 0.0061\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9762 - accuracy: 0.5800 - val_loss: 6.4616 - val_accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9403 - accuracy: 0.5829 - val_loss: 6.5966 - val_accuracy: 0.0210\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9211 - accuracy: 0.5904 - val_loss: 6.5478 - val_accuracy: 0.0429\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9077 - accuracy: 0.5976 - val_loss: 6.6306 - val_accuracy: 0.0263\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8956 - accuracy: 0.6007 - val_loss: 6.7293 - val_accuracy: 0.0307\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8884 - accuracy: 0.5974 - val_loss: 6.8869 - val_accuracy: 0.0263\n",
      "0.5973684191703796\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6155 - accuracy: 0.3068 - val_loss: 3.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1676 - accuracy: 0.4327 - val_loss: 4.8547 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0748 - accuracy: 0.4851 - val_loss: 5.5411 - val_accuracy: 0.0149\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0398 - accuracy: 0.5476 - val_loss: 5.9986 - val_accuracy: 0.0272\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9958 - accuracy: 0.5537 - val_loss: 6.5209 - val_accuracy: 0.0736\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9510 - accuracy: 0.5625 - val_loss: 6.5361 - val_accuracy: 0.0508\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9270 - accuracy: 0.5785 - val_loss: 6.9767 - val_accuracy: 0.0219\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9121 - accuracy: 0.5945 - val_loss: 7.0712 - val_accuracy: 0.0403\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8991 - accuracy: 0.5921 - val_loss: 7.1936 - val_accuracy: 0.0543\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8881 - accuracy: 0.6031 - val_loss: 7.3847 - val_accuracy: 0.0368\n",
      "0.6030701994895935\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 2ms/step - loss: 1.6048 - accuracy: 0.3132 - val_loss: 3.1055 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1679 - accuracy: 0.4349 - val_loss: 4.8719 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0675 - accuracy: 0.5103 - val_loss: 5.7258 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0138 - accuracy: 0.5555 - val_loss: 6.2066 - val_accuracy: 0.0473\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9627 - accuracy: 0.5616 - val_loss: 6.3468 - val_accuracy: 0.0973\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9335 - accuracy: 0.5660 - val_loss: 6.7293 - val_accuracy: 0.0473\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9124 - accuracy: 0.5884 - val_loss: 7.1322 - val_accuracy: 0.0280\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9028 - accuracy: 0.5939 - val_loss: 7.0293 - val_accuracy: 0.0359\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8908 - accuracy: 0.5947 - val_loss: 7.1099 - val_accuracy: 0.0254\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8829 - accuracy: 0.6048 - val_loss: 7.1167 - val_accuracy: 0.0289\n",
      "0.6048245429992676\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6243 - accuracy: 0.3020 - val_loss: 3.1018 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1708 - accuracy: 0.4450 - val_loss: 4.8728 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0617 - accuracy: 0.5224 - val_loss: 5.6812 - val_accuracy: 0.0780\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9937 - accuracy: 0.5550 - val_loss: 6.2445 - val_accuracy: 0.0982\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9423 - accuracy: 0.5636 - val_loss: 6.7939 - val_accuracy: 0.0631\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9208 - accuracy: 0.5728 - val_loss: 6.8155 - val_accuracy: 0.0272\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9048 - accuracy: 0.5886 - val_loss: 6.8846 - val_accuracy: 0.0219\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8930 - accuracy: 0.5974 - val_loss: 6.9076 - val_accuracy: 0.0429\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8843 - accuracy: 0.5939 - val_loss: 7.2244 - val_accuracy: 0.0333\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8782 - accuracy: 0.5998 - val_loss: 7.3164 - val_accuracy: 0.0412\n",
      "0.5997806787490845\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6169 - accuracy: 0.3083 - val_loss: 2.9962 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1653 - accuracy: 0.4513 - val_loss: 4.8437 - val_accuracy: 0.0026\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0661 - accuracy: 0.4965 - val_loss: 5.6044 - val_accuracy: 0.0237\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0166 - accuracy: 0.5410 - val_loss: 6.3409 - val_accuracy: 0.0570\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9655 - accuracy: 0.5557 - val_loss: 6.6631 - val_accuracy: 0.0526\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9325 - accuracy: 0.5667 - val_loss: 7.0704 - val_accuracy: 0.0394\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9122 - accuracy: 0.5882 - val_loss: 7.1128 - val_accuracy: 0.0298\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8981 - accuracy: 0.5895 - val_loss: 7.0718 - val_accuracy: 0.0429\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8846 - accuracy: 0.6007 - val_loss: 7.2380 - val_accuracy: 0.0105\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8781 - accuracy: 0.6026 - val_loss: 7.2845 - val_accuracy: 0.0254\n",
      "0.6026315689086914\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6502 - accuracy: 0.2963 - val_loss: 3.0211 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2184 - accuracy: 0.4340 - val_loss: 4.7985 - val_accuracy: 0.0053\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0832 - accuracy: 0.5086 - val_loss: 5.6297 - val_accuracy: 0.0272\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0307 - accuracy: 0.5480 - val_loss: 6.2716 - val_accuracy: 0.0456\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9791 - accuracy: 0.5577 - val_loss: 6.6295 - val_accuracy: 0.0640\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9442 - accuracy: 0.5658 - val_loss: 7.0621 - val_accuracy: 0.0386\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9257 - accuracy: 0.5868 - val_loss: 6.9637 - val_accuracy: 0.0394\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9141 - accuracy: 0.5844 - val_loss: 7.0259 - val_accuracy: 0.0219\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9040 - accuracy: 0.5895 - val_loss: 7.1111 - val_accuracy: 0.0210\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8984 - accuracy: 0.5893 - val_loss: 7.0993 - val_accuracy: 0.0272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5892543792724609\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6171 - accuracy: 0.3138 - val_loss: 3.0193 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1773 - accuracy: 0.4373 - val_loss: 4.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0832 - accuracy: 0.4715 - val_loss: 5.5423 - val_accuracy: 0.0184\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0436 - accuracy: 0.5318 - val_loss: 6.0794 - val_accuracy: 0.0719\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9877 - accuracy: 0.5594 - val_loss: 6.5596 - val_accuracy: 0.0684\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9454 - accuracy: 0.5667 - val_loss: 6.6454 - val_accuracy: 0.0438\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9241 - accuracy: 0.5816 - val_loss: 6.8317 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9102 - accuracy: 0.5945 - val_loss: 6.7822 - val_accuracy: 0.0403\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8994 - accuracy: 0.5978 - val_loss: 6.9751 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8902 - accuracy: 0.5998 - val_loss: 7.0943 - val_accuracy: 0.0219\n",
      "0.5997806787490845\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6250 - accuracy: 0.3125 - val_loss: 2.9890 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1865 - accuracy: 0.4471 - val_loss: 4.7439 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0610 - accuracy: 0.5305 - val_loss: 5.5103 - val_accuracy: 0.0359\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9870 - accuracy: 0.5603 - val_loss: 6.0675 - val_accuracy: 0.0438\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9393 - accuracy: 0.5711 - val_loss: 6.3220 - val_accuracy: 0.0210\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9183 - accuracy: 0.5895 - val_loss: 6.8724 - val_accuracy: 0.0429\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9066 - accuracy: 0.5877 - val_loss: 6.8211 - val_accuracy: 0.0298\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8940 - accuracy: 0.5967 - val_loss: 6.8297 - val_accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8875 - accuracy: 0.5967 - val_loss: 7.0341 - val_accuracy: 0.0316\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8819 - accuracy: 0.5989 - val_loss: 7.3164 - val_accuracy: 0.0167\n",
      "0.5989035367965698\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6188 - accuracy: 0.3101 - val_loss: 3.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1686 - accuracy: 0.4276 - val_loss: 4.9088 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0711 - accuracy: 0.4800 - val_loss: 5.6821 - val_accuracy: 0.0333\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0272 - accuracy: 0.5393 - val_loss: 6.1730 - val_accuracy: 0.0210\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9772 - accuracy: 0.5559 - val_loss: 6.6420 - val_accuracy: 0.0447\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9411 - accuracy: 0.5669 - val_loss: 6.8374 - val_accuracy: 0.0386\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9200 - accuracy: 0.5800 - val_loss: 7.1824 - val_accuracy: 0.0316\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9055 - accuracy: 0.5873 - val_loss: 7.2726 - val_accuracy: 0.0394\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8934 - accuracy: 0.5936 - val_loss: 7.2938 - val_accuracy: 0.0403\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8818 - accuracy: 0.6009 - val_loss: 7.4225 - val_accuracy: 0.0377\n",
      "0.6008771657943726\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6219 - accuracy: 0.3004 - val_loss: 3.1064 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1770 - accuracy: 0.4360 - val_loss: 4.7654 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0791 - accuracy: 0.4910 - val_loss: 5.5483 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0427 - accuracy: 0.5257 - val_loss: 6.1743 - val_accuracy: 0.0079\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0051 - accuracy: 0.5502 - val_loss: 6.3658 - val_accuracy: 8.7642e-04\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9693 - accuracy: 0.5732 - val_loss: 6.2995 - val_accuracy: 0.0131\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9471 - accuracy: 0.5831 - val_loss: 6.2894 - val_accuracy: 0.0140\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9258 - accuracy: 0.5910 - val_loss: 6.5701 - val_accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9094 - accuracy: 0.5985 - val_loss: 6.6027 - val_accuracy: 0.0298\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9004 - accuracy: 0.5965 - val_loss: 7.2464 - val_accuracy: 0.0158\n",
      "0.5964912176132202\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6165 - accuracy: 0.2958 - val_loss: 3.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1796 - accuracy: 0.4454 - val_loss: 4.7620 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0816 - accuracy: 0.4941 - val_loss: 5.7830 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0456 - accuracy: 0.5327 - val_loss: 5.9952 - val_accuracy: 0.0526\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9980 - accuracy: 0.5605 - val_loss: 6.2547 - val_accuracy: 0.0640\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9543 - accuracy: 0.5726 - val_loss: 6.6086 - val_accuracy: 0.0193\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9292 - accuracy: 0.5851 - val_loss: 6.8281 - val_accuracy: 0.0359\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9151 - accuracy: 0.5857 - val_loss: 6.9670 - val_accuracy: 0.0482\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9037 - accuracy: 0.5952 - val_loss: 7.0588 - val_accuracy: 0.0394\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8938 - accuracy: 0.5980 - val_loss: 7.1421 - val_accuracy: 0.0175\n",
      "0.5980263352394104\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6108 - accuracy: 0.3123 - val_loss: 3.0563 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1761 - accuracy: 0.4515 - val_loss: 4.8110 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0710 - accuracy: 0.5154 - val_loss: 5.4271 - val_accuracy: 0.0316\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0116 - accuracy: 0.5568 - val_loss: 5.8534 - val_accuracy: 0.0351\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9579 - accuracy: 0.5800 - val_loss: 6.2074 - val_accuracy: 0.0447\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9335 - accuracy: 0.5763 - val_loss: 6.3891 - val_accuracy: 0.0429\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9142 - accuracy: 0.5855 - val_loss: 6.6096 - val_accuracy: 0.0359\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8994 - accuracy: 0.5932 - val_loss: 6.7292 - val_accuracy: 0.0245\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8884 - accuracy: 0.6002 - val_loss: 6.9936 - val_accuracy: 0.0237\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8816 - accuracy: 0.6033 - val_loss: 7.0767 - val_accuracy: 0.0228\n",
      "0.6032894849777222\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6163 - accuracy: 0.3086 - val_loss: 3.0818 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1700 - accuracy: 0.4379 - val_loss: 4.6956 - val_accuracy: 0.0123\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0748 - accuracy: 0.4860 - val_loss: 5.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0378 - accuracy: 0.5430 - val_loss: 6.1655 - val_accuracy: 0.0035\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9974 - accuracy: 0.5680 - val_loss: 6.7124 - val_accuracy: 0.0202\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9562 - accuracy: 0.5743 - val_loss: 6.7626 - val_accuracy: 0.0465\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9271 - accuracy: 0.5893 - val_loss: 7.0605 - val_accuracy: 0.0491\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9111 - accuracy: 0.5895 - val_loss: 7.1728 - val_accuracy: 0.0438\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9005 - accuracy: 0.5980 - val_loss: 7.2554 - val_accuracy: 0.0351\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8902 - accuracy: 0.6004 - val_loss: 7.5269 - val_accuracy: 0.0245\n",
      "0.6004385948181152\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6225 - accuracy: 0.2978 - val_loss: 3.2204 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1801 - accuracy: 0.4261 - val_loss: 4.9287 - val_accuracy: 0.0070\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0718 - accuracy: 0.5279 - val_loss: 5.8750 - val_accuracy: 0.0061\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0187 - accuracy: 0.5513 - val_loss: 6.2722 - val_accuracy: 0.0815\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9660 - accuracy: 0.5577 - val_loss: 6.9242 - val_accuracy: 0.0394\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9334 - accuracy: 0.5697 - val_loss: 6.8607 - val_accuracy: 0.0368\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9122 - accuracy: 0.5910 - val_loss: 6.9981 - val_accuracy: 0.0473\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9004 - accuracy: 0.5901 - val_loss: 7.2946 - val_accuracy: 0.0254\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8885 - accuracy: 0.6044 - val_loss: 7.4477 - val_accuracy: 0.0263\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8785 - accuracy: 0.6046 - val_loss: 7.5171 - val_accuracy: 0.0421\n",
      "0.6046052575111389\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6502 - accuracy: 0.3061 - val_loss: 3.1052 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2149 - accuracy: 0.4208 - val_loss: 4.8780 - val_accuracy: 0.0114\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0873 - accuracy: 0.4809 - val_loss: 5.7385 - val_accuracy: 0.0149\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0481 - accuracy: 0.5189 - val_loss: 6.1415 - val_accuracy: 0.0263\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0050 - accuracy: 0.5546 - val_loss: 6.7055 - val_accuracy: 0.0377\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9628 - accuracy: 0.5629 - val_loss: 6.7345 - val_accuracy: 0.0649\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9383 - accuracy: 0.5774 - val_loss: 6.9128 - val_accuracy: 0.0447\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9197 - accuracy: 0.5792 - val_loss: 7.4078 - val_accuracy: 0.0298\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9078 - accuracy: 0.5895 - val_loss: 7.2741 - val_accuracy: 0.0280\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8985 - accuracy: 0.5917 - val_loss: 7.5096 - val_accuracy: 0.0482\n",
      "0.5916666388511658\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6380 - accuracy: 0.3197 - val_loss: 3.1007 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2004 - accuracy: 0.4364 - val_loss: 4.7515 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0853 - accuracy: 0.5053 - val_loss: 5.6785 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0418 - accuracy: 0.5498 - val_loss: 6.1160 - val_accuracy: 0.0482\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9850 - accuracy: 0.5627 - val_loss: 6.3815 - val_accuracy: 0.0841\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9427 - accuracy: 0.5689 - val_loss: 6.6244 - val_accuracy: 0.0526\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9196 - accuracy: 0.5838 - val_loss: 7.0639 - val_accuracy: 0.0386\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9076 - accuracy: 0.5884 - val_loss: 6.9995 - val_accuracy: 0.0158\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8974 - accuracy: 0.5936 - val_loss: 7.1770 - val_accuracy: 0.0377\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8873 - accuracy: 0.5934 - val_loss: 7.3342 - val_accuracy: 0.0123\n",
      "0.5934210419654846\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6370 - accuracy: 0.3086 - val_loss: 3.1368 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2093 - accuracy: 0.4318 - val_loss: 4.9233 - val_accuracy: 0.0053\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0789 - accuracy: 0.4925 - val_loss: 5.6119 - val_accuracy: 0.0508\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0200 - accuracy: 0.5406 - val_loss: 6.2728 - val_accuracy: 0.0587\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9632 - accuracy: 0.5629 - val_loss: 6.6540 - val_accuracy: 0.0377\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9324 - accuracy: 0.5735 - val_loss: 6.8014 - val_accuracy: 0.0316\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9130 - accuracy: 0.5879 - val_loss: 7.1518 - val_accuracy: 0.0429\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8994 - accuracy: 0.5928 - val_loss: 7.4288 - val_accuracy: 0.0263\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8917 - accuracy: 0.5914 - val_loss: 7.3520 - val_accuracy: 0.0298\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8820 - accuracy: 0.5971 - val_loss: 7.6071 - val_accuracy: 0.0368\n",
      "0.597149133682251\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6354 - accuracy: 0.3143 - val_loss: 2.9922 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1954 - accuracy: 0.4272 - val_loss: 4.7913 - val_accuracy: 0.0131\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0802 - accuracy: 0.4851 - val_loss: 5.7441 - val_accuracy: 0.0123\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0396 - accuracy: 0.5226 - val_loss: 6.2195 - val_accuracy: 0.0289\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9963 - accuracy: 0.5649 - val_loss: 6.5578 - val_accuracy: 0.0745\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9528 - accuracy: 0.5634 - val_loss: 6.8735 - val_accuracy: 0.0701\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9264 - accuracy: 0.5789 - val_loss: 6.9227 - val_accuracy: 0.0473\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9111 - accuracy: 0.5831 - val_loss: 7.1353 - val_accuracy: 0.0245\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9005 - accuracy: 0.5912 - val_loss: 7.4639 - val_accuracy: 0.0465\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8928 - accuracy: 0.5956 - val_loss: 7.4436 - val_accuracy: 0.0298\n",
      "0.5956140160560608\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6441 - accuracy: 0.3011 - val_loss: 3.0188 - val_accuracy: 8.7642e-04\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2108 - accuracy: 0.4039 - val_loss: 4.8879 - val_accuracy: 0.0044\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0883 - accuracy: 0.4634 - val_loss: 5.6691 - val_accuracy: 0.0298\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0478 - accuracy: 0.5037 - val_loss: 6.2592 - val_accuracy: 0.0096\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0086 - accuracy: 0.5454 - val_loss: 6.4643 - val_accuracy: 0.0412\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9655 - accuracy: 0.5634 - val_loss: 6.7291 - val_accuracy: 0.0517\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9354 - accuracy: 0.5862 - val_loss: 7.0397 - val_accuracy: 0.0324\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9160 - accuracy: 0.5844 - val_loss: 7.1447 - val_accuracy: 0.0543\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9055 - accuracy: 0.5901 - val_loss: 7.5976 - val_accuracy: 0.0280\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8950 - accuracy: 0.5910 - val_loss: 7.9013 - val_accuracy: 0.0368\n",
      "0.5910087823867798\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6379 - accuracy: 0.2993 - val_loss: 3.0145 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1951 - accuracy: 0.4327 - val_loss: 4.7957 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0788 - accuracy: 0.5193 - val_loss: 5.5389 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0293 - accuracy: 0.5478 - val_loss: 6.2513 - val_accuracy: 0.0228\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9798 - accuracy: 0.5568 - val_loss: 6.5182 - val_accuracy: 0.0570\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9436 - accuracy: 0.5732 - val_loss: 6.8227 - val_accuracy: 0.0526\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9240 - accuracy: 0.5842 - val_loss: 6.9326 - val_accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9113 - accuracy: 0.5897 - val_loss: 7.0216 - val_accuracy: 0.0412\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9016 - accuracy: 0.5932 - val_loss: 7.0533 - val_accuracy: 0.0368\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8914 - accuracy: 0.5947 - val_loss: 7.1457 - val_accuracy: 0.0351\n",
      "0.5947368144989014\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6312 - accuracy: 0.3320 - val_loss: 2.9571 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1798 - accuracy: 0.4316 - val_loss: 4.7421 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0802 - accuracy: 0.4853 - val_loss: 5.4231 - val_accuracy: 0.0053\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0454 - accuracy: 0.5292 - val_loss: 5.8679 - val_accuracy: 0.0096\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0022 - accuracy: 0.5627 - val_loss: 6.2973 - val_accuracy: 0.0263\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9568 - accuracy: 0.5866 - val_loss: 6.6585 - val_accuracy: 0.0578\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9290 - accuracy: 0.5796 - val_loss: 7.0178 - val_accuracy: 0.0245\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9137 - accuracy: 0.5901 - val_loss: 7.1219 - val_accuracy: 0.0447\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9012 - accuracy: 0.5976 - val_loss: 7.3895 - val_accuracy: 0.0307\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8916 - accuracy: 0.6026 - val_loss: 7.5339 - val_accuracy: 0.0342\n",
      "0.6026315689086914\n",
      "if any\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 3ms/step - loss: 1.6379 - accuracy: 0.2853 - val_loss: 2.9863 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2066 - accuracy: 0.4193 - val_loss: 4.6448 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0848 - accuracy: 0.4805 - val_loss: 5.6581 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0401 - accuracy: 0.5215 - val_loss: 6.0615 - val_accuracy: 0.0018\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9933 - accuracy: 0.5596 - val_loss: 6.2617 - val_accuracy: 0.0500\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9486 - accuracy: 0.5814 - val_loss: 6.2079 - val_accuracy: 0.0780\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9230 - accuracy: 0.5789 - val_loss: 6.5545 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9100 - accuracy: 0.5882 - val_loss: 6.6033 - val_accuracy: 0.0351\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8965 - accuracy: 0.5978 - val_loss: 6.7343 - val_accuracy: 0.0535\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8891 - accuracy: 0.5985 - val_loss: 7.1573 - val_accuracy: 0.0438\n",
      "0.5984649062156677\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6403 - accuracy: 0.2846 - val_loss: 2.9597 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2181 - accuracy: 0.4311 - val_loss: 4.7182 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0794 - accuracy: 0.5226 - val_loss: 5.5526 - val_accuracy: 0.0210\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0075 - accuracy: 0.5529 - val_loss: 6.0169 - val_accuracy: 0.0351\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9598 - accuracy: 0.5702 - val_loss: 6.4568 - val_accuracy: 0.0219\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9326 - accuracy: 0.5779 - val_loss: 6.5938 - val_accuracy: 0.0429\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9169 - accuracy: 0.5884 - val_loss: 6.7070 - val_accuracy: 0.0333\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9022 - accuracy: 0.5912 - val_loss: 6.9151 - val_accuracy: 0.0316\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8924 - accuracy: 0.5991 - val_loss: 7.1065 - val_accuracy: 0.0377\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8820 - accuracy: 0.6007 - val_loss: 7.0815 - val_accuracy: 0.0210\n",
      "0.6006578803062439\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6183 - accuracy: 0.3039 - val_loss: 3.0570 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1702 - accuracy: 0.4322 - val_loss: 4.8414 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0763 - accuracy: 0.4768 - val_loss: 5.7853 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0385 - accuracy: 0.5353 - val_loss: 6.1699 - val_accuracy: 0.0517\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9747 - accuracy: 0.5748 - val_loss: 6.7100 - val_accuracy: 0.0307\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9283 - accuracy: 0.5842 - val_loss: 6.8497 - val_accuracy: 0.0359\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9034 - accuracy: 0.5840 - val_loss: 6.9609 - val_accuracy: 0.0368\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8928 - accuracy: 0.5943 - val_loss: 7.1683 - val_accuracy: 0.0421\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8816 - accuracy: 0.5991 - val_loss: 7.2846 - val_accuracy: 0.0351\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8729 - accuracy: 0.6007 - val_loss: 7.2608 - val_accuracy: 0.0289\n",
      "0.6006578803062439\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6400 - accuracy: 0.2910 - val_loss: 3.0306 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2085 - accuracy: 0.4243 - val_loss: 4.7876 - val_accuracy: 0.0184\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0767 - accuracy: 0.4855 - val_loss: 5.6842 - val_accuracy: 0.0649\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0099 - accuracy: 0.5548 - val_loss: 6.2497 - val_accuracy: 0.0824\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9549 - accuracy: 0.5599 - val_loss: 6.6282 - val_accuracy: 0.0850\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9252 - accuracy: 0.5763 - val_loss: 6.8663 - val_accuracy: 0.0526\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9107 - accuracy: 0.5871 - val_loss: 7.0977 - val_accuracy: 0.0613\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9000 - accuracy: 0.5862 - val_loss: 7.0692 - val_accuracy: 0.0272\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8906 - accuracy: 0.5895 - val_loss: 7.1648 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8823 - accuracy: 0.5974 - val_loss: 7.2346 - val_accuracy: 0.0307\n",
      "0.5973684191703796\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6056 - accuracy: 0.3103 - val_loss: 3.0637 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1757 - accuracy: 0.4336 - val_loss: 4.7548 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0774 - accuracy: 0.4965 - val_loss: 5.6113 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0270 - accuracy: 0.5445 - val_loss: 6.0088 - val_accuracy: 0.0561\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9723 - accuracy: 0.5643 - val_loss: 6.3071 - val_accuracy: 0.0780\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9368 - accuracy: 0.5684 - val_loss: 6.5540 - val_accuracy: 0.0210\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9197 - accuracy: 0.5917 - val_loss: 6.5418 - val_accuracy: 0.0570\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9043 - accuracy: 0.5965 - val_loss: 6.6974 - val_accuracy: 0.0421\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8962 - accuracy: 0.5967 - val_loss: 6.5994 - val_accuracy: 0.0351\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8884 - accuracy: 0.6033 - val_loss: 6.5886 - val_accuracy: 0.0298\n",
      "0.6032894849777222\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6241 - accuracy: 0.3002 - val_loss: 3.1976 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1835 - accuracy: 0.4379 - val_loss: 4.8568 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0634 - accuracy: 0.5500 - val_loss: 5.7802 - val_accuracy: 0.0324\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9969 - accuracy: 0.5542 - val_loss: 6.2013 - val_accuracy: 0.0552\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9521 - accuracy: 0.5588 - val_loss: 6.5226 - val_accuracy: 0.0684\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9298 - accuracy: 0.5838 - val_loss: 6.8208 - val_accuracy: 0.0316\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9174 - accuracy: 0.5809 - val_loss: 6.6728 - val_accuracy: 0.0386\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9029 - accuracy: 0.5917 - val_loss: 6.6079 - val_accuracy: 0.0254\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8931 - accuracy: 0.5934 - val_loss: 6.8646 - val_accuracy: 0.0324\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8857 - accuracy: 0.5958 - val_loss: 7.0430 - val_accuracy: 0.0219\n",
      "0.5958333611488342\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6407 - accuracy: 0.3408 - val_loss: 3.1206 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2063 - accuracy: 0.4206 - val_loss: 4.9232 - val_accuracy: 0.0088\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0839 - accuracy: 0.4895 - val_loss: 5.7022 - val_accuracy: 0.0131\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0309 - accuracy: 0.5340 - val_loss: 6.2981 - val_accuracy: 0.0175\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9740 - accuracy: 0.5572 - val_loss: 6.2867 - val_accuracy: 0.0833\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9359 - accuracy: 0.5735 - val_loss: 6.7136 - val_accuracy: 0.0596\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9166 - accuracy: 0.5827 - val_loss: 6.8709 - val_accuracy: 0.0491\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8993 - accuracy: 0.5993 - val_loss: 7.5022 - val_accuracy: 0.0289\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8898 - accuracy: 0.5961 - val_loss: 7.2852 - val_accuracy: 0.0298\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8830 - accuracy: 0.6020 - val_loss: 7.4490 - val_accuracy: 0.0210\n",
      "0.6019737124443054\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6295 - accuracy: 0.2954 - val_loss: 3.1260 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1935 - accuracy: 0.4535 - val_loss: 4.8514 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0791 - accuracy: 0.4921 - val_loss: 5.5941 - val_accuracy: 0.0771\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0297 - accuracy: 0.5586 - val_loss: 6.1999 - val_accuracy: 0.0911\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9761 - accuracy: 0.5605 - val_loss: 6.5179 - val_accuracy: 0.0456\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9374 - accuracy: 0.5765 - val_loss: 6.6948 - val_accuracy: 0.0675\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9161 - accuracy: 0.5875 - val_loss: 6.8665 - val_accuracy: 0.0175\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9041 - accuracy: 0.5908 - val_loss: 7.1864 - val_accuracy: 0.0263\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8919 - accuracy: 0.6000 - val_loss: 7.1720 - val_accuracy: 0.0149\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8849 - accuracy: 0.6015 - val_loss: 7.1367 - val_accuracy: 0.0149\n",
      "0.6015350818634033\n",
      "yhn tk\n",
      "2\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:85: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhn tk\n",
      "1\n",
      "Done\n",
      "125/125 [==============================] - 0s 760us/step - loss: 2.3733 - accuracy: 0.4682\n",
      "54/54 [==============================] - 0s 759us/step - loss: 2.3233 - accuracy: 0.4641\n",
      "125/125 [==============================] - 0s 772us/step - loss: 2.3029 - accuracy: 0.4599\n",
      "54/54 [==============================] - 0s 750us/step - loss: 2.2512 - accuracy: 0.4676\n",
      "125/125 [==============================] - 0s 717us/step - loss: 2.2519 - accuracy: 0.4702\n",
      "54/54 [==============================] - 0s 685us/step - loss: 2.2046 - accuracy: 0.4734\n",
      "125/125 [==============================] - 0s 762us/step - loss: 2.3947 - accuracy: 0.4531\n",
      "54/54 [==============================] - 0s 813us/step - loss: 2.3445 - accuracy: 0.4600\n",
      "125/125 [==============================] - 0s 778us/step - loss: 2.2739 - accuracy: 0.4444\n",
      "54/54 [==============================] - 0s 718us/step - loss: 2.2229 - accuracy: 0.4623\n",
      "36/36 [==============================] - 0s 653us/step\n",
      "36/36 [==============================] - 0s 740us/step\n",
      "36/36 [==============================] - 0s 667us/step\n",
      "36/36 [==============================] - 0s 637us/step\n",
      "36/36 [==============================] - 0s 636us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 588us/step\n",
      "179/179 [==============================] - 0s 585us/step\n",
      "179/179 [==============================] - 0s 563us/step\n",
      "179/179 [==============================] - 0s 533us/step\n",
      "179/179 [==============================] - 0s 577us/step\n",
      "36/36 [==============================] - 0s 679us/step\n",
      "36/36 [==============================] - 0s 615us/step\n",
      "36/36 [==============================] - 0s 648us/step\n",
      "36/36 [==============================] - 0s 616us/step\n",
      "36/36 [==============================] - 0s 701us/step\n",
      "1140\n",
      "drift has been detected models must be retrained\n",
      "some intersection\n",
      "finished\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6379 - accuracy: 0.3147 - val_loss: 2.9740 - val_accuracy: 0.0044\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1952 - accuracy: 0.4360 - val_loss: 4.9876 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0692 - accuracy: 0.5184 - val_loss: 5.9161 - val_accuracy: 0.0105\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0068 - accuracy: 0.5524 - val_loss: 6.3501 - val_accuracy: 0.0692\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9507 - accuracy: 0.5645 - val_loss: 6.5702 - val_accuracy: 0.0622\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9231 - accuracy: 0.5794 - val_loss: 7.1185 - val_accuracy: 0.0456\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9066 - accuracy: 0.5851 - val_loss: 7.2009 - val_accuracy: 0.0377\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8960 - accuracy: 0.5947 - val_loss: 7.2578 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8876 - accuracy: 0.5895 - val_loss: 7.6050 - val_accuracy: 0.0447\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8794 - accuracy: 0.5976 - val_loss: 7.4259 - val_accuracy: 0.0123\n",
      "0.5975877046585083\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6364 - accuracy: 0.3388 - val_loss: 3.1799 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1978 - accuracy: 0.4167 - val_loss: 4.8384 - val_accuracy: 0.0061\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0837 - accuracy: 0.4623 - val_loss: 5.8228 - val_accuracy: 0.0061\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0483 - accuracy: 0.5125 - val_loss: 6.1130 - val_accuracy: 0.0228\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0044 - accuracy: 0.5601 - val_loss: 6.6528 - val_accuracy: 0.0149\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9628 - accuracy: 0.5765 - val_loss: 6.8068 - val_accuracy: 0.0447\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9337 - accuracy: 0.5798 - val_loss: 6.9058 - val_accuracy: 0.0412\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9183 - accuracy: 0.5836 - val_loss: 7.3780 - val_accuracy: 0.0359\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9068 - accuracy: 0.5888 - val_loss: 7.2899 - val_accuracy: 0.0333\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8982 - accuracy: 0.5965 - val_loss: 7.4450 - val_accuracy: 0.0316\n",
      "0.5964912176132202\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6107 - accuracy: 0.3064 - val_loss: 3.0853 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1685 - accuracy: 0.4548 - val_loss: 4.9281 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0488 - accuracy: 0.5353 - val_loss: 5.9061 - val_accuracy: 0.0096\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9820 - accuracy: 0.5616 - val_loss: 6.4251 - val_accuracy: 0.0114\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9402 - accuracy: 0.5711 - val_loss: 6.7348 - val_accuracy: 0.0316\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9179 - accuracy: 0.5842 - val_loss: 6.8365 - val_accuracy: 0.0482\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9023 - accuracy: 0.5901 - val_loss: 7.0805 - val_accuracy: 0.0184\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8934 - accuracy: 0.5982 - val_loss: 7.2026 - val_accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8845 - accuracy: 0.5963 - val_loss: 7.5718 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8744 - accuracy: 0.6066 - val_loss: 7.5119 - val_accuracy: 0.0245\n",
      "0.6065789461135864\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6141 - accuracy: 0.3184 - val_loss: 2.9726 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1822 - accuracy: 0.4399 - val_loss: 4.8214 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0823 - accuracy: 0.4952 - val_loss: 5.5523 - val_accuracy: 0.0096\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0374 - accuracy: 0.5325 - val_loss: 5.8890 - val_accuracy: 0.0035\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9810 - accuracy: 0.5772 - val_loss: 6.1812 - val_accuracy: 0.0412\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9390 - accuracy: 0.5860 - val_loss: 6.3398 - val_accuracy: 0.0421\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9169 - accuracy: 0.5954 - val_loss: 6.7107 - val_accuracy: 0.0202\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9036 - accuracy: 0.5936 - val_loss: 6.5804 - val_accuracy: 0.0245\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8944 - accuracy: 0.5971 - val_loss: 6.8456 - val_accuracy: 0.0245\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8855 - accuracy: 0.5985 - val_loss: 7.0595 - val_accuracy: 0.0298\n",
      "0.5984649062156677\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6388 - accuracy: 0.2943 - val_loss: 3.0853 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2017 - accuracy: 0.4322 - val_loss: 4.6544 - val_accuracy: 0.0219\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0882 - accuracy: 0.4956 - val_loss: 5.6080 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0482 - accuracy: 0.5200 - val_loss: 6.0397 - val_accuracy: 0.0202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0080 - accuracy: 0.5522 - val_loss: 6.2343 - val_accuracy: 0.0429\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9683 - accuracy: 0.5735 - val_loss: 6.4835 - val_accuracy: 0.0228\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9376 - accuracy: 0.5853 - val_loss: 6.4315 - val_accuracy: 0.0324\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9200 - accuracy: 0.5814 - val_loss: 6.7196 - val_accuracy: 0.0202\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9069 - accuracy: 0.5950 - val_loss: 6.7605 - val_accuracy: 0.0307\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8981 - accuracy: 0.5956 - val_loss: 6.9959 - val_accuracy: 0.0289\n",
      "0.5956140160560608\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6191 - accuracy: 0.3167 - val_loss: 3.0807 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1802 - accuracy: 0.4263 - val_loss: 4.8059 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0789 - accuracy: 0.4623 - val_loss: 5.6806 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0504 - accuracy: 0.5151 - val_loss: 6.0716 - val_accuracy: 0.0473\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0165 - accuracy: 0.5417 - val_loss: 6.3213 - val_accuracy: 0.0412\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9753 - accuracy: 0.5697 - val_loss: 6.7225 - val_accuracy: 0.0228\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9400 - accuracy: 0.5765 - val_loss: 6.8355 - val_accuracy: 0.0368\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9237 - accuracy: 0.5846 - val_loss: 7.0369 - val_accuracy: 0.0386\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9093 - accuracy: 0.5890 - val_loss: 7.1361 - val_accuracy: 0.0280\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9010 - accuracy: 0.5910 - val_loss: 7.2802 - val_accuracy: 0.0342\n",
      "0.5910087823867798\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6272 - accuracy: 0.2961 - val_loss: 3.0532 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1747 - accuracy: 0.4360 - val_loss: 5.0444 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0771 - accuracy: 0.4717 - val_loss: 5.8514 - val_accuracy: 0.0088\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0414 - accuracy: 0.5314 - val_loss: 6.0878 - val_accuracy: 0.0526\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0003 - accuracy: 0.5568 - val_loss: 6.4858 - val_accuracy: 0.0570\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9619 - accuracy: 0.5599 - val_loss: 6.7799 - val_accuracy: 0.0491\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9333 - accuracy: 0.5816 - val_loss: 7.0396 - val_accuracy: 0.0324\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9185 - accuracy: 0.5928 - val_loss: 6.9976 - val_accuracy: 0.0307\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9048 - accuracy: 0.5963 - val_loss: 7.2142 - val_accuracy: 0.0298\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8957 - accuracy: 0.5963 - val_loss: 7.1674 - val_accuracy: 0.0359\n",
      "0.5962719321250916\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6472 - accuracy: 0.2794 - val_loss: 2.9722 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2105 - accuracy: 0.4250 - val_loss: 4.8307 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0897 - accuracy: 0.4713 - val_loss: 5.5280 - val_accuracy: 0.0289\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0551 - accuracy: 0.5230 - val_loss: 6.2982 - val_accuracy: 0.0070\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0160 - accuracy: 0.5559 - val_loss: 6.3603 - val_accuracy: 0.0456\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9731 - accuracy: 0.5787 - val_loss: 6.4317 - val_accuracy: 0.0473\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9393 - accuracy: 0.5750 - val_loss: 6.8526 - val_accuracy: 0.0237\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9229 - accuracy: 0.5866 - val_loss: 6.9920 - val_accuracy: 0.0543\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9127 - accuracy: 0.5901 - val_loss: 7.2949 - val_accuracy: 0.0333\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9041 - accuracy: 0.5952 - val_loss: 7.6229 - val_accuracy: 0.0272\n",
      "0.5951754450798035\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6064 - accuracy: 0.3037 - val_loss: 3.0947 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1714 - accuracy: 0.4432 - val_loss: 4.8413 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0711 - accuracy: 0.5039 - val_loss: 5.7415 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0254 - accuracy: 0.5522 - val_loss: 6.0901 - val_accuracy: 0.0228\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9813 - accuracy: 0.5713 - val_loss: 6.6334 - val_accuracy: 0.0210\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9465 - accuracy: 0.5901 - val_loss: 6.5260 - val_accuracy: 0.0421\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9180 - accuracy: 0.5910 - val_loss: 6.6863 - val_accuracy: 0.0272\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9033 - accuracy: 0.5952 - val_loss: 6.9019 - val_accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8936 - accuracy: 0.5961 - val_loss: 6.9520 - val_accuracy: 0.0237\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8809 - accuracy: 0.5941 - val_loss: 7.2479 - val_accuracy: 0.0324\n",
      "0.5940789580345154\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 2ms/step - loss: 1.6256 - accuracy: 0.2967 - val_loss: 3.1769 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1934 - accuracy: 0.4353 - val_loss: 4.8883 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0813 - accuracy: 0.4974 - val_loss: 5.5734 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0367 - accuracy: 0.5386 - val_loss: 6.0823 - val_accuracy: 0.0079\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9883 - accuracy: 0.5643 - val_loss: 6.4746 - val_accuracy: 0.0140\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9511 - accuracy: 0.5868 - val_loss: 6.6769 - val_accuracy: 0.0280\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9276 - accuracy: 0.5871 - val_loss: 6.7506 - val_accuracy: 0.0114\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9139 - accuracy: 0.5921 - val_loss: 6.8700 - val_accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9009 - accuracy: 0.5965 - val_loss: 6.9391 - val_accuracy: 0.0219\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8933 - accuracy: 0.5963 - val_loss: 7.0071 - val_accuracy: 0.0131\n",
      "0.5962719321250916\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6139 - accuracy: 0.3191 - val_loss: 3.0940 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1851 - accuracy: 0.4322 - val_loss: 4.8532 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0767 - accuracy: 0.5066 - val_loss: 5.7096 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0249 - accuracy: 0.5467 - val_loss: 6.0713 - val_accuracy: 0.0131\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9711 - accuracy: 0.5757 - val_loss: 6.4777 - val_accuracy: 0.0596\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9362 - accuracy: 0.5737 - val_loss: 6.8382 - val_accuracy: 0.0640\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9159 - accuracy: 0.5897 - val_loss: 6.9410 - val_accuracy: 0.0342\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9042 - accuracy: 0.5945 - val_loss: 6.8044 - val_accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8943 - accuracy: 0.5971 - val_loss: 7.1218 - val_accuracy: 0.0140\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8852 - accuracy: 0.5954 - val_loss: 7.0400 - val_accuracy: 0.0210\n",
      "0.5953947305679321\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6175 - accuracy: 0.3011 - val_loss: 3.0374 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1844 - accuracy: 0.4417 - val_loss: 4.7964 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0753 - accuracy: 0.5068 - val_loss: 5.7713 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0275 - accuracy: 0.5454 - val_loss: 6.1936 - val_accuracy: 0.0140\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9803 - accuracy: 0.5682 - val_loss: 6.4872 - val_accuracy: 0.0447\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9464 - accuracy: 0.5770 - val_loss: 6.4326 - val_accuracy: 0.0386\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9218 - accuracy: 0.5873 - val_loss: 6.3882 - val_accuracy: 0.0289\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9092 - accuracy: 0.5864 - val_loss: 7.0419 - val_accuracy: 0.0280\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8993 - accuracy: 0.5980 - val_loss: 6.8439 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8875 - accuracy: 0.5971 - val_loss: 7.2796 - val_accuracy: 0.0202\n",
      "0.597149133682251\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6327 - accuracy: 0.3057 - val_loss: 3.1375 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1878 - accuracy: 0.4237 - val_loss: 5.0075 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0812 - accuracy: 0.4857 - val_loss: 5.8278 - val_accuracy: 0.0123\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0438 - accuracy: 0.5395 - val_loss: 6.3237 - val_accuracy: 0.0727\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9949 - accuracy: 0.5491 - val_loss: 6.5913 - val_accuracy: 0.0727\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9531 - accuracy: 0.5682 - val_loss: 7.0036 - val_accuracy: 0.0613\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9263 - accuracy: 0.5770 - val_loss: 7.3855 - val_accuracy: 0.0578\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9109 - accuracy: 0.5836 - val_loss: 7.2131 - val_accuracy: 0.0429\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9011 - accuracy: 0.5904 - val_loss: 7.5381 - val_accuracy: 0.0394\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8923 - accuracy: 0.5958 - val_loss: 7.5829 - val_accuracy: 0.0368\n",
      "0.5958333611488342\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6138 - accuracy: 0.3061 - val_loss: 3.1004 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1724 - accuracy: 0.4618 - val_loss: 4.8329 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0529 - accuracy: 0.5355 - val_loss: 5.6971 - val_accuracy: 0.0070\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9801 - accuracy: 0.5660 - val_loss: 6.1708 - val_accuracy: 0.0508\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9393 - accuracy: 0.5794 - val_loss: 6.4084 - val_accuracy: 0.0298\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9173 - accuracy: 0.5864 - val_loss: 6.8300 - val_accuracy: 0.0219\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9047 - accuracy: 0.5939 - val_loss: 6.7063 - val_accuracy: 0.0316\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8939 - accuracy: 0.5965 - val_loss: 6.9332 - val_accuracy: 0.0114\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8847 - accuracy: 0.5978 - val_loss: 7.2344 - val_accuracy: 0.0079\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8791 - accuracy: 0.5985 - val_loss: 7.3736 - val_accuracy: 0.0105\n",
      "0.5984649062156677\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6354 - accuracy: 0.2998 - val_loss: 3.1080 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1975 - accuracy: 0.4307 - val_loss: 4.7669 - val_accuracy: 0.0096\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0881 - accuracy: 0.4853 - val_loss: 5.7668 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0535 - accuracy: 0.5243 - val_loss: 6.0954 - val_accuracy: 0.0088\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0144 - accuracy: 0.5610 - val_loss: 6.4638 - val_accuracy: 0.0771\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9680 - accuracy: 0.5741 - val_loss: 6.7972 - val_accuracy: 0.0675\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9370 - accuracy: 0.5774 - val_loss: 7.0462 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9192 - accuracy: 0.5857 - val_loss: 7.3659 - val_accuracy: 0.0351\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9051 - accuracy: 0.5936 - val_loss: 7.2467 - val_accuracy: 0.0447\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8911 - accuracy: 0.5963 - val_loss: 7.3835 - val_accuracy: 0.0333\n",
      "0.5962719321250916\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6262 - accuracy: 0.3000 - val_loss: 3.0981 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1803 - accuracy: 0.4325 - val_loss: 4.8781 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0763 - accuracy: 0.4693 - val_loss: 5.5661 - val_accuracy: 0.0105\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0400 - accuracy: 0.5406 - val_loss: 6.2310 - val_accuracy: 0.0517\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9967 - accuracy: 0.5500 - val_loss: 6.4829 - val_accuracy: 0.0833\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9538 - accuracy: 0.5706 - val_loss: 6.8320 - val_accuracy: 0.0228\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9294 - accuracy: 0.5807 - val_loss: 6.9695 - val_accuracy: 0.0403\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9120 - accuracy: 0.5871 - val_loss: 7.1581 - val_accuracy: 0.0245\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9014 - accuracy: 0.5996 - val_loss: 7.1563 - val_accuracy: 0.0280\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8919 - accuracy: 0.5954 - val_loss: 7.3124 - val_accuracy: 0.0254\n",
      "0.5953947305679321\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6410 - accuracy: 0.2989 - val_loss: 3.0533 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2030 - accuracy: 0.4419 - val_loss: 4.6665 - val_accuracy: 0.0053\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0853 - accuracy: 0.4925 - val_loss: 5.7192 - val_accuracy: 0.0035\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0428 - accuracy: 0.5263 - val_loss: 6.1838 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0030 - accuracy: 0.5586 - val_loss: 6.3603 - val_accuracy: 0.0158\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9584 - accuracy: 0.5820 - val_loss: 6.8666 - val_accuracy: 0.0245\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9282 - accuracy: 0.5862 - val_loss: 6.5790 - val_accuracy: 0.0324\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9119 - accuracy: 0.5923 - val_loss: 6.8413 - val_accuracy: 0.0280\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8987 - accuracy: 0.5985 - val_loss: 7.2971 - val_accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8889 - accuracy: 0.5965 - val_loss: 7.4226 - val_accuracy: 0.0552\n",
      "0.5964912176132202\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6341 - accuracy: 0.3009 - val_loss: 3.0635 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2031 - accuracy: 0.4283 - val_loss: 4.8257 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0896 - accuracy: 0.4800 - val_loss: 5.5867 - val_accuracy: 0.0035\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0446 - accuracy: 0.5289 - val_loss: 5.9906 - val_accuracy: 0.0473\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9963 - accuracy: 0.5601 - val_loss: 6.2827 - val_accuracy: 0.0351\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9534 - accuracy: 0.5783 - val_loss: 6.6764 - val_accuracy: 0.0447\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9314 - accuracy: 0.5888 - val_loss: 6.4727 - val_accuracy: 0.0210\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9115 - accuracy: 0.5941 - val_loss: 6.6469 - val_accuracy: 0.0508\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9009 - accuracy: 0.5934 - val_loss: 6.8934 - val_accuracy: 0.0377\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8929 - accuracy: 0.5980 - val_loss: 7.0875 - val_accuracy: 0.0202\n",
      "0.5980263352394104\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6239 - accuracy: 0.3118 - val_loss: 3.1437 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1754 - accuracy: 0.4583 - val_loss: 4.7669 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0635 - accuracy: 0.5320 - val_loss: 5.6458 - val_accuracy: 0.0272\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0099 - accuracy: 0.5583 - val_loss: 6.3464 - val_accuracy: 0.0307\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9634 - accuracy: 0.5649 - val_loss: 6.4206 - val_accuracy: 0.0394\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9312 - accuracy: 0.5811 - val_loss: 6.7433 - val_accuracy: 0.0447\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9131 - accuracy: 0.5840 - val_loss: 6.7521 - val_accuracy: 0.0368\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9004 - accuracy: 0.5866 - val_loss: 7.0184 - val_accuracy: 0.0245\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8891 - accuracy: 0.5998 - val_loss: 6.9722 - val_accuracy: 0.0272\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8815 - accuracy: 0.6055 - val_loss: 7.4019 - val_accuracy: 0.0272\n",
      "0.6054824590682983\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6397 - accuracy: 0.3086 - val_loss: 3.1377 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2065 - accuracy: 0.4482 - val_loss: 4.9720 - val_accuracy: 0.0096\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0757 - accuracy: 0.5204 - val_loss: 5.8155 - val_accuracy: 0.0070\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0144 - accuracy: 0.5458 - val_loss: 6.1190 - val_accuracy: 0.0824\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9596 - accuracy: 0.5599 - val_loss: 6.4710 - val_accuracy: 0.0254\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9294 - accuracy: 0.5838 - val_loss: 6.7215 - val_accuracy: 0.0263\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9140 - accuracy: 0.5831 - val_loss: 6.6995 - val_accuracy: 0.0245\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8982 - accuracy: 0.5901 - val_loss: 7.1002 - val_accuracy: 0.0412\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8899 - accuracy: 0.5943 - val_loss: 7.3262 - val_accuracy: 0.0210\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8825 - accuracy: 0.5952 - val_loss: 7.5252 - val_accuracy: 0.0307\n",
      "0.5951754450798035\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6099 - accuracy: 0.3149 - val_loss: 2.9953 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1686 - accuracy: 0.4314 - val_loss: 4.8076 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0738 - accuracy: 0.5053 - val_loss: 5.5179 - val_accuracy: 0.0657\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0271 - accuracy: 0.5638 - val_loss: 6.2112 - val_accuracy: 0.0272\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9738 - accuracy: 0.5638 - val_loss: 6.5575 - val_accuracy: 0.0578\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9379 - accuracy: 0.5704 - val_loss: 6.7284 - val_accuracy: 0.0561\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9167 - accuracy: 0.5893 - val_loss: 6.9131 - val_accuracy: 0.0561\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9050 - accuracy: 0.5941 - val_loss: 7.1277 - val_accuracy: 0.0710\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8937 - accuracy: 0.5987 - val_loss: 7.2945 - val_accuracy: 0.0368\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8830 - accuracy: 0.5991 - val_loss: 7.3977 - val_accuracy: 0.0324\n",
      "0.5991228222846985\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6203 - accuracy: 0.2967 - val_loss: 3.0869 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1866 - accuracy: 0.4362 - val_loss: 4.7751 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0763 - accuracy: 0.4947 - val_loss: 5.6146 - val_accuracy: 0.0131\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0219 - accuracy: 0.5502 - val_loss: 6.0737 - val_accuracy: 0.0403\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9677 - accuracy: 0.5572 - val_loss: 6.4940 - val_accuracy: 0.0535\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9373 - accuracy: 0.5770 - val_loss: 6.6493 - val_accuracy: 0.0386\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9198 - accuracy: 0.5893 - val_loss: 6.5703 - val_accuracy: 0.0324\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9072 - accuracy: 0.5917 - val_loss: 6.5492 - val_accuracy: 0.0298\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8995 - accuracy: 0.5908 - val_loss: 6.5980 - val_accuracy: 0.0202\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8889 - accuracy: 0.5941 - val_loss: 6.5319 - val_accuracy: 0.0131\n",
      "0.5940789580345154\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6403 - accuracy: 0.3105 - val_loss: 3.1187 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2202 - accuracy: 0.4239 - val_loss: 4.9078 - val_accuracy: 0.0044\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0926 - accuracy: 0.4798 - val_loss: 5.7130 - val_accuracy: 0.0079\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0517 - accuracy: 0.5202 - val_loss: 6.0909 - val_accuracy: 0.0596\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0136 - accuracy: 0.5544 - val_loss: 6.6209 - val_accuracy: 0.0403\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9695 - accuracy: 0.5726 - val_loss: 6.8306 - val_accuracy: 0.0543\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9355 - accuracy: 0.5825 - val_loss: 7.1927 - val_accuracy: 0.0237\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9156 - accuracy: 0.5921 - val_loss: 7.7471 - val_accuracy: 0.0473\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9023 - accuracy: 0.5906 - val_loss: 7.4266 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8913 - accuracy: 0.5976 - val_loss: 7.6694 - val_accuracy: 0.0272\n",
      "0.5975877046585083\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6344 - accuracy: 0.3044 - val_loss: 3.0667 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2028 - accuracy: 0.4364 - val_loss: 4.8088 - val_accuracy: 0.0026\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0878 - accuracy: 0.4693 - val_loss: 5.6991 - val_accuracy: 0.0140\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0489 - accuracy: 0.5112 - val_loss: 6.0946 - val_accuracy: 0.0289\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0103 - accuracy: 0.5575 - val_loss: 6.6967 - val_accuracy: 0.0342\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9632 - accuracy: 0.5713 - val_loss: 7.1057 - val_accuracy: 0.0219\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9333 - accuracy: 0.5800 - val_loss: 7.3884 - val_accuracy: 0.0245\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9153 - accuracy: 0.5807 - val_loss: 7.4443 - val_accuracy: 0.0280\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9023 - accuracy: 0.5947 - val_loss: 7.6103 - val_accuracy: 0.0316\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8926 - accuracy: 0.5952 - val_loss: 7.5037 - val_accuracy: 0.0351\n",
      "0.5951754450798035\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6083 - accuracy: 0.3094 - val_loss: 3.2149 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1612 - accuracy: 0.4594 - val_loss: 4.9483 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0453 - accuracy: 0.5349 - val_loss: 5.7189 - val_accuracy: 0.0640\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9819 - accuracy: 0.5564 - val_loss: 6.1183 - val_accuracy: 0.0570\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9436 - accuracy: 0.5763 - val_loss: 6.4561 - val_accuracy: 0.0351\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9232 - accuracy: 0.5763 - val_loss: 6.7314 - val_accuracy: 0.0561\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9093 - accuracy: 0.5809 - val_loss: 6.8395 - val_accuracy: 0.0342\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8999 - accuracy: 0.5901 - val_loss: 6.8523 - val_accuracy: 0.0377\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8907 - accuracy: 0.5954 - val_loss: 7.0490 - val_accuracy: 0.0237\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8812 - accuracy: 0.5958 - val_loss: 7.0578 - val_accuracy: 0.0237\n",
      "0.5958333611488342\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6200 - accuracy: 0.3186 - val_loss: 3.0388 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1734 - accuracy: 0.4261 - val_loss: 4.9381 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0765 - accuracy: 0.5013 - val_loss: 5.4943 - val_accuracy: 0.0421\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0345 - accuracy: 0.5340 - val_loss: 6.1240 - val_accuracy: 0.0833\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9819 - accuracy: 0.5502 - val_loss: 6.6501 - val_accuracy: 0.0394\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9387 - accuracy: 0.5667 - val_loss: 6.9648 - val_accuracy: 0.0421\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9143 - accuracy: 0.5825 - val_loss: 7.0638 - val_accuracy: 0.0482\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9024 - accuracy: 0.5895 - val_loss: 7.2446 - val_accuracy: 0.0368\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8908 - accuracy: 0.5976 - val_loss: 7.4133 - val_accuracy: 0.0394\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8780 - accuracy: 0.6031 - val_loss: 7.5816 - val_accuracy: 0.0298\n",
      "0.6030701994895935\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6353 - accuracy: 0.3077 - val_loss: 3.0525 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2066 - accuracy: 0.4202 - val_loss: 4.7922 - val_accuracy: 0.0105\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0908 - accuracy: 0.4719 - val_loss: 5.6026 - val_accuracy: 0.0035\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0568 - accuracy: 0.5127 - val_loss: 6.1833 - val_accuracy: 0.0123\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0227 - accuracy: 0.5425 - val_loss: 6.3541 - val_accuracy: 0.0552\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9826 - accuracy: 0.5678 - val_loss: 6.7360 - val_accuracy: 0.0692\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9488 - accuracy: 0.5776 - val_loss: 6.9521 - val_accuracy: 0.0377\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9269 - accuracy: 0.5827 - val_loss: 7.1715 - val_accuracy: 0.0307\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9122 - accuracy: 0.5893 - val_loss: 7.4614 - val_accuracy: 0.0500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9004 - accuracy: 0.5923 - val_loss: 7.6108 - val_accuracy: 0.0272\n",
      "0.5923245549201965\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6169 - accuracy: 0.3136 - val_loss: 2.9044 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1670 - accuracy: 0.4355 - val_loss: 4.7837 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0733 - accuracy: 0.5086 - val_loss: 5.5306 - val_accuracy: 0.0096\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0271 - accuracy: 0.5388 - val_loss: 6.0289 - val_accuracy: 0.0657\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9779 - accuracy: 0.5577 - val_loss: 6.5243 - val_accuracy: 0.0710\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9428 - accuracy: 0.5691 - val_loss: 6.6933 - val_accuracy: 0.0351\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9253 - accuracy: 0.5855 - val_loss: 6.7381 - val_accuracy: 0.0552\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9146 - accuracy: 0.5910 - val_loss: 6.9738 - val_accuracy: 0.0359\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8993 - accuracy: 0.5919 - val_loss: 7.1818 - val_accuracy: 0.0184\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8902 - accuracy: 0.5956 - val_loss: 7.1575 - val_accuracy: 0.0316\n",
      "0.5956140160560608\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 2ms/step - loss: 1.6249 - accuracy: 0.3033 - val_loss: 3.0562 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1813 - accuracy: 0.4346 - val_loss: 4.7621 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0805 - accuracy: 0.4754 - val_loss: 5.7263 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0511 - accuracy: 0.5235 - val_loss: 6.1505 - val_accuracy: 0.0053\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0128 - accuracy: 0.5629 - val_loss: 6.4697 - val_accuracy: 0.0070\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9695 - accuracy: 0.5728 - val_loss: 6.6683 - val_accuracy: 0.0727\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9360 - accuracy: 0.5866 - val_loss: 6.9337 - val_accuracy: 0.0167\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9193 - accuracy: 0.5917 - val_loss: 7.0793 - val_accuracy: 0.0289\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9072 - accuracy: 0.5963 - val_loss: 7.4455 - val_accuracy: 0.0386\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8950 - accuracy: 0.5969 - val_loss: 7.7606 - val_accuracy: 0.0403\n",
      "0.5969298481941223\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6387 - accuracy: 0.3219 - val_loss: 2.9465 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1973 - accuracy: 0.4208 - val_loss: 4.9644 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0838 - accuracy: 0.4893 - val_loss: 5.5570 - val_accuracy: 0.0219\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0477 - accuracy: 0.5154 - val_loss: 5.9094 - val_accuracy: 0.0149\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0107 - accuracy: 0.5491 - val_loss: 6.3010 - val_accuracy: 0.0096\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9754 - accuracy: 0.5787 - val_loss: 6.3866 - val_accuracy: 0.0158\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9483 - accuracy: 0.5849 - val_loss: 6.4864 - val_accuracy: 0.0202\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9273 - accuracy: 0.5943 - val_loss: 6.6391 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9154 - accuracy: 0.5956 - val_loss: 6.5025 - val_accuracy: 0.0359\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9055 - accuracy: 0.6000 - val_loss: 6.9478 - val_accuracy: 0.0351\n",
      "0.6000000238418579\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6411 - accuracy: 0.3026 - val_loss: 2.9574 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2088 - accuracy: 0.4281 - val_loss: 4.7565 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0892 - accuracy: 0.4838 - val_loss: 5.4249 - val_accuracy: 0.0167\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0513 - accuracy: 0.5156 - val_loss: 6.0355 - val_accuracy: 0.0044\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0076 - accuracy: 0.5546 - val_loss: 6.4075 - val_accuracy: 0.0307\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9681 - accuracy: 0.5682 - val_loss: 6.3500 - val_accuracy: 0.0272\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9371 - accuracy: 0.5829 - val_loss: 6.3646 - val_accuracy: 0.0640\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9187 - accuracy: 0.5816 - val_loss: 6.7869 - val_accuracy: 0.0587\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9097 - accuracy: 0.5884 - val_loss: 6.8683 - val_accuracy: 0.0351\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8968 - accuracy: 0.5967 - val_loss: 7.1958 - val_accuracy: 0.0359\n",
      "0.5967105031013489\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6200 - accuracy: 0.2893 - val_loss: 3.0560 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1676 - accuracy: 0.4285 - val_loss: 4.8643 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0734 - accuracy: 0.4943 - val_loss: 5.6392 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0301 - accuracy: 0.5507 - val_loss: 6.1235 - val_accuracy: 0.0517\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9791 - accuracy: 0.5570 - val_loss: 6.5147 - val_accuracy: 0.0491\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9395 - accuracy: 0.5678 - val_loss: 6.8747 - val_accuracy: 0.0596\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9198 - accuracy: 0.5844 - val_loss: 6.9781 - val_accuracy: 0.0526\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9062 - accuracy: 0.5853 - val_loss: 7.0717 - val_accuracy: 0.0500\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8943 - accuracy: 0.5950 - val_loss: 7.2081 - val_accuracy: 0.0438\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8851 - accuracy: 0.5982 - val_loss: 7.2973 - val_accuracy: 0.0298\n",
      "0.5982456207275391\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6361 - accuracy: 0.3103 - val_loss: 3.1093 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1976 - accuracy: 0.4355 - val_loss: 4.9662 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0797 - accuracy: 0.5031 - val_loss: 5.6039 - val_accuracy: 0.0061\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0296 - accuracy: 0.5425 - val_loss: 6.0733 - val_accuracy: 0.0429\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9763 - accuracy: 0.5704 - val_loss: 6.6337 - val_accuracy: 0.0692\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9397 - accuracy: 0.5792 - val_loss: 6.8517 - val_accuracy: 0.0368\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9191 - accuracy: 0.5886 - val_loss: 7.1885 - val_accuracy: 0.0482\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9037 - accuracy: 0.5996 - val_loss: 7.2680 - val_accuracy: 0.0500\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8938 - accuracy: 0.5980 - val_loss: 7.7197 - val_accuracy: 0.0465\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8871 - accuracy: 0.5965 - val_loss: 7.7998 - val_accuracy: 0.0386\n",
      "0.5964912176132202\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6331 - accuracy: 0.3013 - val_loss: 3.1036 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1880 - accuracy: 0.4314 - val_loss: 4.7574 - val_accuracy: 0.0053\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0641 - accuracy: 0.5206 - val_loss: 5.6314 - val_accuracy: 0.0175\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0041 - accuracy: 0.5537 - val_loss: 6.1765 - val_accuracy: 0.0175\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9539 - accuracy: 0.5730 - val_loss: 6.5146 - val_accuracy: 0.0421\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9282 - accuracy: 0.5785 - val_loss: 6.5920 - val_accuracy: 0.0482\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9128 - accuracy: 0.5842 - val_loss: 6.7506 - val_accuracy: 0.0394\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8981 - accuracy: 0.5882 - val_loss: 7.0503 - val_accuracy: 0.0429\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8893 - accuracy: 0.5919 - val_loss: 6.9138 - val_accuracy: 0.0298\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8812 - accuracy: 0.5963 - val_loss: 7.2634 - val_accuracy: 0.0254\n",
      "0.5962719321250916\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6314 - accuracy: 0.2879 - val_loss: 2.9442 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1857 - accuracy: 0.4311 - val_loss: 4.7901 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0783 - accuracy: 0.4943 - val_loss: 5.7187 - val_accuracy: 0.0061\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0337 - accuracy: 0.5333 - val_loss: 6.0799 - val_accuracy: 0.0280\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9797 - accuracy: 0.5533 - val_loss: 6.4598 - val_accuracy: 0.0552\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9402 - accuracy: 0.5654 - val_loss: 6.7586 - val_accuracy: 0.0561\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9196 - accuracy: 0.5851 - val_loss: 6.9672 - val_accuracy: 0.0289\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9061 - accuracy: 0.5906 - val_loss: 7.3261 - val_accuracy: 0.0438\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8954 - accuracy: 0.5928 - val_loss: 7.3644 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8865 - accuracy: 0.5989 - val_loss: 7.5170 - val_accuracy: 0.0394\n",
      "0.5989035367965698\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6209 - accuracy: 0.3029 - val_loss: 3.0409 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1792 - accuracy: 0.4329 - val_loss: 4.7650 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0737 - accuracy: 0.4921 - val_loss: 5.6860 - val_accuracy: 0.0482\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0211 - accuracy: 0.5461 - val_loss: 6.3091 - val_accuracy: 0.0675\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9655 - accuracy: 0.5596 - val_loss: 6.7052 - val_accuracy: 0.0815\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9331 - accuracy: 0.5651 - val_loss: 6.8383 - val_accuracy: 0.0543\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9149 - accuracy: 0.5884 - val_loss: 7.0671 - val_accuracy: 0.0456\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9001 - accuracy: 0.5853 - val_loss: 7.2178 - val_accuracy: 0.0272\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8910 - accuracy: 0.5998 - val_loss: 7.3724 - val_accuracy: 0.0307\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8833 - accuracy: 0.5969 - val_loss: 7.1513 - val_accuracy: 0.0491\n",
      "0.5969298481941223\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6332 - accuracy: 0.3022 - val_loss: 3.0251 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1922 - accuracy: 0.4237 - val_loss: 4.8393 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0881 - accuracy: 0.4673 - val_loss: 5.5463 - val_accuracy: 0.0105\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0528 - accuracy: 0.5151 - val_loss: 6.1751 - val_accuracy: 0.0219\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0177 - accuracy: 0.5428 - val_loss: 6.4041 - val_accuracy: 0.0386\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9758 - accuracy: 0.5711 - val_loss: 6.6343 - val_accuracy: 0.0149\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9440 - accuracy: 0.5800 - val_loss: 6.8101 - val_accuracy: 0.0175\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9256 - accuracy: 0.5890 - val_loss: 6.9624 - val_accuracy: 0.0263\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9116 - accuracy: 0.5906 - val_loss: 7.0602 - val_accuracy: 0.0351\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9012 - accuracy: 0.5971 - val_loss: 7.3703 - val_accuracy: 0.0421\n",
      "0.597149133682251\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6215 - accuracy: 0.3101 - val_loss: 3.0162 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1811 - accuracy: 0.4307 - val_loss: 4.7763 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0862 - accuracy: 0.4939 - val_loss: 5.4523 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0535 - accuracy: 0.5248 - val_loss: 5.9046 - val_accuracy: 0.0263\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0151 - accuracy: 0.5489 - val_loss: 6.2395 - val_accuracy: 0.0552\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9726 - accuracy: 0.5770 - val_loss: 6.7170 - val_accuracy: 0.0175\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9398 - accuracy: 0.5838 - val_loss: 6.9362 - val_accuracy: 0.0219\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9188 - accuracy: 0.5934 - val_loss: 7.0731 - val_accuracy: 0.0403\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9081 - accuracy: 0.5921 - val_loss: 7.4609 - val_accuracy: 0.0254\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8962 - accuracy: 0.6002 - val_loss: 7.5855 - val_accuracy: 0.0394\n",
      "0.6002193093299866\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6315 - accuracy: 0.3081 - val_loss: 3.1121 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1899 - accuracy: 0.4371 - val_loss: 4.9627 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0792 - accuracy: 0.5039 - val_loss: 5.7215 - val_accuracy: 0.0491\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0260 - accuracy: 0.5511 - val_loss: 6.1752 - val_accuracy: 0.0815\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9689 - accuracy: 0.5614 - val_loss: 6.7295 - val_accuracy: 0.0789\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9344 - accuracy: 0.5704 - val_loss: 6.9271 - val_accuracy: 0.0210\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9151 - accuracy: 0.5886 - val_loss: 6.8351 - val_accuracy: 0.0587\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9017 - accuracy: 0.5851 - val_loss: 7.2521 - val_accuracy: 0.0131\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8959 - accuracy: 0.5952 - val_loss: 7.1524 - val_accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8848 - accuracy: 0.5939 - val_loss: 7.5534 - val_accuracy: 0.0351\n",
      "0.5938596725463867\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6214 - accuracy: 0.3077 - val_loss: 3.0476 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1933 - accuracy: 0.4537 - val_loss: 4.7753 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0573 - accuracy: 0.5353 - val_loss: 5.5540 - val_accuracy: 0.0824\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9866 - accuracy: 0.5524 - val_loss: 6.2254 - val_accuracy: 0.0403\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9477 - accuracy: 0.5706 - val_loss: 6.6465 - val_accuracy: 0.0447\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9282 - accuracy: 0.5803 - val_loss: 6.8387 - val_accuracy: 0.0429\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9168 - accuracy: 0.5831 - val_loss: 6.6397 - val_accuracy: 0.0429\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9040 - accuracy: 0.5849 - val_loss: 6.7777 - val_accuracy: 0.0465\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8952 - accuracy: 0.5943 - val_loss: 6.7343 - val_accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8929 - accuracy: 0.5917 - val_loss: 6.9029 - val_accuracy: 0.0245\n",
      "0.5916666388511658\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6401 - accuracy: 0.3123 - val_loss: 3.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2006 - accuracy: 0.4230 - val_loss: 4.9103 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0840 - accuracy: 0.4809 - val_loss: 5.6442 - val_accuracy: 0.0140\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0427 - accuracy: 0.5298 - val_loss: 6.0066 - val_accuracy: 0.0482\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0028 - accuracy: 0.5577 - val_loss: 6.4619 - val_accuracy: 0.0535\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9610 - accuracy: 0.5785 - val_loss: 6.6700 - val_accuracy: 0.0719\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9339 - accuracy: 0.5800 - val_loss: 6.9950 - val_accuracy: 0.0359\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9187 - accuracy: 0.5910 - val_loss: 7.1668 - val_accuracy: 0.0316\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9042 - accuracy: 0.5919 - val_loss: 7.2983 - val_accuracy: 0.0386\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8951 - accuracy: 0.5982 - val_loss: 7.6434 - val_accuracy: 0.0228\n",
      "0.5982456207275391\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6082 - accuracy: 0.2991 - val_loss: 3.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1698 - accuracy: 0.4340 - val_loss: 4.9368 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0827 - accuracy: 0.4715 - val_loss: 5.6576 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0483 - accuracy: 0.5189 - val_loss: 6.2607 - val_accuracy: 0.0026\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0095 - accuracy: 0.5493 - val_loss: 6.3765 - val_accuracy: 0.0605\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9696 - accuracy: 0.5721 - val_loss: 6.7463 - val_accuracy: 0.0465\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9411 - accuracy: 0.5871 - val_loss: 6.7480 - val_accuracy: 0.0412\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9209 - accuracy: 0.5967 - val_loss: 7.0552 - val_accuracy: 0.0307\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9093 - accuracy: 0.5952 - val_loss: 7.1941 - val_accuracy: 0.0368\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9007 - accuracy: 0.5991 - val_loss: 7.2714 - val_accuracy: 0.0316\n",
      "0.5991228222846985\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6126 - accuracy: 0.3007 - val_loss: 3.0233 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1652 - accuracy: 0.4346 - val_loss: 4.9130 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0780 - accuracy: 0.4732 - val_loss: 5.6575 - val_accuracy: 0.0316\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0440 - accuracy: 0.5274 - val_loss: 6.2187 - val_accuracy: 0.0289\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0043 - accuracy: 0.5579 - val_loss: 6.6860 - val_accuracy: 0.0394\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9639 - accuracy: 0.5822 - val_loss: 6.8873 - val_accuracy: 0.0351\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9346 - accuracy: 0.5844 - val_loss: 7.2049 - val_accuracy: 0.0333\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9185 - accuracy: 0.5954 - val_loss: 7.3187 - val_accuracy: 0.0631\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9062 - accuracy: 0.5978 - val_loss: 7.4769 - val_accuracy: 0.0552\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8930 - accuracy: 0.6044 - val_loss: 7.6696 - val_accuracy: 0.0316\n",
      "0.6043859720230103\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6340 - accuracy: 0.3114 - val_loss: 3.0645 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2036 - accuracy: 0.4305 - val_loss: 4.8621 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0806 - accuracy: 0.5125 - val_loss: 5.6591 - val_accuracy: 0.0727\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0235 - accuracy: 0.5366 - val_loss: 6.3147 - val_accuracy: 0.0701\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9677 - accuracy: 0.5561 - val_loss: 6.7788 - val_accuracy: 0.0543\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9336 - accuracy: 0.5724 - val_loss: 6.9613 - val_accuracy: 0.0438\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9157 - accuracy: 0.5963 - val_loss: 7.3293 - val_accuracy: 0.0394\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9059 - accuracy: 0.5855 - val_loss: 7.2312 - val_accuracy: 0.0403\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8940 - accuracy: 0.5943 - val_loss: 7.2523 - val_accuracy: 0.0245\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8860 - accuracy: 0.5980 - val_loss: 7.1192 - val_accuracy: 0.0237\n",
      "0.5980263352394104\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6337 - accuracy: 0.3118 - val_loss: 3.0921 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1964 - accuracy: 0.4300 - val_loss: 4.9029 - val_accuracy: 0.0131\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0832 - accuracy: 0.4836 - val_loss: 5.7220 - val_accuracy: 0.0631\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0376 - accuracy: 0.5421 - val_loss: 6.2678 - val_accuracy: 0.0605\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9876 - accuracy: 0.5557 - val_loss: 6.6314 - val_accuracy: 0.0719\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9488 - accuracy: 0.5550 - val_loss: 7.0758 - val_accuracy: 0.0622\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9233 - accuracy: 0.5765 - val_loss: 6.8985 - val_accuracy: 0.0631\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9098 - accuracy: 0.5893 - val_loss: 7.5045 - val_accuracy: 0.0377\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8962 - accuracy: 0.5963 - val_loss: 7.5318 - val_accuracy: 0.0272\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8894 - accuracy: 0.6015 - val_loss: 7.6318 - val_accuracy: 0.0219\n",
      "0.6015350818634033\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6187 - accuracy: 0.3064 - val_loss: 3.0937 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1795 - accuracy: 0.4564 - val_loss: 4.7242 - val_accuracy: 0.0026\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0498 - accuracy: 0.5252 - val_loss: 5.9504 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9844 - accuracy: 0.5555 - val_loss: 6.3275 - val_accuracy: 0.0368\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9497 - accuracy: 0.5697 - val_loss: 6.6644 - val_accuracy: 0.0377\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9300 - accuracy: 0.5750 - val_loss: 6.8793 - val_accuracy: 0.0298\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9176 - accuracy: 0.5842 - val_loss: 6.7973 - val_accuracy: 0.0465\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9080 - accuracy: 0.5860 - val_loss: 6.9105 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9005 - accuracy: 0.5890 - val_loss: 7.0316 - val_accuracy: 0.0272\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8919 - accuracy: 0.5971 - val_loss: 6.9736 - val_accuracy: 0.0245\n",
      "0.597149133682251\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6309 - accuracy: 0.3090 - val_loss: 3.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1788 - accuracy: 0.4294 - val_loss: 4.8915 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0757 - accuracy: 0.4879 - val_loss: 5.7285 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0283 - accuracy: 0.5410 - val_loss: 6.0001 - val_accuracy: 0.0789\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9796 - accuracy: 0.5583 - val_loss: 6.4481 - val_accuracy: 0.0465\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9431 - accuracy: 0.5739 - val_loss: 6.7522 - val_accuracy: 0.0649\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9213 - accuracy: 0.5884 - val_loss: 6.9373 - val_accuracy: 0.0403\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9076 - accuracy: 0.5879 - val_loss: 7.1192 - val_accuracy: 0.0237\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8956 - accuracy: 0.5956 - val_loss: 6.9463 - val_accuracy: 0.0237\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8890 - accuracy: 0.5965 - val_loss: 7.3869 - val_accuracy: 0.0447\n",
      "0.5964912176132202\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 2ms/step - loss: 1.6395 - accuracy: 0.3018 - val_loss: 3.0129 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2061 - accuracy: 0.4263 - val_loss: 4.9304 - val_accuracy: 0.0044\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0842 - accuracy: 0.4667 - val_loss: 5.7004 - val_accuracy: 0.0053\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0514 - accuracy: 0.5114 - val_loss: 6.3217 - val_accuracy: 0.0061\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0165 - accuracy: 0.5390 - val_loss: 6.3829 - val_accuracy: 0.0175\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9720 - accuracy: 0.5629 - val_loss: 6.2751 - val_accuracy: 0.0762\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9387 - accuracy: 0.5833 - val_loss: 6.8100 - val_accuracy: 0.0140\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9190 - accuracy: 0.5919 - val_loss: 7.0380 - val_accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9077 - accuracy: 0.5928 - val_loss: 7.2136 - val_accuracy: 0.0149\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8958 - accuracy: 0.5936 - val_loss: 7.6632 - val_accuracy: 0.0245\n",
      "0.5936403274536133\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6359 - accuracy: 0.3046 - val_loss: 3.0434 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2054 - accuracy: 0.4320 - val_loss: 4.7849 - val_accuracy: 0.0061\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0887 - accuracy: 0.4893 - val_loss: 5.6066 - val_accuracy: 0.0123\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0449 - accuracy: 0.5248 - val_loss: 5.9368 - val_accuracy: 0.0026\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9995 - accuracy: 0.5627 - val_loss: 6.1442 - val_accuracy: 0.0456\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9545 - accuracy: 0.5770 - val_loss: 6.5100 - val_accuracy: 0.0333\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9263 - accuracy: 0.5827 - val_loss: 6.6595 - val_accuracy: 0.0316\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9108 - accuracy: 0.5996 - val_loss: 6.8361 - val_accuracy: 0.0412\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8991 - accuracy: 0.5996 - val_loss: 6.9342 - val_accuracy: 0.0482\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8873 - accuracy: 0.5967 - val_loss: 7.0443 - val_accuracy: 0.0351\n",
      "0.5967105031013489\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6377 - accuracy: 0.3072 - val_loss: 3.0579 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2024 - accuracy: 0.4186 - val_loss: 4.8497 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0784 - accuracy: 0.5112 - val_loss: 5.5611 - val_accuracy: 0.0622\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0196 - accuracy: 0.5498 - val_loss: 6.2900 - val_accuracy: 0.0613\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9634 - accuracy: 0.5599 - val_loss: 6.5992 - val_accuracy: 0.0596\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9304 - accuracy: 0.5805 - val_loss: 6.9485 - val_accuracy: 0.0412\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9143 - accuracy: 0.5875 - val_loss: 7.2119 - val_accuracy: 0.0500\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9007 - accuracy: 0.5875 - val_loss: 7.3647 - val_accuracy: 0.0228\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8924 - accuracy: 0.5912 - val_loss: 7.4898 - val_accuracy: 0.0175\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8834 - accuracy: 0.5991 - val_loss: 7.5013 - val_accuracy: 0.0386\n",
      "0.5991228222846985\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:85: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yhn tk\n",
      "1\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "125/125 [==============================] - 0s 751us/step - loss: 2.5037 - accuracy: 0.4388\n",
      "54/54 [==============================] - 0s 737us/step - loss: 2.3675 - accuracy: 0.4442\n",
      "125/125 [==============================] - 0s 684us/step - loss: 2.5409 - accuracy: 0.4371\n",
      "54/54 [==============================] - 0s 696us/step - loss: 2.4080 - accuracy: 0.4255\n",
      "125/125 [==============================] - 0s 719us/step - loss: 2.5557 - accuracy: 0.4321\n",
      "54/54 [==============================] - 0s 722us/step - loss: 2.4255 - accuracy: 0.4214\n",
      "125/125 [==============================] - 0s 706us/step - loss: 2.3347 - accuracy: 0.4095\n",
      "54/54 [==============================] - 0s 737us/step - loss: 2.2174 - accuracy: 0.4173\n",
      "125/125 [==============================] - 0s 707us/step - loss: 2.4669 - accuracy: 0.4321\n",
      "54/54 [==============================] - 0s 687us/step - loss: 2.3373 - accuracy: 0.4354\n",
      "36/36 [==============================] - 0s 649us/step\n",
      "36/36 [==============================] - 0s 648us/step\n",
      "36/36 [==============================] - 0s 588us/step\n",
      "36/36 [==============================] - 0s 605us/step\n",
      "36/36 [==============================] - 0s 598us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 599us/step\n",
      "179/179 [==============================] - 0s 569us/step\n",
      "179/179 [==============================] - 0s 546us/step\n",
      "179/179 [==============================] - 0s 532us/step\n",
      "179/179 [==============================] - 0s 567us/step\n",
      "36/36 [==============================] - 0s 644us/step\n",
      "36/36 [==============================] - 0s 673us/step\n",
      "36/36 [==============================] - 0s 646us/step\n",
      "36/36 [==============================] - 0s 591us/step\n",
      "36/36 [==============================] - 0s 573us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 610us/step\n",
      "179/179 [==============================] - 0s 586us/step\n",
      "179/179 [==============================] - 0s 561us/step\n",
      "179/179 [==============================] - 0s 573us/step\n",
      "179/179 [==============================] - 0s 594us/step\n",
      "36/36 [==============================] - 0s 670us/step\n",
      "36/36 [==============================] - 0s 655us/step\n",
      "36/36 [==============================] - 0s 621us/step\n",
      "36/36 [==============================] - 0s 601us/step\n",
      "36/36 [==============================] - 0s 598us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 562us/step\n",
      "179/179 [==============================] - 0s 561us/step\n",
      "179/179 [==============================] - 0s 615us/step\n",
      "179/179 [==============================] - 0s 605us/step\n",
      "179/179 [==============================] - 0s 585us/step\n",
      "36/36 [==============================] - 0s 682us/step\n",
      "36/36 [==============================] - 0s 618us/step\n",
      "36/36 [==============================] - 0s 588us/step\n",
      "36/36 [==============================] - 0s 573us/step\n",
      "36/36 [==============================] - 0s 575us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 588us/step\n",
      "179/179 [==============================] - 0s 539us/step\n",
      "179/179 [==============================] - 0s 571us/step\n",
      "179/179 [==============================] - 0s 561us/step\n",
      "179/179 [==============================] - 0s 560us/step\n",
      "36/36 [==============================] - 0s 634us/step\n",
      "36/36 [==============================] - 0s 588us/step\n",
      "36/36 [==============================] - 0s 950us/step\n",
      "36/36 [==============================] - 0s 560us/step\n",
      "36/36 [==============================] - 0s 594us/step\n",
      "1140\n",
      "drift has been detected models must be retrained\n",
      "some intersection\n",
      "finished\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6220 - accuracy: 0.3022 - val_loss: 3.0797 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1717 - accuracy: 0.4338 - val_loss: 4.8052 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0809 - accuracy: 0.4855 - val_loss: 5.5560 - val_accuracy: 0.0035\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0492 - accuracy: 0.5178 - val_loss: 6.0399 - val_accuracy: 0.0035\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0171 - accuracy: 0.5507 - val_loss: 6.2895 - val_accuracy: 0.0053\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9770 - accuracy: 0.5719 - val_loss: 6.5569 - val_accuracy: 0.0578\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9460 - accuracy: 0.5846 - val_loss: 6.7163 - val_accuracy: 0.0473\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9283 - accuracy: 0.5884 - val_loss: 6.9856 - val_accuracy: 0.0368\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9157 - accuracy: 0.5941 - val_loss: 7.1960 - val_accuracy: 0.0359\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9043 - accuracy: 0.6000 - val_loss: 7.4062 - val_accuracy: 0.0324\n",
      "0.6000000238418579\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6306 - accuracy: 0.2888 - val_loss: 3.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1931 - accuracy: 0.4596 - val_loss: 4.7023 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0712 - accuracy: 0.5346 - val_loss: 5.6430 - val_accuracy: 0.1060\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0128 - accuracy: 0.5566 - val_loss: 6.2296 - val_accuracy: 0.0465\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9638 - accuracy: 0.5548 - val_loss: 6.4984 - val_accuracy: 0.0868\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9342 - accuracy: 0.5724 - val_loss: 6.9047 - val_accuracy: 0.0482\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9196 - accuracy: 0.5897 - val_loss: 6.9087 - val_accuracy: 0.0552\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9059 - accuracy: 0.5928 - val_loss: 6.8089 - val_accuracy: 0.0228\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8964 - accuracy: 0.5914 - val_loss: 6.8898 - val_accuracy: 0.0465\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8887 - accuracy: 0.5943 - val_loss: 7.1641 - val_accuracy: 0.0386\n",
      "0.594298243522644\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6369 - accuracy: 0.3033 - val_loss: 3.1844 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1991 - accuracy: 0.4338 - val_loss: 4.7938 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0850 - accuracy: 0.4846 - val_loss: 5.6684 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0368 - accuracy: 0.5322 - val_loss: 6.1956 - val_accuracy: 0.0307\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9836 - accuracy: 0.5682 - val_loss: 6.5998 - val_accuracy: 0.0307\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9395 - accuracy: 0.5811 - val_loss: 6.8304 - val_accuracy: 0.0438\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9174 - accuracy: 0.5897 - val_loss: 7.0449 - val_accuracy: 0.0263\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9050 - accuracy: 0.5923 - val_loss: 7.1628 - val_accuracy: 0.0167\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8934 - accuracy: 0.5987 - val_loss: 7.1917 - val_accuracy: 0.0123\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8855 - accuracy: 0.5993 - val_loss: 7.4576 - val_accuracy: 0.0140\n",
      "0.5993421077728271\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6371 - accuracy: 0.3046 - val_loss: 3.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1955 - accuracy: 0.4186 - val_loss: 4.7572 - val_accuracy: 0.0298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0792 - accuracy: 0.4741 - val_loss: 5.6484 - val_accuracy: 0.0210\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0340 - accuracy: 0.5371 - val_loss: 6.1271 - val_accuracy: 0.0666\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9841 - accuracy: 0.5513 - val_loss: 6.3779 - val_accuracy: 0.0517\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9412 - accuracy: 0.5759 - val_loss: 6.8955 - val_accuracy: 0.0578\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9181 - accuracy: 0.5829 - val_loss: 6.8734 - val_accuracy: 0.0605\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9044 - accuracy: 0.5906 - val_loss: 7.2123 - val_accuracy: 0.0377\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8931 - accuracy: 0.5952 - val_loss: 7.3049 - val_accuracy: 0.0543\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8841 - accuracy: 0.5993 - val_loss: 7.3759 - val_accuracy: 0.0701\n",
      "0.5993421077728271\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6239 - accuracy: 0.3132 - val_loss: 3.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1767 - accuracy: 0.4340 - val_loss: 4.7822 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0609 - accuracy: 0.5364 - val_loss: 5.7114 - val_accuracy: 0.0806\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9975 - accuracy: 0.5612 - val_loss: 6.2941 - val_accuracy: 0.0859\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9520 - accuracy: 0.5570 - val_loss: 6.7233 - val_accuracy: 0.0929\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9240 - accuracy: 0.5779 - val_loss: 7.0041 - val_accuracy: 0.0219\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9086 - accuracy: 0.5864 - val_loss: 6.8397 - val_accuracy: 0.0429\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8942 - accuracy: 0.5943 - val_loss: 6.9368 - val_accuracy: 0.0394\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8867 - accuracy: 0.5952 - val_loss: 7.0209 - val_accuracy: 0.0394\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8781 - accuracy: 0.6011 - val_loss: 7.2319 - val_accuracy: 0.0245\n",
      "0.601096510887146\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6532 - accuracy: 0.2947 - val_loss: 3.0204 - val_accuracy: 8.7642e-04\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2220 - accuracy: 0.4279 - val_loss: 4.8186 - val_accuracy: 0.0070\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0825 - accuracy: 0.5018 - val_loss: 5.6804 - val_accuracy: 0.0053\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0271 - accuracy: 0.5504 - val_loss: 6.1763 - val_accuracy: 0.0552\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9723 - accuracy: 0.5507 - val_loss: 6.6201 - val_accuracy: 0.0263\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9411 - accuracy: 0.5774 - val_loss: 6.7487 - val_accuracy: 0.0412\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9241 - accuracy: 0.5831 - val_loss: 6.9734 - val_accuracy: 0.0429\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9130 - accuracy: 0.5917 - val_loss: 7.2401 - val_accuracy: 0.0359\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9019 - accuracy: 0.5882 - val_loss: 7.4083 - val_accuracy: 0.0316\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8944 - accuracy: 0.5879 - val_loss: 7.5101 - val_accuracy: 0.0298\n",
      "0.5879386067390442\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6431 - accuracy: 0.3033 - val_loss: 3.0926 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2017 - accuracy: 0.4254 - val_loss: 4.8536 - val_accuracy: 0.0377\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0790 - accuracy: 0.4866 - val_loss: 5.6470 - val_accuracy: 0.0202\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0316 - accuracy: 0.5406 - val_loss: 6.2577 - val_accuracy: 8.7642e-04\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9839 - accuracy: 0.5643 - val_loss: 6.4447 - val_accuracy: 0.0394\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9456 - accuracy: 0.5735 - val_loss: 6.7694 - val_accuracy: 0.0386\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9276 - accuracy: 0.5860 - val_loss: 6.9901 - val_accuracy: 0.0272\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9103 - accuracy: 0.5934 - val_loss: 7.3623 - val_accuracy: 0.0368\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8991 - accuracy: 0.5976 - val_loss: 7.4560 - val_accuracy: 0.0237\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8940 - accuracy: 0.5954 - val_loss: 7.7301 - val_accuracy: 0.0351\n",
      "0.5953947305679321\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6166 - accuracy: 0.3079 - val_loss: 3.1058 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1735 - accuracy: 0.4215 - val_loss: 4.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0769 - accuracy: 0.4660 - val_loss: 5.7488 - val_accuracy: 0.0210\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0370 - accuracy: 0.5408 - val_loss: 6.1319 - val_accuracy: 0.0640\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9902 - accuracy: 0.5577 - val_loss: 6.7010 - val_accuracy: 0.0745\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9450 - accuracy: 0.5645 - val_loss: 7.0379 - val_accuracy: 0.0263\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9187 - accuracy: 0.5921 - val_loss: 7.1670 - val_accuracy: 0.0684\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9031 - accuracy: 0.5906 - val_loss: 7.4466 - val_accuracy: 0.0228\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8931 - accuracy: 0.6022 - val_loss: 7.5187 - val_accuracy: 0.0684\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8871 - accuracy: 0.6031 - val_loss: 7.6566 - val_accuracy: 0.0342\n",
      "0.6030701994895935\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6326 - accuracy: 0.3197 - val_loss: 3.1151 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1908 - accuracy: 0.4357 - val_loss: 4.8100 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0741 - accuracy: 0.5272 - val_loss: 5.6407 - val_accuracy: 0.0570\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0144 - accuracy: 0.5546 - val_loss: 6.4101 - val_accuracy: 0.0780\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9616 - accuracy: 0.5544 - val_loss: 6.4790 - val_accuracy: 0.0491\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9261 - accuracy: 0.5772 - val_loss: 6.9538 - val_accuracy: 0.0298\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9104 - accuracy: 0.5855 - val_loss: 6.9064 - val_accuracy: 0.0307\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8980 - accuracy: 0.5943 - val_loss: 7.0081 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8904 - accuracy: 0.5976 - val_loss: 7.2178 - val_accuracy: 0.0517\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8805 - accuracy: 0.5978 - val_loss: 7.2774 - val_accuracy: 0.0307\n",
      "0.597806990146637\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6348 - accuracy: 0.3053 - val_loss: 2.9943 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2079 - accuracy: 0.4217 - val_loss: 4.6108 - val_accuracy: 0.0061\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0907 - accuracy: 0.4954 - val_loss: 5.5141 - val_accuracy: 0.0061\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0493 - accuracy: 0.5230 - val_loss: 6.0046 - val_accuracy: 0.0123\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0080 - accuracy: 0.5553 - val_loss: 6.2885 - val_accuracy: 0.0053\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9671 - accuracy: 0.5737 - val_loss: 6.4187 - val_accuracy: 0.0140\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9408 - accuracy: 0.5882 - val_loss: 6.1520 - val_accuracy: 0.0210\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9226 - accuracy: 0.5893 - val_loss: 6.5591 - val_accuracy: 0.0412\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9080 - accuracy: 0.5982 - val_loss: 6.6974 - val_accuracy: 0.0193\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8964 - accuracy: 0.5993 - val_loss: 6.8480 - val_accuracy: 0.0219\n",
      "0.5993421077728271\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6140 - accuracy: 0.3042 - val_loss: 3.0376 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1830 - accuracy: 0.4441 - val_loss: 4.8733 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0762 - accuracy: 0.5053 - val_loss: 5.6341 - val_accuracy: 0.0018\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0282 - accuracy: 0.5463 - val_loss: 6.1366 - val_accuracy: 0.0061\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9709 - accuracy: 0.5669 - val_loss: 6.2443 - val_accuracy: 0.0552\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9328 - accuracy: 0.5825 - val_loss: 6.4341 - val_accuracy: 0.0368\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9143 - accuracy: 0.5879 - val_loss: 6.5649 - val_accuracy: 0.0316\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9004 - accuracy: 0.5906 - val_loss: 6.5605 - val_accuracy: 0.0368\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8892 - accuracy: 0.5993 - val_loss: 6.8421 - val_accuracy: 0.0263\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8828 - accuracy: 0.5993 - val_loss: 6.8975 - val_accuracy: 0.0167\n",
      "0.5993421077728271\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6472 - accuracy: 0.2860 - val_loss: 3.1582 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2424 - accuracy: 0.4143 - val_loss: 4.8971 - val_accuracy: 0.0096\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1024 - accuracy: 0.4640 - val_loss: 5.6109 - val_accuracy: 0.0447\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0653 - accuracy: 0.4950 - val_loss: 6.3062 - val_accuracy: 0.0061\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0310 - accuracy: 0.5417 - val_loss: 6.3586 - val_accuracy: 0.0771\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9844 - accuracy: 0.5625 - val_loss: 6.5462 - val_accuracy: 0.0815\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9494 - accuracy: 0.5735 - val_loss: 7.0121 - val_accuracy: 0.0386\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9309 - accuracy: 0.5862 - val_loss: 7.1438 - val_accuracy: 0.0245\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9189 - accuracy: 0.5884 - val_loss: 7.2290 - val_accuracy: 0.0438\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9080 - accuracy: 0.5930 - val_loss: 7.4088 - val_accuracy: 0.0228\n",
      "0.5929824709892273\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6235 - accuracy: 0.3002 - val_loss: 3.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1730 - accuracy: 0.4857 - val_loss: 4.8594 - val_accuracy: 0.0044\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0517 - accuracy: 0.5487 - val_loss: 5.6926 - val_accuracy: 0.0377\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9853 - accuracy: 0.5544 - val_loss: 6.2359 - val_accuracy: 0.0421\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9445 - accuracy: 0.5741 - val_loss: 6.4454 - val_accuracy: 0.0657\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9220 - accuracy: 0.5838 - val_loss: 6.5727 - val_accuracy: 0.0447\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9074 - accuracy: 0.5897 - val_loss: 6.7013 - val_accuracy: 0.0377\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8951 - accuracy: 0.5952 - val_loss: 7.0666 - val_accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8863 - accuracy: 0.6009 - val_loss: 7.1698 - val_accuracy: 0.0333\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8797 - accuracy: 0.6013 - val_loss: 7.2214 - val_accuracy: 0.0316\n",
      "0.6013157963752747\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6312 - accuracy: 0.2853 - val_loss: 3.0986 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2065 - accuracy: 0.4289 - val_loss: 4.8787 - val_accuracy: 0.0026\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0939 - accuracy: 0.4818 - val_loss: 5.6665 - val_accuracy: 0.0053\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0548 - accuracy: 0.5173 - val_loss: 6.2910 - val_accuracy: 0.0026\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0207 - accuracy: 0.5509 - val_loss: 6.5749 - val_accuracy: 0.0018\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9875 - accuracy: 0.5678 - val_loss: 6.6693 - val_accuracy: 0.0149\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9559 - accuracy: 0.5798 - val_loss: 6.5644 - val_accuracy: 0.0342\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9374 - accuracy: 0.5805 - val_loss: 6.9240 - val_accuracy: 0.0316\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9210 - accuracy: 0.5914 - val_loss: 6.8271 - val_accuracy: 0.0570\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9119 - accuracy: 0.5939 - val_loss: 7.3759 - val_accuracy: 0.0429\n",
      "0.5938596725463867\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 2ms/step - loss: 1.6381 - accuracy: 0.3112 - val_loss: 3.0587 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2086 - accuracy: 0.4246 - val_loss: 4.8023 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0905 - accuracy: 0.4829 - val_loss: 5.6107 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0496 - accuracy: 0.5340 - val_loss: 6.1321 - val_accuracy: 0.0254\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0053 - accuracy: 0.5559 - val_loss: 6.8323 - val_accuracy: 0.0140\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9606 - accuracy: 0.5746 - val_loss: 6.9980 - val_accuracy: 0.0219\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9343 - accuracy: 0.5842 - val_loss: 7.0768 - val_accuracy: 0.0210\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9161 - accuracy: 0.5928 - val_loss: 7.1106 - val_accuracy: 0.0394\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9022 - accuracy: 0.5982 - val_loss: 7.1163 - val_accuracy: 0.0438\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8939 - accuracy: 0.5952 - val_loss: 7.2320 - val_accuracy: 0.0333\n",
      "0.5951754450798035\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6439 - accuracy: 0.3026 - val_loss: 2.9648 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2089 - accuracy: 0.4246 - val_loss: 4.7445 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0836 - accuracy: 0.4936 - val_loss: 5.6204 - val_accuracy: 0.0272\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0305 - accuracy: 0.5414 - val_loss: 6.2213 - val_accuracy: 0.0316\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9754 - accuracy: 0.5743 - val_loss: 6.4927 - val_accuracy: 0.0815\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9349 - accuracy: 0.5816 - val_loss: 6.7971 - val_accuracy: 0.0210\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9164 - accuracy: 0.5879 - val_loss: 7.0507 - val_accuracy: 0.0307\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9016 - accuracy: 0.5947 - val_loss: 7.3024 - val_accuracy: 0.0140\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8935 - accuracy: 0.5932 - val_loss: 7.3603 - val_accuracy: 0.0167\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8839 - accuracy: 0.5976 - val_loss: 7.6307 - val_accuracy: 0.0193\n",
      "0.5975877046585083\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6252 - accuracy: 0.3031 - val_loss: 3.0324 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1832 - accuracy: 0.4331 - val_loss: 4.6230 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0844 - accuracy: 0.4726 - val_loss: 5.5550 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0406 - accuracy: 0.5283 - val_loss: 6.0253 - val_accuracy: 0.0403\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9859 - accuracy: 0.5491 - val_loss: 6.2656 - val_accuracy: 0.0990\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9437 - accuracy: 0.5682 - val_loss: 6.7165 - val_accuracy: 0.0631\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9214 - accuracy: 0.5811 - val_loss: 6.7551 - val_accuracy: 0.0359\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9062 - accuracy: 0.5866 - val_loss: 6.9121 - val_accuracy: 0.0386\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8957 - accuracy: 0.5928 - val_loss: 7.0498 - val_accuracy: 0.0412\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8866 - accuracy: 0.5985 - val_loss: 7.3316 - val_accuracy: 0.0368\n",
      "0.5984649062156677\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6409 - accuracy: 0.3189 - val_loss: 3.0326 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2069 - accuracy: 0.4355 - val_loss: 4.8957 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0811 - accuracy: 0.5072 - val_loss: 5.6313 - val_accuracy: 0.0114\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0269 - accuracy: 0.5404 - val_loss: 6.2194 - val_accuracy: 0.0465\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9707 - accuracy: 0.5651 - val_loss: 6.4582 - val_accuracy: 0.0640\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9369 - accuracy: 0.5737 - val_loss: 6.7840 - val_accuracy: 0.0386\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9170 - accuracy: 0.5877 - val_loss: 7.1783 - val_accuracy: 0.0421\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9060 - accuracy: 0.5895 - val_loss: 7.1828 - val_accuracy: 0.0307\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8973 - accuracy: 0.5908 - val_loss: 7.4459 - val_accuracy: 0.0394\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8910 - accuracy: 0.5912 - val_loss: 7.6452 - val_accuracy: 0.0351\n",
      "0.5912280678749084\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6304 - accuracy: 0.3090 - val_loss: 3.0560 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1833 - accuracy: 0.4219 - val_loss: 4.8794 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0803 - accuracy: 0.4844 - val_loss: 5.5390 - val_accuracy: 0.0289\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0360 - accuracy: 0.5296 - val_loss: 6.2165 - val_accuracy: 0.0096\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9812 - accuracy: 0.5686 - val_loss: 6.6640 - val_accuracy: 0.0184\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9385 - accuracy: 0.5789 - val_loss: 6.8484 - val_accuracy: 0.0324\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9168 - accuracy: 0.5829 - val_loss: 6.9950 - val_accuracy: 0.0289\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9009 - accuracy: 0.5906 - val_loss: 7.2273 - val_accuracy: 0.0175\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8877 - accuracy: 0.6031 - val_loss: 7.3721 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8805 - accuracy: 0.6026 - val_loss: 7.3034 - val_accuracy: 0.0298\n",
      "0.6026315689086914\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6301 - accuracy: 0.3009 - val_loss: 3.0564 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2048 - accuracy: 0.4333 - val_loss: 4.5302 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0885 - accuracy: 0.4814 - val_loss: 5.4857 - val_accuracy: 0.0044\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0433 - accuracy: 0.5362 - val_loss: 5.9666 - val_accuracy: 0.0535\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9910 - accuracy: 0.5621 - val_loss: 6.2294 - val_accuracy: 0.0465\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9499 - accuracy: 0.5752 - val_loss: 6.4131 - val_accuracy: 0.0587\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9275 - accuracy: 0.5814 - val_loss: 6.6728 - val_accuracy: 0.0482\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9133 - accuracy: 0.5864 - val_loss: 6.6550 - val_accuracy: 0.0307\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9031 - accuracy: 0.5965 - val_loss: 6.7583 - val_accuracy: 0.0298\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8970 - accuracy: 0.5893 - val_loss: 6.8552 - val_accuracy: 0.0202\n",
      "0.5892543792724609\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6293 - accuracy: 0.2987 - val_loss: 3.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1785 - accuracy: 0.4307 - val_loss: 4.7225 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0788 - accuracy: 0.4836 - val_loss: 5.6025 - val_accuracy: 0.0175\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0490 - accuracy: 0.5246 - val_loss: 6.0048 - val_accuracy: 8.7642e-04\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0139 - accuracy: 0.5491 - val_loss: 6.4645 - val_accuracy: 0.0272\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9741 - accuracy: 0.5728 - val_loss: 6.7654 - val_accuracy: 0.0324\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9407 - accuracy: 0.5765 - val_loss: 6.9589 - val_accuracy: 0.0438\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9221 - accuracy: 0.5818 - val_loss: 7.1280 - val_accuracy: 0.0491\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9091 - accuracy: 0.5908 - val_loss: 7.3948 - val_accuracy: 0.0386\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8993 - accuracy: 0.5912 - val_loss: 7.6185 - val_accuracy: 0.0333\n",
      "0.5912280678749084\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6421 - accuracy: 0.2998 - val_loss: 3.1353 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2204 - accuracy: 0.4064 - val_loss: 5.0242 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0908 - accuracy: 0.4629 - val_loss: 5.7204 - val_accuracy: 0.0105\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0592 - accuracy: 0.5000 - val_loss: 6.1999 - val_accuracy: 0.0158\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0315 - accuracy: 0.5254 - val_loss: 6.4732 - val_accuracy: 0.0438\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9969 - accuracy: 0.5559 - val_loss: 6.7476 - val_accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9598 - accuracy: 0.5651 - val_loss: 6.9301 - val_accuracy: 0.0096\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9365 - accuracy: 0.5798 - val_loss: 7.0000 - val_accuracy: 0.0438\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9236 - accuracy: 0.5871 - val_loss: 7.3091 - val_accuracy: 0.0394\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9155 - accuracy: 0.5888 - val_loss: 7.3612 - val_accuracy: 0.0307\n",
      "0.5888158082962036\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6411 - accuracy: 0.2897 - val_loss: 3.0845 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2121 - accuracy: 0.4180 - val_loss: 4.9420 - val_accuracy: 0.0070\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0840 - accuracy: 0.4914 - val_loss: 5.8840 - val_accuracy: 0.0114\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0303 - accuracy: 0.5557 - val_loss: 6.0898 - val_accuracy: 0.1069\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9774 - accuracy: 0.5586 - val_loss: 6.5255 - val_accuracy: 0.0692\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9423 - accuracy: 0.5697 - val_loss: 6.8096 - val_accuracy: 0.0570\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9242 - accuracy: 0.5836 - val_loss: 6.8548 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9093 - accuracy: 0.5897 - val_loss: 6.9246 - val_accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8977 - accuracy: 0.5932 - val_loss: 7.1605 - val_accuracy: 0.0412\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8894 - accuracy: 0.5985 - val_loss: 7.1773 - val_accuracy: 0.0280\n",
      "0.5984649062156677\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6281 - accuracy: 0.3116 - val_loss: 2.9863 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1866 - accuracy: 0.4307 - val_loss: 4.7263 - val_accuracy: 0.0289\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0779 - accuracy: 0.5077 - val_loss: 5.6207 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0326 - accuracy: 0.5605 - val_loss: 6.1030 - val_accuracy: 0.0727\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9851 - accuracy: 0.5463 - val_loss: 6.4636 - val_accuracy: 0.0324\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9444 - accuracy: 0.5752 - val_loss: 6.8298 - val_accuracy: 0.0333\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9241 - accuracy: 0.5785 - val_loss: 6.9148 - val_accuracy: 0.0342\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9124 - accuracy: 0.5934 - val_loss: 7.0647 - val_accuracy: 0.0377\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9007 - accuracy: 0.5943 - val_loss: 6.9049 - val_accuracy: 0.0210\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8913 - accuracy: 0.5943 - val_loss: 7.1358 - val_accuracy: 0.0289\n",
      "0.594298243522644\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6403 - accuracy: 0.2879 - val_loss: 3.0872 - val_accuracy: 0.0018\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2124 - accuracy: 0.4274 - val_loss: 5.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0925 - accuracy: 0.4895 - val_loss: 5.8483 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0547 - accuracy: 0.5195 - val_loss: 6.4863 - val_accuracy: 0.0079\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0120 - accuracy: 0.5581 - val_loss: 6.5865 - val_accuracy: 0.0719\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9662 - accuracy: 0.5675 - val_loss: 6.7889 - val_accuracy: 0.0552\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9337 - accuracy: 0.5831 - val_loss: 7.2716 - val_accuracy: 0.0517\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9170 - accuracy: 0.5884 - val_loss: 7.1877 - val_accuracy: 0.0298\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9046 - accuracy: 0.5914 - val_loss: 7.3916 - val_accuracy: 0.0158\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8955 - accuracy: 0.5958 - val_loss: 7.3264 - val_accuracy: 0.0254\n",
      "0.5958333611488342\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6316 - accuracy: 0.3127 - val_loss: 3.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1925 - accuracy: 0.4340 - val_loss: 4.8078 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0819 - accuracy: 0.5018 - val_loss: 5.6043 - val_accuracy: 0.0079\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0412 - accuracy: 0.5360 - val_loss: 5.9373 - val_accuracy: 0.0070\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0066 - accuracy: 0.5588 - val_loss: 6.3723 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9749 - accuracy: 0.5770 - val_loss: 6.1463 - val_accuracy: 0.0333\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9497 - accuracy: 0.5809 - val_loss: 6.1746 - val_accuracy: 0.0193\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9292 - accuracy: 0.5882 - val_loss: 6.0834 - val_accuracy: 0.0263\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9168 - accuracy: 0.5882 - val_loss: 6.5540 - val_accuracy: 0.0175\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9032 - accuracy: 0.5906 - val_loss: 6.8495 - val_accuracy: 0.0202\n",
      "0.5905701518058777\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6221 - accuracy: 0.3075 - val_loss: 3.1217 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1729 - accuracy: 0.4809 - val_loss: 4.9202 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0522 - accuracy: 0.5314 - val_loss: 5.8365 - val_accuracy: 0.0263\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9818 - accuracy: 0.5572 - val_loss: 6.5077 - val_accuracy: 0.0316\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9382 - accuracy: 0.5732 - val_loss: 6.7583 - val_accuracy: 0.0237\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9153 - accuracy: 0.5943 - val_loss: 6.7763 - val_accuracy: 0.0465\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8992 - accuracy: 0.5923 - val_loss: 7.0651 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8857 - accuracy: 0.6009 - val_loss: 6.9749 - val_accuracy: 0.0412\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8756 - accuracy: 0.6031 - val_loss: 7.2357 - val_accuracy: 0.0280\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8672 - accuracy: 0.6125 - val_loss: 7.3506 - val_accuracy: 0.0298\n",
      "0.612500011920929\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6369 - accuracy: 0.2954 - val_loss: 3.0283 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2032 - accuracy: 0.4322 - val_loss: 4.9622 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0785 - accuracy: 0.5121 - val_loss: 5.6840 - val_accuracy: 0.0324\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0229 - accuracy: 0.5493 - val_loss: 6.2042 - val_accuracy: 0.0613\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9667 - accuracy: 0.5702 - val_loss: 6.8762 - val_accuracy: 0.0237\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9325 - accuracy: 0.5890 - val_loss: 6.9128 - val_accuracy: 0.0359\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9165 - accuracy: 0.5816 - val_loss: 7.0739 - val_accuracy: 0.0210\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9026 - accuracy: 0.5914 - val_loss: 7.5031 - val_accuracy: 0.0272\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8916 - accuracy: 0.5939 - val_loss: 7.4737 - val_accuracy: 0.0237\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8828 - accuracy: 0.5967 - val_loss: 7.8253 - val_accuracy: 0.0254\n",
      "0.5967105031013489\n",
      "if any\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6473 - accuracy: 0.3230 - val_loss: 3.1324 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2255 - accuracy: 0.4178 - val_loss: 4.8544 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0971 - accuracy: 0.4678 - val_loss: 5.6846 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0700 - accuracy: 0.4958 - val_loss: 6.0858 - val_accuracy: 0.0018\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0500 - accuracy: 0.5132 - val_loss: 6.5067 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0242 - accuracy: 0.5463 - val_loss: 6.8411 - val_accuracy: 0.0070\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9931 - accuracy: 0.5664 - val_loss: 7.1025 - val_accuracy: 0.0088\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9643 - accuracy: 0.5844 - val_loss: 7.1380 - val_accuracy: 0.0237\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9420 - accuracy: 0.5842 - val_loss: 7.2103 - val_accuracy: 0.0263\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9278 - accuracy: 0.5888 - val_loss: 7.5186 - val_accuracy: 0.0237\n",
      "0.5888158082962036\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6441 - accuracy: 0.3129 - val_loss: 3.0290 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2078 - accuracy: 0.4303 - val_loss: 4.6836 - val_accuracy: 0.0219\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0815 - accuracy: 0.4939 - val_loss: 5.6751 - val_accuracy: 0.0096\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0312 - accuracy: 0.5384 - val_loss: 6.2495 - val_accuracy: 0.0044\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9804 - accuracy: 0.5726 - val_loss: 6.4772 - val_accuracy: 0.0324\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9465 - accuracy: 0.5750 - val_loss: 6.7650 - val_accuracy: 0.0508\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9257 - accuracy: 0.5814 - val_loss: 7.0696 - val_accuracy: 0.0280\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9121 - accuracy: 0.5897 - val_loss: 7.4015 - val_accuracy: 0.0421\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9013 - accuracy: 0.5899 - val_loss: 7.6550 - val_accuracy: 0.0333\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8920 - accuracy: 0.5939 - val_loss: 7.5428 - val_accuracy: 0.0316\n",
      "0.5938596725463867\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6425 - accuracy: 0.3178 - val_loss: 2.9703 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2059 - accuracy: 0.4189 - val_loss: 4.7134 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0845 - accuracy: 0.4974 - val_loss: 5.5489 - val_accuracy: 0.0552\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0357 - accuracy: 0.5217 - val_loss: 6.1196 - val_accuracy: 0.0456\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9842 - accuracy: 0.5645 - val_loss: 6.3880 - val_accuracy: 0.0587\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9463 - accuracy: 0.5809 - val_loss: 6.7586 - val_accuracy: 0.0359\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9234 - accuracy: 0.5860 - val_loss: 6.7739 - val_accuracy: 0.0465\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9099 - accuracy: 0.5831 - val_loss: 7.1124 - val_accuracy: 0.0184\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9010 - accuracy: 0.5947 - val_loss: 7.2935 - val_accuracy: 0.0228\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8883 - accuracy: 0.5971 - val_loss: 7.3624 - val_accuracy: 0.0219\n",
      "0.597149133682251\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6111 - accuracy: 0.3033 - val_loss: 3.0960 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1671 - accuracy: 0.4572 - val_loss: 4.7594 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0630 - accuracy: 0.5250 - val_loss: 5.6626 - val_accuracy: 0.0149\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0031 - accuracy: 0.5601 - val_loss: 6.1818 - val_accuracy: 0.0333\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9584 - accuracy: 0.5684 - val_loss: 6.3234 - val_accuracy: 0.0280\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9306 - accuracy: 0.5800 - val_loss: 6.5514 - val_accuracy: 0.0394\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9162 - accuracy: 0.5851 - val_loss: 6.6858 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9004 - accuracy: 0.5895 - val_loss: 6.6603 - val_accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8907 - accuracy: 0.5939 - val_loss: 6.8743 - val_accuracy: 0.0219\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8848 - accuracy: 0.5950 - val_loss: 6.8532 - val_accuracy: 0.0368\n",
      "0.5949561595916748\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6175 - accuracy: 0.3072 - val_loss: 3.0742 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1702 - accuracy: 0.4529 - val_loss: 4.7369 - val_accuracy: 0.0631\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0688 - accuracy: 0.5292 - val_loss: 5.4986 - val_accuracy: 0.0798\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0115 - accuracy: 0.5507 - val_loss: 6.1302 - val_accuracy: 0.0920\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9607 - accuracy: 0.5586 - val_loss: 6.4366 - val_accuracy: 0.0885\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9300 - accuracy: 0.5719 - val_loss: 6.6532 - val_accuracy: 0.0666\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9127 - accuracy: 0.5897 - val_loss: 6.7465 - val_accuracy: 0.0447\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9025 - accuracy: 0.5936 - val_loss: 7.0256 - val_accuracy: 0.0359\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8921 - accuracy: 0.5969 - val_loss: 7.0341 - val_accuracy: 0.0447\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8821 - accuracy: 0.6002 - val_loss: 7.0103 - val_accuracy: 0.0307\n",
      "0.6002193093299866\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 3ms/step - loss: 1.6346 - accuracy: 0.2996 - val_loss: 3.1367 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1966 - accuracy: 0.4252 - val_loss: 4.8377 - val_accuracy: 0.0351\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0769 - accuracy: 0.4965 - val_loss: 5.8925 - val_accuracy: 0.0210\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0274 - accuracy: 0.5355 - val_loss: 6.3595 - val_accuracy: 0.0903\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9768 - accuracy: 0.5500 - val_loss: 6.4080 - val_accuracy: 0.0955\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9411 - accuracy: 0.5542 - val_loss: 6.7210 - val_accuracy: 0.0570\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9189 - accuracy: 0.5851 - val_loss: 6.9570 - val_accuracy: 0.0605\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9081 - accuracy: 0.5844 - val_loss: 7.0689 - val_accuracy: 0.0237\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8957 - accuracy: 0.5917 - val_loss: 7.2184 - val_accuracy: 0.0280\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8861 - accuracy: 0.5958 - val_loss: 7.3091 - val_accuracy: 0.0254\n",
      "0.5958333611488342\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6369 - accuracy: 0.2967 - val_loss: 3.0643 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1960 - accuracy: 0.4353 - val_loss: 4.7445 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0859 - accuracy: 0.4873 - val_loss: 5.6126 - val_accuracy: 0.0061\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0501 - accuracy: 0.5200 - val_loss: 6.0920 - val_accuracy: 0.0289\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0140 - accuracy: 0.5489 - val_loss: 6.2609 - val_accuracy: 0.0456\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9733 - accuracy: 0.5654 - val_loss: 6.7996 - val_accuracy: 0.0377\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9459 - accuracy: 0.5836 - val_loss: 6.9931 - val_accuracy: 0.0482\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9294 - accuracy: 0.5864 - val_loss: 7.0984 - val_accuracy: 0.0438\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9160 - accuracy: 0.5932 - val_loss: 7.3935 - val_accuracy: 0.0351\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9056 - accuracy: 0.5963 - val_loss: 7.5253 - val_accuracy: 0.0403\n",
      "0.5962719321250916\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6162 - accuracy: 0.3053 - val_loss: 3.1819 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1607 - accuracy: 0.4680 - val_loss: 4.9730 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0607 - accuracy: 0.5081 - val_loss: 5.7331 - val_accuracy: 0.0649\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0038 - accuracy: 0.5504 - val_loss: 6.2610 - val_accuracy: 0.0789\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9518 - accuracy: 0.5566 - val_loss: 6.8388 - val_accuracy: 0.0473\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9243 - accuracy: 0.5800 - val_loss: 6.9057 - val_accuracy: 0.0622\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9059 - accuracy: 0.5840 - val_loss: 7.2437 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8891 - accuracy: 0.5991 - val_loss: 7.4424 - val_accuracy: 0.0403\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8806 - accuracy: 0.5987 - val_loss: 7.4453 - val_accuracy: 0.0316\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8680 - accuracy: 0.6055 - val_loss: 7.7446 - val_accuracy: 0.0298\n",
      "0.6054824590682983\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6221 - accuracy: 0.3092 - val_loss: 3.0165 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1818 - accuracy: 0.4235 - val_loss: 4.6117 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0876 - accuracy: 0.4627 - val_loss: 5.3814 - val_accuracy: 0.0061\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0596 - accuracy: 0.5077 - val_loss: 5.7987 - val_accuracy: 0.0123\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0323 - accuracy: 0.5309 - val_loss: 6.2271 - val_accuracy: 0.0193\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9939 - accuracy: 0.5623 - val_loss: 6.3924 - val_accuracy: 0.0184\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9615 - accuracy: 0.5864 - val_loss: 6.4253 - val_accuracy: 0.0307\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9354 - accuracy: 0.5855 - val_loss: 6.8932 - val_accuracy: 0.0316\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9180 - accuracy: 0.5952 - val_loss: 7.3714 - val_accuracy: 0.0254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9058 - accuracy: 0.5965 - val_loss: 7.3474 - val_accuracy: 0.0175\n",
      "0.5964912176132202\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6389 - accuracy: 0.3033 - val_loss: 2.9685 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2003 - accuracy: 0.4298 - val_loss: 4.8530 - val_accuracy: 0.0167\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0864 - accuracy: 0.4651 - val_loss: 5.6688 - val_accuracy: 0.0219\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0491 - accuracy: 0.5235 - val_loss: 6.1830 - val_accuracy: 0.0885\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0058 - accuracy: 0.5605 - val_loss: 6.3634 - val_accuracy: 0.1034\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9627 - accuracy: 0.5658 - val_loss: 6.9170 - val_accuracy: 0.0850\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9323 - accuracy: 0.5792 - val_loss: 6.9749 - val_accuracy: 0.0710\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9177 - accuracy: 0.5862 - val_loss: 7.2988 - val_accuracy: 0.0368\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9063 - accuracy: 0.5875 - val_loss: 7.3945 - val_accuracy: 0.0298\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8947 - accuracy: 0.5978 - val_loss: 7.5619 - val_accuracy: 0.0377\n",
      "0.597806990146637\n",
      "if any\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6259 - accuracy: 0.3149 - val_loss: 3.1356 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1842 - accuracy: 0.4546 - val_loss: 4.7909 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0649 - accuracy: 0.5373 - val_loss: 5.7052 - val_accuracy: 0.0447\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0021 - accuracy: 0.5601 - val_loss: 6.1861 - val_accuracy: 0.0929\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9567 - accuracy: 0.5577 - val_loss: 6.4178 - val_accuracy: 0.0316\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9307 - accuracy: 0.5779 - val_loss: 6.6243 - val_accuracy: 0.0543\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9177 - accuracy: 0.5860 - val_loss: 6.5941 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9042 - accuracy: 0.5943 - val_loss: 6.6869 - val_accuracy: 0.0228\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8941 - accuracy: 0.5969 - val_loss: 6.9418 - val_accuracy: 0.0219\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8879 - accuracy: 0.6039 - val_loss: 7.0244 - val_accuracy: 0.0237\n",
      "0.6039473414421082\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6255 - accuracy: 0.2954 - val_loss: 3.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1787 - accuracy: 0.4237 - val_loss: 4.9100 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0798 - accuracy: 0.4711 - val_loss: 5.5875 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0432 - accuracy: 0.5336 - val_loss: 6.1406 - val_accuracy: 0.0070\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0023 - accuracy: 0.5496 - val_loss: 6.6445 - val_accuracy: 0.0316\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9632 - accuracy: 0.5636 - val_loss: 6.8987 - val_accuracy: 0.0219\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9333 - accuracy: 0.5829 - val_loss: 7.0300 - val_accuracy: 0.0622\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9179 - accuracy: 0.5877 - val_loss: 7.2326 - val_accuracy: 0.0570\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9032 - accuracy: 0.5967 - val_loss: 7.2221 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8946 - accuracy: 0.5939 - val_loss: 7.4147 - val_accuracy: 0.0289\n",
      "0.5938596725463867\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6298 - accuracy: 0.2908 - val_loss: 3.0908 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1976 - accuracy: 0.4498 - val_loss: 4.7736 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0785 - accuracy: 0.5140 - val_loss: 5.7092 - val_accuracy: 0.0079\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0237 - accuracy: 0.5461 - val_loss: 6.1927 - val_accuracy: 0.0167\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9710 - accuracy: 0.5741 - val_loss: 6.6759 - val_accuracy: 0.0324\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9383 - accuracy: 0.5818 - val_loss: 6.8678 - val_accuracy: 0.0245\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9236 - accuracy: 0.5844 - val_loss: 6.7164 - val_accuracy: 0.0245\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9103 - accuracy: 0.5917 - val_loss: 7.0571 - val_accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9012 - accuracy: 0.5921 - val_loss: 7.2446 - val_accuracy: 0.0280\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8915 - accuracy: 0.6000 - val_loss: 7.4967 - val_accuracy: 0.0298\n",
      "0.6000000238418579\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6387 - accuracy: 0.2987 - val_loss: 3.1346 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1979 - accuracy: 0.4399 - val_loss: 5.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0799 - accuracy: 0.4956 - val_loss: 5.8104 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0319 - accuracy: 0.5518 - val_loss: 6.6509 - val_accuracy: 0.0053\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9821 - accuracy: 0.5592 - val_loss: 6.9255 - val_accuracy: 0.0167\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9404 - accuracy: 0.5721 - val_loss: 7.0592 - val_accuracy: 0.0605\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9190 - accuracy: 0.5783 - val_loss: 7.2453 - val_accuracy: 0.0175\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9044 - accuracy: 0.5908 - val_loss: 7.2095 - val_accuracy: 0.0438\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8926 - accuracy: 0.5921 - val_loss: 7.4352 - val_accuracy: 0.0219\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8829 - accuracy: 0.6026 - val_loss: 7.6760 - val_accuracy: 0.0289\n",
      "0.6026315689086914\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6194 - accuracy: 0.3004 - val_loss: 3.0846 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1697 - accuracy: 0.4711 - val_loss: 4.8847 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0601 - accuracy: 0.5353 - val_loss: 5.6857 - val_accuracy: 0.0210\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0030 - accuracy: 0.5561 - val_loss: 6.1568 - val_accuracy: 0.0824\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9545 - accuracy: 0.5522 - val_loss: 6.5266 - val_accuracy: 0.0710\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9278 - accuracy: 0.5647 - val_loss: 6.6972 - val_accuracy: 0.0333\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9123 - accuracy: 0.5860 - val_loss: 6.6666 - val_accuracy: 0.0316\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8981 - accuracy: 0.5961 - val_loss: 6.7908 - val_accuracy: 0.0368\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8895 - accuracy: 0.5945 - val_loss: 6.7810 - val_accuracy: 0.0228\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8823 - accuracy: 0.5963 - val_loss: 6.9345 - val_accuracy: 0.0254\n",
      "0.5962719321250916\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6160 - accuracy: 0.3046 - val_loss: 3.0785 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1933 - accuracy: 0.4338 - val_loss: 4.6299 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0879 - accuracy: 0.4877 - val_loss: 5.5075 - val_accuracy: 8.7642e-04\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0474 - accuracy: 0.5292 - val_loss: 5.9255 - val_accuracy: 0.0131\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9961 - accuracy: 0.5515 - val_loss: 6.2339 - val_accuracy: 0.0762\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9547 - accuracy: 0.5708 - val_loss: 6.1979 - val_accuracy: 0.0622\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9278 - accuracy: 0.5849 - val_loss: 6.4213 - val_accuracy: 0.0429\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9121 - accuracy: 0.5969 - val_loss: 6.6686 - val_accuracy: 0.0342\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8990 - accuracy: 0.6013 - val_loss: 6.7852 - val_accuracy: 0.0508\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8908 - accuracy: 0.5989 - val_loss: 6.8381 - val_accuracy: 0.0289\n",
      "0.5989035367965698\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6379 - accuracy: 0.3232 - val_loss: 3.0304 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2140 - accuracy: 0.4325 - val_loss: 4.7563 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0880 - accuracy: 0.4943 - val_loss: 5.6063 - val_accuracy: 0.0026\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0413 - accuracy: 0.5355 - val_loss: 6.1215 - val_accuracy: 0.0079\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9956 - accuracy: 0.5616 - val_loss: 6.0647 - val_accuracy: 0.0272\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9562 - accuracy: 0.5787 - val_loss: 6.3362 - val_accuracy: 0.0333\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9269 - accuracy: 0.5846 - val_loss: 6.3054 - val_accuracy: 0.0482\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9103 - accuracy: 0.5958 - val_loss: 6.6386 - val_accuracy: 0.0447\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8965 - accuracy: 0.5971 - val_loss: 6.9077 - val_accuracy: 0.0280\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8857 - accuracy: 0.5985 - val_loss: 7.1139 - val_accuracy: 0.0149\n",
      "0.5984649062156677\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6150 - accuracy: 0.3004 - val_loss: 3.0094 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1623 - accuracy: 0.4566 - val_loss: 4.9427 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0445 - accuracy: 0.5311 - val_loss: 5.8795 - val_accuracy: 0.0333\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9756 - accuracy: 0.5553 - val_loss: 6.2972 - val_accuracy: 0.0754\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9396 - accuracy: 0.5660 - val_loss: 6.6017 - val_accuracy: 0.0351\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9176 - accuracy: 0.5805 - val_loss: 6.8154 - val_accuracy: 0.0368\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9028 - accuracy: 0.5943 - val_loss: 6.9294 - val_accuracy: 0.0456\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8918 - accuracy: 0.5936 - val_loss: 7.0819 - val_accuracy: 0.0386\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8843 - accuracy: 0.5910 - val_loss: 7.3373 - val_accuracy: 0.0342\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8767 - accuracy: 0.5989 - val_loss: 7.4119 - val_accuracy: 0.0289\n",
      "0.5989035367965698\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6199 - accuracy: 0.3105 - val_loss: 3.0525 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1674 - accuracy: 0.4507 - val_loss: 4.8893 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0758 - accuracy: 0.4860 - val_loss: 5.7559 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0374 - accuracy: 0.5482 - val_loss: 6.1693 - val_accuracy: 0.0727\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9879 - accuracy: 0.5610 - val_loss: 6.5185 - val_accuracy: 0.0666\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9491 - accuracy: 0.5678 - val_loss: 6.9395 - val_accuracy: 0.0412\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9285 - accuracy: 0.5816 - val_loss: 6.9855 - val_accuracy: 0.0429\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9113 - accuracy: 0.5888 - val_loss: 7.1210 - val_accuracy: 0.0438\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8996 - accuracy: 0.5952 - val_loss: 7.0787 - val_accuracy: 0.0438\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8910 - accuracy: 0.6018 - val_loss: 7.5498 - val_accuracy: 0.0368\n",
      "0.601754367351532\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6335 - accuracy: 0.3046 - val_loss: 3.1937 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1893 - accuracy: 0.4353 - val_loss: 5.0736 - val_accuracy: 0.0044\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0818 - accuracy: 0.4820 - val_loss: 5.9309 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0382 - accuracy: 0.5480 - val_loss: 6.2779 - val_accuracy: 0.1034\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9880 - accuracy: 0.5469 - val_loss: 6.7315 - val_accuracy: 0.0351\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9465 - accuracy: 0.5724 - val_loss: 7.1654 - val_accuracy: 0.0368\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9256 - accuracy: 0.5827 - val_loss: 7.1011 - val_accuracy: 0.0403\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9085 - accuracy: 0.5908 - val_loss: 7.5303 - val_accuracy: 0.0386\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8998 - accuracy: 0.5939 - val_loss: 7.5385 - val_accuracy: 0.0377\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8905 - accuracy: 0.5963 - val_loss: 7.6495 - val_accuracy: 0.0289\n",
      "0.5962719321250916\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6313 - accuracy: 0.2958 - val_loss: 2.9759 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1875 - accuracy: 0.4261 - val_loss: 4.8463 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0870 - accuracy: 0.4697 - val_loss: 5.5346 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0567 - accuracy: 0.5134 - val_loss: 5.8913 - val_accuracy: 0.0114\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0301 - accuracy: 0.5340 - val_loss: 6.2553 - val_accuracy: 0.0070\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9937 - accuracy: 0.5621 - val_loss: 6.4765 - val_accuracy: 0.0245\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9601 - accuracy: 0.5785 - val_loss: 6.6143 - val_accuracy: 0.0351\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9378 - accuracy: 0.5829 - val_loss: 6.8745 - val_accuracy: 0.0429\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9236 - accuracy: 0.5956 - val_loss: 7.1201 - val_accuracy: 0.0333\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9121 - accuracy: 0.5871 - val_loss: 7.1613 - val_accuracy: 0.0351\n",
      "0.5870614051818848\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6237 - accuracy: 0.3042 - val_loss: 2.9749 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1705 - accuracy: 0.4765 - val_loss: 4.8738 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0551 - accuracy: 0.5581 - val_loss: 5.6301 - val_accuracy: 0.1131\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9887 - accuracy: 0.5480 - val_loss: 6.2610 - val_accuracy: 0.0324\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9452 - accuracy: 0.5629 - val_loss: 6.4711 - val_accuracy: 0.0272\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9182 - accuracy: 0.5906 - val_loss: 6.7058 - val_accuracy: 0.0526\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9062 - accuracy: 0.5873 - val_loss: 6.8693 - val_accuracy: 0.0456\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8954 - accuracy: 0.6039 - val_loss: 6.8811 - val_accuracy: 0.0219\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8855 - accuracy: 0.6013 - val_loss: 7.1911 - val_accuracy: 0.0289\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8810 - accuracy: 0.6029 - val_loss: 7.3447 - val_accuracy: 0.0351\n",
      "0.6028508543968201\n",
      "if any\n",
      "yhn tk\n",
      "2\n",
      "Done\n",
      "yhn tk\n",
      "2\n",
      "Done\n",
      "yhn tk\n",
      "2\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "yhn tk\n",
      "1\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:85: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 721us/step - loss: 2.7892 - accuracy: 0.3622\n",
      "54/54 [==============================] - 0s 734us/step - loss: 2.6988 - accuracy: 0.3688\n",
      "125/125 [==============================] - 0s 729us/step - loss: 2.6497 - accuracy: 0.3644\n",
      "54/54 [==============================] - 0s 710us/step - loss: 2.5576 - accuracy: 0.3816\n",
      "125/125 [==============================] - 0s 762us/step - loss: 2.7590 - accuracy: 0.3554\n",
      "54/54 [==============================] - 0s 677us/step - loss: 2.6709 - accuracy: 0.3647\n",
      "125/125 [==============================] - 0s 753us/step - loss: 2.6574 - accuracy: 0.3842\n",
      "54/54 [==============================] - 0s 728us/step - loss: 2.5638 - accuracy: 0.3834\n",
      "125/125 [==============================] - 0s 723us/step - loss: 2.7201 - accuracy: 0.3594\n",
      "54/54 [==============================] - 0s 727us/step - loss: 2.6284 - accuracy: 0.3705\n",
      "36/36 [==============================] - 0s 648us/step\n",
      "36/36 [==============================] - 0s 643us/step\n",
      "36/36 [==============================] - 0s 634us/step\n",
      "36/36 [==============================] - 0s 659us/step\n",
      "36/36 [==============================] - 0s 609us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 592us/step\n",
      "179/179 [==============================] - 0s 557us/step\n",
      "179/179 [==============================] - 0s 548us/step\n",
      "179/179 [==============================] - 0s 526us/step\n",
      "179/179 [==============================] - 0s 494us/step\n",
      "36/36 [==============================] - 0s 618us/step\n",
      "36/36 [==============================] - 0s 612us/step\n",
      "36/36 [==============================] - 0s 608us/step\n",
      "36/36 [==============================] - 0s 607us/step\n",
      "36/36 [==============================] - 0s 624us/step\n",
      "1140\n",
      "drift has been detected models must be retrained\n",
      "some intersection\n",
      "finished\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 2s 2ms/step - loss: 1.6443 - accuracy: 0.2787 - val_loss: 3.0999 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2247 - accuracy: 0.4287 - val_loss: 4.9395 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0939 - accuracy: 0.4849 - val_loss: 5.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0489 - accuracy: 0.5410 - val_loss: 6.1717 - val_accuracy: 0.0359\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9990 - accuracy: 0.5638 - val_loss: 6.4059 - val_accuracy: 0.0841\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9596 - accuracy: 0.5640 - val_loss: 6.6814 - val_accuracy: 0.0508\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9295 - accuracy: 0.5792 - val_loss: 7.0143 - val_accuracy: 0.0596\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9143 - accuracy: 0.5886 - val_loss: 7.1375 - val_accuracy: 0.0316\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9019 - accuracy: 0.5901 - val_loss: 7.2609 - val_accuracy: 0.0359\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8917 - accuracy: 0.5971 - val_loss: 7.3719 - val_accuracy: 0.0386\n",
      "0.597149133682251\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6512 - accuracy: 0.2939 - val_loss: 3.1273 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2196 - accuracy: 0.4311 - val_loss: 4.8030 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0827 - accuracy: 0.4846 - val_loss: 5.5463 - val_accuracy: 0.0096\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0326 - accuracy: 0.5577 - val_loss: 6.2352 - val_accuracy: 0.0727\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9785 - accuracy: 0.5640 - val_loss: 6.8596 - val_accuracy: 0.0263\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9434 - accuracy: 0.5739 - val_loss: 6.7095 - val_accuracy: 0.0368\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9257 - accuracy: 0.5814 - val_loss: 7.0052 - val_accuracy: 0.0482\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9144 - accuracy: 0.5886 - val_loss: 7.3537 - val_accuracy: 0.0368\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9060 - accuracy: 0.5871 - val_loss: 7.1173 - val_accuracy: 0.0368\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8967 - accuracy: 0.5925 - val_loss: 7.3263 - val_accuracy: 0.0219\n",
      "0.5925438404083252\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6184 - accuracy: 0.3022 - val_loss: 3.0367 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1777 - accuracy: 0.4550 - val_loss: 4.7872 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0567 - accuracy: 0.5445 - val_loss: 5.6693 - val_accuracy: 0.0061\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9906 - accuracy: 0.5621 - val_loss: 6.2106 - val_accuracy: 0.0237\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9485 - accuracy: 0.5675 - val_loss: 6.5475 - val_accuracy: 0.0333\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9216 - accuracy: 0.5759 - val_loss: 6.6759 - val_accuracy: 0.0263\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9071 - accuracy: 0.5890 - val_loss: 7.0012 - val_accuracy: 0.0228\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8947 - accuracy: 0.5910 - val_loss: 7.0008 - val_accuracy: 0.0421\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8895 - accuracy: 0.5965 - val_loss: 7.0291 - val_accuracy: 0.0202\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8792 - accuracy: 0.5989 - val_loss: 7.1332 - val_accuracy: 0.0219\n",
      "0.5989035367965698\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6462 - accuracy: 0.2754 - val_loss: 3.0758 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2125 - accuracy: 0.4296 - val_loss: 4.9171 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0895 - accuracy: 0.4779 - val_loss: 5.7899 - val_accuracy: 0.0070\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0521 - accuracy: 0.5182 - val_loss: 6.1595 - val_accuracy: 0.0131\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0154 - accuracy: 0.5434 - val_loss: 6.5678 - val_accuracy: 0.0333\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9702 - accuracy: 0.5686 - val_loss: 6.8329 - val_accuracy: 0.0491\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9407 - accuracy: 0.5752 - val_loss: 6.9704 - val_accuracy: 0.0298\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9253 - accuracy: 0.5796 - val_loss: 6.9960 - val_accuracy: 0.0219\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9153 - accuracy: 0.5877 - val_loss: 7.2826 - val_accuracy: 0.0429\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9057 - accuracy: 0.5886 - val_loss: 7.1823 - val_accuracy: 0.0237\n",
      "0.5885964632034302\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 3ms/step - loss: 1.6090 - accuracy: 0.3070 - val_loss: 3.0532 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1685 - accuracy: 0.4382 - val_loss: 4.8137 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0692 - accuracy: 0.5213 - val_loss: 5.4239 - val_accuracy: 0.1174\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0199 - accuracy: 0.5572 - val_loss: 6.1397 - val_accuracy: 0.0649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9658 - accuracy: 0.5638 - val_loss: 6.6769 - val_accuracy: 0.0692\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9322 - accuracy: 0.5717 - val_loss: 6.8917 - val_accuracy: 0.0745\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9136 - accuracy: 0.5842 - val_loss: 6.9714 - val_accuracy: 0.0307\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9000 - accuracy: 0.5963 - val_loss: 7.0150 - val_accuracy: 0.0210\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8896 - accuracy: 0.5987 - val_loss: 7.0819 - val_accuracy: 0.0105\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8774 - accuracy: 0.6029 - val_loss: 7.2719 - val_accuracy: 0.0272\n",
      "0.6028508543968201\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6174 - accuracy: 0.3090 - val_loss: 3.1482 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1709 - accuracy: 0.4395 - val_loss: 4.9679 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0703 - accuracy: 0.5132 - val_loss: 5.7689 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0220 - accuracy: 0.5487 - val_loss: 6.1527 - val_accuracy: 0.0692\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9718 - accuracy: 0.5662 - val_loss: 6.6229 - val_accuracy: 0.0561\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9391 - accuracy: 0.5697 - val_loss: 6.5697 - val_accuracy: 0.0657\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9173 - accuracy: 0.5846 - val_loss: 6.8479 - val_accuracy: 0.0543\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9065 - accuracy: 0.5897 - val_loss: 7.0581 - val_accuracy: 0.0324\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8945 - accuracy: 0.6020 - val_loss: 7.0936 - val_accuracy: 0.0465\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8855 - accuracy: 0.5991 - val_loss: 7.4172 - val_accuracy: 0.0272\n",
      "0.5991228222846985\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6388 - accuracy: 0.2978 - val_loss: 3.0694 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2054 - accuracy: 0.4300 - val_loss: 4.8733 - val_accuracy: 8.7642e-04\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0769 - accuracy: 0.4978 - val_loss: 5.9325 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0148 - accuracy: 0.5476 - val_loss: 6.3096 - val_accuracy: 0.0105\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9590 - accuracy: 0.5750 - val_loss: 6.6625 - val_accuracy: 0.0885\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9308 - accuracy: 0.5748 - val_loss: 6.8902 - val_accuracy: 0.0131\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9153 - accuracy: 0.5888 - val_loss: 7.0708 - val_accuracy: 0.0359\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9026 - accuracy: 0.5908 - val_loss: 7.5119 - val_accuracy: 0.0210\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8923 - accuracy: 0.5952 - val_loss: 7.6716 - val_accuracy: 0.0368\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8835 - accuracy: 0.5967 - val_loss: 7.5648 - val_accuracy: 0.0175\n",
      "0.5967105031013489\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6226 - accuracy: 0.3059 - val_loss: 3.1383 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1801 - accuracy: 0.4471 - val_loss: 4.8311 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0792 - accuracy: 0.4976 - val_loss: 5.6443 - val_accuracy: 0.0096\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0364 - accuracy: 0.5362 - val_loss: 6.0061 - val_accuracy: 0.0263\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9853 - accuracy: 0.5640 - val_loss: 6.2482 - val_accuracy: 0.0245\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9436 - accuracy: 0.5838 - val_loss: 6.3592 - val_accuracy: 0.0526\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9271 - accuracy: 0.5871 - val_loss: 6.5778 - val_accuracy: 0.0307\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9080 - accuracy: 0.5936 - val_loss: 6.9803 - val_accuracy: 0.0316\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8970 - accuracy: 0.5956 - val_loss: 7.1530 - val_accuracy: 0.0254\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8881 - accuracy: 0.6011 - val_loss: 7.3290 - val_accuracy: 0.0245\n",
      "0.601096510887146\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6362 - accuracy: 0.3169 - val_loss: 3.1167 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2107 - accuracy: 0.4390 - val_loss: 4.9725 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0927 - accuracy: 0.4748 - val_loss: 5.4797 - val_accuracy: 0.0552\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0584 - accuracy: 0.5079 - val_loss: 6.1375 - val_accuracy: 0.0184\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0245 - accuracy: 0.5314 - val_loss: 6.4138 - val_accuracy: 0.0228\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9820 - accuracy: 0.5752 - val_loss: 6.7131 - val_accuracy: 0.0535\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9467 - accuracy: 0.5792 - val_loss: 6.8838 - val_accuracy: 0.0333\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9267 - accuracy: 0.5890 - val_loss: 7.0965 - val_accuracy: 0.0394\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9156 - accuracy: 0.5947 - val_loss: 7.2431 - val_accuracy: 0.0473\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9043 - accuracy: 0.5895 - val_loss: 7.6335 - val_accuracy: 0.0324\n",
      "0.5894736647605896\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6429 - accuracy: 0.3002 - val_loss: 3.0980 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1983 - accuracy: 0.4471 - val_loss: 4.7647 - val_accuracy: 0.0044\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0827 - accuracy: 0.4798 - val_loss: 5.4646 - val_accuracy: 0.0245\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0407 - accuracy: 0.5395 - val_loss: 6.1553 - val_accuracy: 0.0298\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9955 - accuracy: 0.5629 - val_loss: 6.2479 - val_accuracy: 0.0412\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9528 - accuracy: 0.5759 - val_loss: 6.7888 - val_accuracy: 0.0701\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9272 - accuracy: 0.5783 - val_loss: 6.7304 - val_accuracy: 0.0333\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9137 - accuracy: 0.5895 - val_loss: 6.9987 - val_accuracy: 0.0342\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9002 - accuracy: 0.5897 - val_loss: 7.1018 - val_accuracy: 0.0465\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8908 - accuracy: 0.5917 - val_loss: 7.3047 - val_accuracy: 0.0438\n",
      "0.5916666388511658\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6345 - accuracy: 0.2998 - val_loss: 3.0138 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1887 - accuracy: 0.4200 - val_loss: 4.9207 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0776 - accuracy: 0.4814 - val_loss: 5.6179 - val_accuracy: 0.0193\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0304 - accuracy: 0.5377 - val_loss: 5.9710 - val_accuracy: 0.0973\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9791 - accuracy: 0.5445 - val_loss: 6.5347 - val_accuracy: 0.0605\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9378 - accuracy: 0.5873 - val_loss: 6.6747 - val_accuracy: 0.0684\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9172 - accuracy: 0.5789 - val_loss: 7.1138 - val_accuracy: 0.0421\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9041 - accuracy: 0.5899 - val_loss: 7.3687 - val_accuracy: 0.0359\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8916 - accuracy: 0.5932 - val_loss: 7.1272 - val_accuracy: 0.0351\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8829 - accuracy: 0.5967 - val_loss: 7.3670 - val_accuracy: 0.0316\n",
      "0.5967105031013489\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6261 - accuracy: 0.3048 - val_loss: 3.0626 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2046 - accuracy: 0.4294 - val_loss: 4.6568 - val_accuracy: 0.0018\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0733 - accuracy: 0.5134 - val_loss: 5.6299 - val_accuracy: 0.0123\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0010 - accuracy: 0.5592 - val_loss: 6.0921 - val_accuracy: 0.0745\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9513 - accuracy: 0.5737 - val_loss: 6.3509 - val_accuracy: 0.0543\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9270 - accuracy: 0.5833 - val_loss: 6.5272 - val_accuracy: 0.0386\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.9104 - accuracy: 0.5868 - val_loss: 6.7666 - val_accuracy: 0.0438\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8984 - accuracy: 0.5895 - val_loss: 6.9407 - val_accuracy: 0.0333\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8881 - accuracy: 0.6022 - val_loss: 6.8811 - val_accuracy: 0.0526\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 0.8803 - accuracy: 0.6015 - val_loss: 7.0896 - val_accuracy: 0.0228\n",
      "0.6015350818634033\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.6172 - accuracy: 0.3173 - val_loss: 3.0578 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1821 - accuracy: 0.4316 - val_loss: 4.8003 - val_accuracy: 0.0035\n",
      "Epoch 3/10\n",
      "121/143 [========================>.....] - ETA: 0s - loss: 1.0772 - accuracy: 0.4987"
     ]
    }
   ],
   "source": [
    "stream_mean_results=[]\n",
    "current_window = data_init.copy()\n",
    "delta=0.1\n",
    "adwin = ADWIN(delta)\n",
    "detected = False\n",
    "retraining_count=0\n",
    "data_window=data_init.copy()\n",
    "\n",
    "\n",
    "\n",
    "num_models=[]\n",
    "while stream.n_remaining_samples()>1:\n",
    "    \n",
    "    y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_window.copy())\n",
    "        \n",
    "    incoming_data = stream.next_sample(two_percent)\n",
    "    \n",
    "    data_incoming = pd.DataFrame(incoming_data[0], columns=dataset.columns[:-1])\n",
    "    data_incoming[target_variable]=incoming_data[1]\n",
    "    true_values.append(data_incoming[target_variable])\n",
    "    \n",
    "    y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_incoming.copy()) \n",
    "    \n",
    "    \n",
    "    y_pred_uncertainty_total.append(y_pred_uncertainty)\n",
    "    print(len(y_pred_uncertainty))\n",
    "    \n",
    "    detected=False\n",
    "    for i in range(len(data_incoming[target_variable])):\n",
    "        adwin.add_element(y_pred_uncertainty[i])\n",
    "        if adwin.detected_change():\n",
    "            detected = True\n",
    "            break;\n",
    "    \n",
    "    if detected:\n",
    "        print(\"drift has been detected models must be retrained\")\n",
    "        \n",
    "        data_window = update_train_data(data_window, data_incoming)\n",
    "        \n",
    "        retraining_count+=1\n",
    "        \n",
    "        Models=[]\n",
    "        val_acc=[]\n",
    "        train_acc=[]\n",
    "        test_acc=[]\n",
    "        val_loss=[]\n",
    "        train_loss=[]\n",
    "        ind=0\n",
    "        add_weights=[]\n",
    "        \n",
    "        samples = generate_samples_multi(data_init.copy(), 50, N)\n",
    "        \n",
    "        while ind<len(samples):\n",
    "            \n",
    "            train_data=samples[ind]\n",
    "            ind+=1\n",
    "            \n",
    "            ann_model = get_initial_model_2(dataset.shape[1]-1, 6) #same intial weights\n",
    "            ann_model.set_weights(initial_model.get_weights())\n",
    "            X_train=train_data.drop(columns=[target_variable])\n",
    "            print(X_train.shape[1])\n",
    "\n",
    "            y_train=to_categorical(train_data[target_variable], num_classes = 6)\n",
    "\n",
    "            ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # metrics=['accuracy']\n",
    "            history = ann_model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "            print(history.history['accuracy'][-1])\n",
    "\n",
    "\n",
    "\n",
    "            present=False\n",
    "            for i in range(len(Models)):\n",
    "                if (check_models(Models[i][0], ann_model.get_weights())):\n",
    "                  print(\"if any\")\n",
    "                  Models[i][1]=Models[i][1]+1\n",
    "                  add_weights[i].append(ann_model.get_weights())\n",
    "                \n",
    "                  present=True\n",
    "                  break;\n",
    "            if present==False:\n",
    "                add_weights.append([ann_model.get_weights()])\n",
    "                Models.append([ann_model.get_weights(), 1])\n",
    "                \n",
    "        \n",
    "        A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "        \n",
    "        num_models.append(len(A))\n",
    "        recommended_models=[]\n",
    "        for i in range(len(A)):\n",
    "            recommended_models.append(add_weights[A[i]])\n",
    "            \n",
    "        mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss = epsilon_mean_recommendation_2(recommended_models, data_window)\n",
    "        y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_incoming.copy())\n",
    "        y_pred_total.append(y_pred)\n",
    "        \n",
    "    else:\n",
    "        y_pred_total.append(y_pred)\n",
    "        print(\"One lap done.\")\n",
    "        continue\n",
    "    print(\"one thing\")\n",
    "print(retraining_count)\n",
    "\n",
    "predictions=[]\n",
    "for i in y_pred_total:\n",
    "    predictions.append(list(np.argmax(i,axis=1)))\n",
    "predictions = list(np.concatenate(predictions))\n",
    "y_pred_total[0], len(predictions)\n",
    "\n",
    "true_values = list(np.concatenate(true_values))\n",
    "\n",
    "\n",
    "\n",
    "# this is for classification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55be9670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "0.202234382124943\n",
      "0.04485734974970738\n",
      "15\n",
      "0.1791473907715429\n",
      "0.5249700435765734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, mean_squared_error, accuracy_score, mean_absolute_error, f1_score, matthews_corrcoef, mean_squared_error, mean_squared_log_error, roc_auc_score\n",
    "print(num_models)\n",
    "acc_score = accuracy_score(true_values, predictions)\n",
    "print(acc_score)\n",
    "mcc = matthews_corrcoef(true_values, predictions)\n",
    "print(mcc)\n",
    "f1_score = f1_score(true_values, predictions, average = 'weighted')\n",
    "y_pred_total_test = list(np.concatenate(y_pred_total))\n",
    "auc_score = roc_auc_score(true_values, y_pred_total_test, multi_class='ovo')\n",
    "\n",
    "\n",
    "\n",
    "print(retraining_count)\n",
    "\n",
    "print(f1_score)\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b99da01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "some intersection\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "#No training\n",
    "dataset = pd.read_csv(\"./artificial/insects/INSECTS-incremental_balanced_norm.csv\", sep=',')\n",
    "\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#dataset = pd.DataFrame(scaler.fit_transform(dataset), columns=dataset.columns)\n",
    "#target_variable=\n",
    "#dataset[54] = dataset[54]-1\n",
    "#experiments for ADWIN unlimited\n",
    "\n",
    "#try with no retraining\n",
    "\n",
    "#Now lets see for No training\n",
    "\n",
    "from skmultiflow.data import DataStream\n",
    "stream = DataStream(dataset)\n",
    "\n",
    "two_percent = int(stream.n_remaining_samples()*0.02)\n",
    "five_percent = int(stream.n_remaining_samples()*0.05)\n",
    "initial_data = stream.next_sample(int(stream.n_remaining_samples()*0.10))\n",
    "\n",
    "data_init=pd.DataFrame(initial_data[0], columns=dataset.columns[:-1])\n",
    "data_init['Class']=initial_data[1]\n",
    "target_variable='Class'\n",
    "\n",
    "print(data_init['Class'][5])\n",
    "epsilon = 0.1\n",
    "N = int(data_init.shape[0]*0.25)\n",
    "samples = generate_samples_multi(data_init.copy(), 50, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40eb6300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7303 - accuracy: 0.2625 - val_loss: 1.5578 - val_accuracy: 0.3602\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4040 - accuracy: 0.3726 - val_loss: 1.2523 - val_accuracy: 0.4242\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2542 - accuracy: 0.4388 - val_loss: 1.1768 - val_accuracy: 0.4706\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1776 - accuracy: 0.4943 - val_loss: 1.1096 - val_accuracy: 0.5434\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1280 - accuracy: 0.5061 - val_loss: 1.0742 - val_accuracy: 0.5390\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1009 - accuracy: 0.5182 - val_loss: 1.0591 - val_accuracy: 0.5495\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0806 - accuracy: 0.5204 - val_loss: 1.0341 - val_accuracy: 0.5416\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0664 - accuracy: 0.5239 - val_loss: 1.0204 - val_accuracy: 0.5557\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0536 - accuracy: 0.5342 - val_loss: 1.0098 - val_accuracy: 0.5478\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0434 - accuracy: 0.5364 - val_loss: 0.9982 - val_accuracy: 0.5592\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "yhn tk\n",
      "1\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 727us/step - loss: 1.0179 - accuracy: 0.5607\n",
      "54/54 [==============================] - 0s 711us/step - loss: 1.0528 - accuracy: 0.5178\n",
      "179/179 [==============================] - 0s 589us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Models=[]\n",
    "val_acc=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "ind=0\n",
    "add_weights=[]\n",
    "\n",
    "ann_model=get_initial_model_2(dataset.shape[1]-1, 6) \n",
    "\n",
    "X_train=data_init.drop(columns=[target_variable])\n",
    "print(X_train.shape[1])\n",
    "\n",
    "y_train=to_categorical(data_init[target_variable], num_classes = 6)\n",
    "\n",
    "ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # metrics=['accuracy']\n",
    "history = ann_model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "#print(history.history['f1_m'][-1])\n",
    "\n",
    "\n",
    "add_weights.append([ann_model.get_weights()])\n",
    "Models.append([ann_model.get_weights(), 1])\n",
    "\n",
    "\n",
    "print(len(Models))\n",
    "#here use only top 5-10 integrally private models.\n",
    "#add_weights=add_weights[top_5]\n",
    "A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "print(np.array(Models).T[1])\n",
    "print(A)\n",
    "recommended_models=[]\n",
    "for i in range(len(A)):\n",
    "    recommended_models.append(add_weights[A[i]])\n",
    "\n",
    "    \n",
    "mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss = epsilon_mean_recommendation_2(recommended_models, data_init)\n",
    "\n",
    "y_pred_total=[]\n",
    "y_pred_uncertainty_total=[]\n",
    "true_values=[]\n",
    "\n",
    "y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_init.copy())\n",
    "\n",
    "y_pred_total.append(y_pred)\n",
    "y_pred_uncertainty_total.append(y_pred_uncertainty)\n",
    "\n",
    "true_values.append(data_init[target_variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f29dc3e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 670us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 597us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 621us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 676us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 609us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 656us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 633us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 668us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 676us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 695us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 645us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 691us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 716us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 663us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 641us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 669us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 679us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 614us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 638us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 642us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 661us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 637us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 639us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 744us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 620us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 677us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 641us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 619us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 666us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 689us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 637us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 671us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 631us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 652us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 641us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 651us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 656us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 636us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 616us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 639us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 636us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 637us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 646us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 663us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 658us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 649us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 666us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 628us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 657us/step\n",
      "one lap done\n",
      "36/36 [==============================] - 0s 610us/step\n",
      "one lap done\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "one lap done\n"
     ]
    }
   ],
   "source": [
    "#right now trying for mean models\n",
    "stream_mean_results=[]\n",
    "current_window = data_init.copy()\n",
    "\n",
    "data_window=data_init.copy()\n",
    "stream.restart()\n",
    "\n",
    "num_models=[]\n",
    "while stream.n_remaining_samples()>1:\n",
    "    incoming_data = stream.next_sample(two_percent)\n",
    "    #rint(incoming_data)\n",
    "    \n",
    "    data_incoming = pd.DataFrame(incoming_data[0], columns=dataset.columns[:-1])\n",
    "    data_incoming[target_variable]=incoming_data[1]\n",
    "    true_values.append(data_incoming[target_variable])\n",
    "    #print(data_incoming)\n",
    "    y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_incoming.copy()) \n",
    "    #detected, evaluate, adwin = drift_detection_each_model(mean_model_weights, data_incoming.copy(), adwin)\n",
    "    y_pred_total.append(y_pred)\n",
    "    y_pred_uncertainty_total.append(y_pred_uncertainty)\n",
    "    print(\"one lap done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c211c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for i in y_pred_total:\n",
    "    predictions.append(list(np.argmax(i,axis=1)))\n",
    "predictions = list(np.concatenate(predictions))\n",
    "y_pred_total[0], len(predictions)\n",
    "\n",
    "true_values = list(np.concatenate(true_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbca6fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0.2612764871888901\n",
      "0.11453220906245352\n",
      "0.2527293035916669\n",
      "0.5894976422684244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, mean_squared_error, accuracy_score, mean_absolute_error, f1_score, matthews_corrcoef, mean_squared_error, mean_squared_log_error, roc_auc_score\n",
    "print(num_models)\n",
    "acc_score = accuracy_score(true_values, predictions)\n",
    "print(acc_score)\n",
    "mcc = matthews_corrcoef(true_values, predictions)\n",
    "print(mcc)\n",
    "f1_score = f1_score(true_values, predictions, average = 'weighted')\n",
    "y_pred_total_test = list(np.concatenate(y_pred_total))\n",
    "auc_score = roc_auc_score(true_values, y_pred_total_test, multi_class='ovo')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f1_score)\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4670b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "some intersection\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "#Now for adwin unlimited\n",
    "#No training\n",
    "dataset = pd.read_csv(\"./artificial/insects/INSECTS-incremental_balanced_norm.csv\", sep=',')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from skmultiflow.data import DataStream\n",
    "stream = DataStream(dataset)\n",
    "\n",
    "two_percent = int(stream.n_remaining_samples()*0.02)\n",
    "five_percent = int(stream.n_remaining_samples()*0.05)\n",
    "initial_data = stream.next_sample(int(stream.n_remaining_samples()*0.10))\n",
    "\n",
    "data_init=pd.DataFrame(initial_data[0], columns=dataset.columns[:-1])\n",
    "data_init['Class']=initial_data[1]\n",
    "target_variable='Class'\n",
    "\n",
    "print(data_init['Class'][5])\n",
    "epsilon = 0.1\n",
    "N = int(data_init.shape[0]*0.25)\n",
    "samples = generate_samples_multi(data_init.copy(), 50, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15f26483",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7693 - accuracy: 0.2522 - val_loss: 1.6807 - val_accuracy: 0.3278\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.5117 - accuracy: 0.3268 - val_loss: 1.3089 - val_accuracy: 0.4128\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2630 - accuracy: 0.4669 - val_loss: 1.1372 - val_accuracy: 0.5565\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1386 - accuracy: 0.5050 - val_loss: 1.0610 - val_accuracy: 0.5539\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0840 - accuracy: 0.5178 - val_loss: 1.0215 - val_accuracy: 0.5565\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0566 - accuracy: 0.5235 - val_loss: 1.0071 - val_accuracy: 0.5521\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0402 - accuracy: 0.5318 - val_loss: 1.0001 - val_accuracy: 0.5548\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0291 - accuracy: 0.5412 - val_loss: 0.9794 - val_accuracy: 0.5670\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0226 - accuracy: 0.5428 - val_loss: 0.9686 - val_accuracy: 0.5679\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0153 - accuracy: 0.5487 - val_loss: 0.9774 - val_accuracy: 0.5662\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "yhn tk\n",
      "1\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 700us/step - loss: 1.0086 - accuracy: 0.5486\n",
      "54/54 [==============================] - 0s 666us/step - loss: 0.9977 - accuracy: 0.5599\n",
      "179/179 [==============================] - 0s 584us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Models=[]\n",
    "val_acc=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "ind=0\n",
    "add_weights=[]\n",
    "\n",
    "ann_model=get_initial_model_2(dataset.shape[1]-1, 6) \n",
    "\n",
    "X_train=data_init.drop(columns=[target_variable])\n",
    "print(X_train.shape[1])\n",
    "\n",
    "y_train=to_categorical(data_init[target_variable], num_classes = 6)\n",
    "\n",
    "ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # metrics=['accuracy']\n",
    "history = ann_model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "#print(history.history['f1_m'][-1])\n",
    "\n",
    "\n",
    "add_weights.append([ann_model.get_weights()])\n",
    "Models.append([ann_model.get_weights(), 1])\n",
    "\n",
    "\n",
    "print(len(Models))\n",
    "#here use only top 5-10 integrally private models.\n",
    "#add_weights=add_weights[top_5]\n",
    "A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "print(np.array(Models).T[1])\n",
    "print(A)\n",
    "recommended_models=[]\n",
    "for i in range(len(A)):\n",
    "    recommended_models.append(add_weights[A[i]])\n",
    "\n",
    "    \n",
    "mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss = epsilon_mean_recommendation_2(recommended_models, data_init)\n",
    "\n",
    "y_pred_total=[]\n",
    "y_pred_uncertainty_total=[]\n",
    "true_values=[]\n",
    "\n",
    "y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_init.copy())\n",
    "\n",
    "y_pred_total.append(y_pred)\n",
    "y_pred_uncertainty_total.append(y_pred_uncertainty)\n",
    "\n",
    "true_values.append(data_init[target_variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d40fc2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 578us/step\n",
      "36/36 [==============================] - 0s 616us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 554us/step\n",
      "36/36 [==============================] - 0s 655us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 587us/step\n",
      "36/36 [==============================] - 0s 676us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 572us/step\n",
      "36/36 [==============================] - 0s 627us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 563us/step\n",
      "36/36 [==============================] - 0s 589us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 554us/step\n",
      "36/36 [==============================] - 0s 635us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 557us/step\n",
      "36/36 [==============================] - 0s 566us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 519us/step\n",
      "36/36 [==============================] - 0s 565us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 577us/step\n",
      "36/36 [==============================] - 0s 577us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 555us/step\n",
      "36/36 [==============================] - 0s 633us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 576us/step\n",
      "36/36 [==============================] - 0s 650us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 554us/step\n",
      "36/36 [==============================] - 0s 630us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 564us/step\n",
      "36/36 [==============================] - 0s 643us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 572us/step\n",
      "36/36 [==============================] - 0s 641us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 551us/step\n",
      "36/36 [==============================] - 0s 629us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 583us/step\n",
      "36/36 [==============================] - 0s 642us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 559us/step\n",
      "36/36 [==============================] - 0s 621us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 564us/step\n",
      "36/36 [==============================] - 0s 606us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 544us/step\n",
      "36/36 [==============================] - 0s 620us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 582us/step\n",
      "36/36 [==============================] - 0s 663us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 587us/step\n",
      "36/36 [==============================] - 0s 641us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 582us/step\n",
      "36/36 [==============================] - 0s 647us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 586us/step\n",
      "36/36 [==============================] - 0s 623us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 555us/step\n",
      "36/36 [==============================] - 0s 598us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 559us/step\n",
      "36/36 [==============================] - 0s 648us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 589us/step\n",
      "36/36 [==============================] - 0s 624us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 562us/step\n",
      "36/36 [==============================] - 0s 618us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 577us/step\n",
      "36/36 [==============================] - 0s 616us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 610us/step\n",
      "36/36 [==============================] - 0s 658us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 585us/step\n",
      "36/36 [==============================] - 0s 625us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 613us/step\n",
      "36/36 [==============================] - 0s 627us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 563us/step\n",
      "36/36 [==============================] - 0s 582us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 604us/step\n",
      "36/36 [==============================] - 0s 628us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 589us/step\n",
      "36/36 [==============================] - 0s 590us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 583us/step\n",
      "36/36 [==============================] - 0s 642us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 572us/step\n",
      "36/36 [==============================] - 0s 648us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 573us/step\n",
      "36/36 [==============================] - 0s 613us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 623us/step\n",
      "36/36 [==============================] - 0s 633us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 611us/step\n",
      "36/36 [==============================] - 0s 621us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 574us/step\n",
      "36/36 [==============================] - 0s 627us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 558us/step\n",
      "36/36 [==============================] - 0s 619us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 559us/step\n",
      "36/36 [==============================] - 0s 650us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 595us/step\n",
      "36/36 [==============================] - 0s 605us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 591us/step\n",
      "36/36 [==============================] - 0s 615us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 557us/step\n",
      "36/36 [==============================] - 0s 610us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 551us/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "17\n",
      "One lap done.\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[2.72197537e-02, 1.39881368e-03, 1.06656975e-04, 9.29762602e-01,\n",
       "         8.78282764e-04, 4.06339690e-02],\n",
       "        [2.74247140e-01, 5.05133644e-02, 3.72775197e-02, 1.63647845e-01,\n",
       "         1.26225308e-01, 3.48088980e-01],\n",
       "        [7.41291419e-02, 1.76173359e-01, 1.55080080e-01, 9.20884982e-02,\n",
       "         3.32613736e-01, 1.69915155e-01],\n",
       "        ...,\n",
       "        [9.43482369e-02, 7.75247216e-02, 8.57655890e-03, 6.17759109e-01,\n",
       "         4.49896939e-02, 1.56801715e-01],\n",
       "        [1.65285811e-01, 4.93825786e-03, 8.28957243e-04, 6.33944631e-01,\n",
       "         6.50613243e-03, 1.88496217e-01],\n",
       "        [5.23847761e-04, 2.60416031e-01, 4.43820268e-01, 3.59895232e-04,\n",
       "         2.93592602e-01, 1.28739583e-03]], dtype=float32),\n",
       " 57018)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_mean_results=[]\n",
    "current_window = data_init.copy()\n",
    "delta=0.01\n",
    "adwin = ADWIN(delta)\n",
    "detected = False\n",
    "retraining_count=0\n",
    "data_window=data_init.copy()\n",
    "\n",
    "\n",
    "\n",
    "num_models=[]\n",
    "while stream.n_remaining_samples()>1:\n",
    "    \n",
    "    y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_window.copy())\n",
    "        \n",
    "    incoming_data = stream.next_sample(two_percent)\n",
    "    \n",
    "    data_incoming = pd.DataFrame(incoming_data[0], columns=dataset.columns[:-1])\n",
    "    data_incoming[target_variable]=incoming_data[1]\n",
    "    true_values.append(data_incoming[target_variable])\n",
    "    \n",
    "    y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_incoming.copy()) \n",
    "    \n",
    "    \n",
    "    y_pred_uncertainty_total.append(y_pred_uncertainty)\n",
    "    print(len(y_pred_uncertainty))\n",
    "    \n",
    "    detected=False\n",
    "    for i in range(len(data_incoming[target_variable])):\n",
    "        adwin.add_element(data_incoming[target_variable][i])\n",
    "        if adwin.detected_change():\n",
    "            detected = True\n",
    "            break;\n",
    "    \n",
    "    if detected:\n",
    "        print(\"drift has been detecte models must be retrained\")\n",
    "        \n",
    "        data_window = update_train_data(data_window, data_incoming)\n",
    "        \n",
    "        retraining_count+=1\n",
    "        \n",
    "        Models=[]\n",
    "        val_acc=[]\n",
    "        train_acc=[]\n",
    "        test_acc=[]\n",
    "        val_loss=[]\n",
    "        train_loss=[]\n",
    "        ind=0\n",
    "        add_weights=[]\n",
    "\n",
    "        ann_model=get_initial_model(dataset.shape[1]-1, 6) \n",
    "\n",
    "        X_train=data_init.drop(columns=[target_variable])\n",
    "        print(X_train.shape[1])\n",
    "\n",
    "        y_train=to_categorical(data_init[target_variable], num_classes = 6)\n",
    "\n",
    "        ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # metrics=['accuracy']\n",
    "        history = ann_model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "        #print(history.history['f1_m'][-1])\n",
    "\n",
    "\n",
    "        add_weights.append([ann_model.get_weights()])\n",
    "        Models.append([ann_model.get_weights(), 1])\n",
    "\n",
    "\n",
    "        print(len(Models))\n",
    "        #here use only top 5-10 integrally private models.\n",
    "        #add_weights=add_weights[top_5]\n",
    "        A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "        print(np.array(Models).T[1])\n",
    "        print(A)\n",
    "        recommended_models=[]\n",
    "        for i in range(len(A)):\n",
    "            recommended_models.append(add_weights[A[i]])\n",
    "\n",
    "\n",
    "        mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss = epsilon_mean_recommendation_2(recommended_models, data_init)\n",
    "\n",
    "        \n",
    "        A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "        \n",
    "        num_models.append(len(A))\n",
    "        recommended_models=[]\n",
    "        for i in range(len(A)):\n",
    "            recommended_models.append(add_weights[A[i]])\n",
    "            \n",
    "        mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss = epsilon_mean_recommendation_2(recommended_models, data_window)\n",
    "        y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_incoming.copy())\n",
    "        y_pred_total.append(y_pred)\n",
    "        \n",
    "    else:\n",
    "        y_pred_total.append(y_pred)\n",
    "        print(\"One lap done.\")\n",
    "        continue\n",
    "    print(\"one thing\")\n",
    "print(retraining_count)\n",
    "\n",
    "predictions=[]\n",
    "for i in y_pred_total:\n",
    "    predictions.append(list(np.argmax(i,axis=1)))\n",
    "predictions = list(np.concatenate(predictions))\n",
    "y_pred_total[0], len(predictions)\n",
    "\n",
    "# this is for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd434564",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for i in y_pred_total:\n",
    "    predictions.append(list(np.argmax(i,axis=1)))\n",
    "predictions = list(np.concatenate(predictions))\n",
    "y_pred_total[0], len(predictions)\n",
    "\n",
    "true_values = list(np.concatenate(true_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99e0bbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0.24758848083061488\n",
      "0.0978962623690366\n",
      "0\n",
      "0.24350957147649546\n",
      "0.5799595494298787\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, mean_squared_error, accuracy_score, mean_absolute_error, f1_score, matthews_corrcoef, mean_squared_error, mean_squared_log_error, roc_auc_score\n",
    "print(num_models)\n",
    "acc_score = accuracy_score(true_values, predictions)\n",
    "print(acc_score)\n",
    "mcc = matthews_corrcoef(true_values, predictions)\n",
    "print(mcc)\n",
    "f1_score = f1_score(true_values, predictions, average = 'weighted')\n",
    "y_pred_total_test = list(np.concatenate(y_pred_total))\n",
    "auc_score = roc_auc_score(true_values, y_pred_total_test, multi_class='ovo')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(retraining_count)\n",
    "print(f1_score)\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28d7220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "some intersection\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "#Now for adwin limited\n",
    "#No training\n",
    "dataset = pd.read_csv(\"./artificial/insects/INSECTS-incremental_balanced_norm.csv\", sep=',')\n",
    "\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#dataset = pd.DataFrame(scaler.fit_transform(dataset), columns=dataset.columns)\n",
    "#target_variable=\n",
    "#dataset[54] = dataset[54]-1\n",
    "#experiments for ADWIN unlimited\n",
    "\n",
    "#try with no retraining\n",
    "\n",
    "#Now lets see for No training\n",
    "\n",
    "from skmultiflow.data import DataStream\n",
    "stream = DataStream(dataset)\n",
    "\n",
    "two_percent = int(stream.n_remaining_samples()*0.02)\n",
    "five_percent = int(stream.n_remaining_samples()*0.05)\n",
    "initial_data = stream.next_sample(int(stream.n_remaining_samples()*0.10))\n",
    "\n",
    "data_init=pd.DataFrame(initial_data[0], columns=dataset.columns[:-1])\n",
    "data_init['Class']=initial_data[1]\n",
    "target_variable='Class'\n",
    "\n",
    "print(data_init['Class'][5])\n",
    "epsilon = 0.1\n",
    "N = int(data_init.shape[0]*0.25)\n",
    "samples = generate_samples_multi(data_init.copy(), 50, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3e705a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7587 - accuracy: 0.2921 - val_loss: 1.6912 - val_accuracy: 0.4479\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6326 - accuracy: 0.4333 - val_loss: 1.5199 - val_accuracy: 0.4628\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4815 - accuracy: 0.4458 - val_loss: 1.3633 - val_accuracy: 0.4636\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3624 - accuracy: 0.4879 - val_loss: 1.2568 - val_accuracy: 0.5197\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2822 - accuracy: 0.5086 - val_loss: 1.1900 - val_accuracy: 0.5486\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2285 - accuracy: 0.5186 - val_loss: 1.1381 - val_accuracy: 0.5513\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1903 - accuracy: 0.5228 - val_loss: 1.1054 - val_accuracy: 0.5635\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1625 - accuracy: 0.5276 - val_loss: 1.0838 - val_accuracy: 0.5627\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1397 - accuracy: 0.5300 - val_loss: 1.0629 - val_accuracy: 0.5644\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1227 - accuracy: 0.5261 - val_loss: 1.0474 - val_accuracy: 0.5618\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 667us/step - loss: 1.1023 - accuracy: 0.5373\n",
      "54/54 [==============================] - 0s 673us/step - loss: 1.0967 - accuracy: 0.5412\n",
      "179/179 [==============================] - 0s 535us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Models=[]\n",
    "val_acc=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "ind=0\n",
    "add_weights=[]\n",
    "\n",
    "ann_model=get_initial_model(dataset.shape[1]-1, 6) \n",
    "\n",
    "X_train=data_init.drop(columns=[target_variable])\n",
    "print(X_train.shape[1])\n",
    "\n",
    "y_train=to_categorical(data_init[target_variable], num_classes = 6)\n",
    "\n",
    "ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # metrics=['accuracy']\n",
    "history = ann_model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "#print(history.history['f1_m'][-1])\n",
    "\n",
    "\n",
    "add_weights.append([ann_model.get_weights()])\n",
    "Models.append([ann_model.get_weights(), 1])\n",
    "\n",
    "\n",
    "print(len(Models))\n",
    "#here use only top 5-10 integrally private models.\n",
    "#add_weights=add_weights[top_5]\n",
    "A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "print(np.array(Models).T[1])\n",
    "print(A)\n",
    "recommended_models=[]\n",
    "for i in range(len(A)):\n",
    "    recommended_models.append(add_weights[A[i]])\n",
    "\n",
    "    \n",
    "mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss = epsilon_mean_recommendation(recommended_models, data_init)\n",
    "\n",
    "y_pred_total=[]\n",
    "y_pred_uncertainty_total=[]\n",
    "true_values=[]\n",
    "\n",
    "y_pred, y_pred_uncertainty = drift_detection(mean_model_weights, data_init.copy())\n",
    "\n",
    "y_pred_total.append(y_pred)\n",
    "y_pred_uncertainty_total.append(y_pred_uncertainty)\n",
    "\n",
    "true_values.append(data_init[target_variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7dc1f580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 523us/step\n",
      "36/36 [==============================] - 0s 581us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 534us/step\n",
      "36/36 [==============================] - 0s 601us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7720 - accuracy: 0.2779 - val_loss: 1.7363 - val_accuracy: 0.4294\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6938 - accuracy: 0.4138 - val_loss: 1.6147 - val_accuracy: 0.4838\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.5659 - accuracy: 0.4640 - val_loss: 1.4621 - val_accuracy: 0.5013\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4372 - accuracy: 0.4759 - val_loss: 1.3338 - val_accuracy: 0.5101\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3382 - accuracy: 0.4919 - val_loss: 1.2410 - val_accuracy: 0.5083\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2696 - accuracy: 0.4912 - val_loss: 1.1780 - val_accuracy: 0.5162\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2213 - accuracy: 0.4921 - val_loss: 1.1344 - val_accuracy: 0.5381\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1886 - accuracy: 0.5039 - val_loss: 1.1040 - val_accuracy: 0.5495\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1639 - accuracy: 0.5116 - val_loss: 1.0835 - val_accuracy: 0.5530\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1452 - accuracy: 0.5228 - val_loss: 1.0663 - val_accuracy: 0.5600\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 685us/step - loss: 1.1192 - accuracy: 0.5336\n",
      "54/54 [==============================] - 0s 680us/step - loss: 1.1262 - accuracy: 0.5266\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 662us/step - loss: 1.1237 - accuracy: 0.5318\n",
      "54/54 [==============================] - 0s 655us/step - loss: 1.1316 - accuracy: 0.5266\n",
      "36/36 [==============================] - 0s 648us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 529us/step\n",
      "36/36 [==============================] - 0s 595us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7687 - accuracy: 0.2967 - val_loss: 1.7214 - val_accuracy: 0.4855\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6557 - accuracy: 0.4390 - val_loss: 1.5474 - val_accuracy: 0.4750\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4951 - accuracy: 0.4577 - val_loss: 1.3825 - val_accuracy: 0.4969\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3664 - accuracy: 0.4919 - val_loss: 1.2669 - val_accuracy: 0.5443\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2796 - accuracy: 0.5066 - val_loss: 1.1889 - val_accuracy: 0.5372\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2220 - accuracy: 0.5136 - val_loss: 1.1385 - val_accuracy: 0.5399\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1825 - accuracy: 0.5134 - val_loss: 1.1046 - val_accuracy: 0.5443\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1551 - accuracy: 0.5263 - val_loss: 1.0810 - val_accuracy: 0.5495\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1337 - accuracy: 0.5250 - val_loss: 1.0602 - val_accuracy: 0.5521\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1180 - accuracy: 0.5281 - val_loss: 1.0474 - val_accuracy: 0.5521\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 695us/step - loss: 1.1010 - accuracy: 0.5328\n",
      "54/54 [==============================] - 0s 643us/step - loss: 1.0874 - accuracy: 0.5389\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 693us/step - loss: 1.2038 - accuracy: 0.5088\n",
      "54/54 [==============================] - 0s 696us/step - loss: 1.1980 - accuracy: 0.4956\n",
      "36/36 [==============================] - 0s 571us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 544us/step\n",
      "36/36 [==============================] - 0s 602us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7563 - accuracy: 0.3103 - val_loss: 1.7021 - val_accuracy: 0.3918\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6599 - accuracy: 0.4000 - val_loss: 1.5707 - val_accuracy: 0.4259\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.5338 - accuracy: 0.4248 - val_loss: 1.4308 - val_accuracy: 0.4338\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4196 - accuracy: 0.4491 - val_loss: 1.3232 - val_accuracy: 0.5110\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3353 - accuracy: 0.4917 - val_loss: 1.2445 - val_accuracy: 0.5390\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2772 - accuracy: 0.5046 - val_loss: 1.1904 - val_accuracy: 0.5469\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2354 - accuracy: 0.5090 - val_loss: 1.1521 - val_accuracy: 0.5521\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2027 - accuracy: 0.5088 - val_loss: 1.1227 - val_accuracy: 0.5592\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1757 - accuracy: 0.5184 - val_loss: 1.0960 - val_accuracy: 0.5644\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1534 - accuracy: 0.5252 - val_loss: 1.0762 - val_accuracy: 0.5618\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 690us/step - loss: 1.1238 - accuracy: 0.5436\n",
      "54/54 [==============================] - 0s 669us/step - loss: 1.1454 - accuracy: 0.5067\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 692us/step - loss: 1.3436 - accuracy: 0.4679\n",
      "54/54 [==============================] - 0s 684us/step - loss: 1.3032 - accuracy: 0.4681\n",
      "36/36 [==============================] - 0s 589us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 555us/step\n",
      "36/36 [==============================] - 0s 609us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7729 - accuracy: 0.2379 - val_loss: 1.7376 - val_accuracy: 0.3208\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7070 - accuracy: 0.3531 - val_loss: 1.6413 - val_accuracy: 0.3953\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6027 - accuracy: 0.4094 - val_loss: 1.5072 - val_accuracy: 0.4619\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4821 - accuracy: 0.4575 - val_loss: 1.3786 - val_accuracy: 0.5101\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3786 - accuracy: 0.4820 - val_loss: 1.2782 - val_accuracy: 0.5197\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3021 - accuracy: 0.4919 - val_loss: 1.2095 - val_accuracy: 0.5171\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2468 - accuracy: 0.4965 - val_loss: 1.1597 - val_accuracy: 0.5215\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2083 - accuracy: 0.5059 - val_loss: 1.1237 - val_accuracy: 0.5276\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1785 - accuracy: 0.5068 - val_loss: 1.0949 - val_accuracy: 0.5320\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1559 - accuracy: 0.5064 - val_loss: 1.0780 - val_accuracy: 0.5311\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 684us/step - loss: 1.1294 - accuracy: 0.5226\n",
      "54/54 [==============================] - 0s 695us/step - loss: 1.1417 - accuracy: 0.5067\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 691us/step - loss: 1.3744 - accuracy: 0.4170\n",
      "54/54 [==============================] - 0s 700us/step - loss: 1.3894 - accuracy: 0.4015\n",
      "36/36 [==============================] - 0s 621us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 577us/step\n",
      "36/36 [==============================] - 0s 600us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7782 - accuracy: 0.2509 - val_loss: 1.7450 - val_accuracy: 0.3734\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6954 - accuracy: 0.3998 - val_loss: 1.6079 - val_accuracy: 0.4443\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.5567 - accuracy: 0.4518 - val_loss: 1.4492 - val_accuracy: 0.5276\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4257 - accuracy: 0.4921 - val_loss: 1.3222 - val_accuracy: 0.5372\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3298 - accuracy: 0.5081 - val_loss: 1.2357 - val_accuracy: 0.5425\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2660 - accuracy: 0.5138 - val_loss: 1.1781 - val_accuracy: 0.5416\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2216 - accuracy: 0.5123 - val_loss: 1.1398 - val_accuracy: 0.5381\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1915 - accuracy: 0.5158 - val_loss: 1.1110 - val_accuracy: 0.5425\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1682 - accuracy: 0.5178 - val_loss: 1.0923 - val_accuracy: 0.5583\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1505 - accuracy: 0.5197 - val_loss: 1.0774 - val_accuracy: 0.5486\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 702us/step - loss: 1.1200 - accuracy: 0.5281\n",
      "54/54 [==============================] - 0s 694us/step - loss: 1.1487 - accuracy: 0.5190\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 678us/step - loss: 1.6103 - accuracy: 0.3489\n",
      "54/54 [==============================] - 0s 684us/step - loss: 1.5878 - accuracy: 0.3390\n",
      "36/36 [==============================] - 0s 612us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 532us/step\n",
      "36/36 [==============================] - 0s 580us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7568 - accuracy: 0.2219 - val_loss: 1.7012 - val_accuracy: 0.2936\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6500 - accuracy: 0.3099 - val_loss: 1.5649 - val_accuracy: 0.3646\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.5231 - accuracy: 0.3789 - val_loss: 1.4277 - val_accuracy: 0.4102\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4092 - accuracy: 0.4285 - val_loss: 1.3149 - val_accuracy: 0.4847\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3216 - accuracy: 0.4798 - val_loss: 1.2339 - val_accuracy: 0.5320\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2595 - accuracy: 0.5004 - val_loss: 1.1760 - val_accuracy: 0.5399\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2149 - accuracy: 0.5061 - val_loss: 1.1389 - val_accuracy: 0.5486\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1827 - accuracy: 0.5116 - val_loss: 1.1065 - val_accuracy: 0.5513\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1578 - accuracy: 0.5059 - val_loss: 1.0840 - val_accuracy: 0.5434\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1385 - accuracy: 0.5134 - val_loss: 1.0674 - val_accuracy: 0.5460\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 677us/step - loss: 1.1141 - accuracy: 0.5231\n",
      "54/54 [==============================] - 0s 686us/step - loss: 1.1205 - accuracy: 0.5149\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 712us/step - loss: 1.6817 - accuracy: 0.3348\n",
      "54/54 [==============================] - 0s 673us/step - loss: 1.6434 - accuracy: 0.3472\n",
      "36/36 [==============================] - 0s 586us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 520us/step\n",
      "36/36 [==============================] - 0s 579us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 580us/step\n",
      "36/36 [==============================] - 0s 615us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 573us/step\n",
      "36/36 [==============================] - 0s 576us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7606 - accuracy: 0.3013 - val_loss: 1.7081 - val_accuracy: 0.4242\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6480 - accuracy: 0.4480 - val_loss: 1.5433 - val_accuracy: 0.4987\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4938 - accuracy: 0.4838 - val_loss: 1.3800 - val_accuracy: 0.5320\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3654 - accuracy: 0.4893 - val_loss: 1.2647 - val_accuracy: 0.5627\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2789 - accuracy: 0.5031 - val_loss: 1.1867 - val_accuracy: 0.5592\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2214 - accuracy: 0.5042 - val_loss: 1.1382 - val_accuracy: 0.5574\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1831 - accuracy: 0.5103 - val_loss: 1.1073 - val_accuracy: 0.5627\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1566 - accuracy: 0.5123 - val_loss: 1.0819 - val_accuracy: 0.5574\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1368 - accuracy: 0.5134 - val_loss: 1.0633 - val_accuracy: 0.5425\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1211 - accuracy: 0.5140 - val_loss: 1.0529 - val_accuracy: 0.5486\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 652us/step - loss: 1.0933 - accuracy: 0.5296\n",
      "54/54 [==============================] - 0s 636us/step - loss: 1.1217 - accuracy: 0.5120\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 688us/step - loss: 1.8403 - accuracy: 0.2850\n",
      "54/54 [==============================] - 0s 649us/step - loss: 1.8314 - accuracy: 0.2835\n",
      "36/36 [==============================] - 0s 593us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 543us/step\n",
      "36/36 [==============================] - 0s 614us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 553us/step\n",
      "36/36 [==============================] - 0s 617us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 571us/step\n",
      "36/36 [==============================] - 0s 599us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 569us/step\n",
      "36/36 [==============================] - 0s 629us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 556us/step\n",
      "36/36 [==============================] - 0s 609us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 540us/step\n",
      "36/36 [==============================] - 0s 591us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 536us/step\n",
      "36/36 [==============================] - 0s 598us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7748 - accuracy: 0.2520 - val_loss: 1.7474 - val_accuracy: 0.3883\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7142 - accuracy: 0.3675 - val_loss: 1.6420 - val_accuracy: 0.4400\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6026 - accuracy: 0.4239 - val_loss: 1.5005 - val_accuracy: 0.4452\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4817 - accuracy: 0.4346 - val_loss: 1.3750 - val_accuracy: 0.4908\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3816 - accuracy: 0.4719 - val_loss: 1.2789 - val_accuracy: 0.5136\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3065 - accuracy: 0.4919 - val_loss: 1.2097 - val_accuracy: 0.5329\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2516 - accuracy: 0.5160 - val_loss: 1.1585 - val_accuracy: 0.5434\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2103 - accuracy: 0.5217 - val_loss: 1.1220 - val_accuracy: 0.5539\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1788 - accuracy: 0.5292 - val_loss: 1.0937 - val_accuracy: 0.5495\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1550 - accuracy: 0.5239 - val_loss: 1.0709 - val_accuracy: 0.5592\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 666us/step - loss: 1.1298 - accuracy: 0.5301\n",
      "54/54 [==============================] - 0s 631us/step - loss: 1.1273 - accuracy: 0.5400\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 657us/step - loss: 1.8811 - accuracy: 0.2692\n",
      "54/54 [==============================] - 0s 658us/step - loss: 1.8682 - accuracy: 0.2607\n",
      "36/36 [==============================] - 0s 592us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 532us/step\n",
      "36/36 [==============================] - 0s 594us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 534us/step\n",
      "36/36 [==============================] - 0s 598us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7778 - accuracy: 0.2925 - val_loss: 1.7526 - val_accuracy: 0.3970\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7174 - accuracy: 0.3860 - val_loss: 1.6463 - val_accuracy: 0.3839\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6062 - accuracy: 0.3956 - val_loss: 1.5134 - val_accuracy: 0.3935\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4941 - accuracy: 0.3987 - val_loss: 1.3978 - val_accuracy: 0.4058\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4042 - accuracy: 0.4112 - val_loss: 1.3148 - val_accuracy: 0.4365\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3385 - accuracy: 0.4333 - val_loss: 1.2533 - val_accuracy: 0.4636\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2885 - accuracy: 0.4717 - val_loss: 1.2079 - val_accuracy: 0.4969\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2506 - accuracy: 0.4785 - val_loss: 1.1726 - val_accuracy: 0.5048\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2203 - accuracy: 0.5033 - val_loss: 1.1435 - val_accuracy: 0.5206\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1946 - accuracy: 0.5042 - val_loss: 1.1197 - val_accuracy: 0.5408\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 682us/step - loss: 1.1694 - accuracy: 0.5180\n",
      "54/54 [==============================] - 0s 684us/step - loss: 1.1706 - accuracy: 0.5190\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 672us/step - loss: 2.0084 - accuracy: 0.2383\n",
      "54/54 [==============================] - 0s 655us/step - loss: 2.0141 - accuracy: 0.2285\n",
      "36/36 [==============================] - 0s 594us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 550us/step\n",
      "36/36 [==============================] - 0s 608us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7535 - accuracy: 0.3268 - val_loss: 1.6926 - val_accuracy: 0.4189\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6384 - accuracy: 0.4039 - val_loss: 1.5414 - val_accuracy: 0.4575\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4997 - accuracy: 0.4544 - val_loss: 1.3953 - val_accuracy: 0.5118\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3809 - accuracy: 0.4989 - val_loss: 1.2786 - val_accuracy: 0.5469\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2895 - accuracy: 0.5099 - val_loss: 1.1930 - val_accuracy: 0.5565\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2243 - accuracy: 0.5193 - val_loss: 1.1361 - val_accuracy: 0.5653\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1801 - accuracy: 0.5228 - val_loss: 1.0939 - val_accuracy: 0.5557\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1490 - accuracy: 0.5248 - val_loss: 1.0688 - val_accuracy: 0.5688\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1269 - accuracy: 0.5314 - val_loss: 1.0486 - val_accuracy: 0.5600\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1110 - accuracy: 0.5388 - val_loss: 1.0372 - val_accuracy: 0.5670\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 645us/step - loss: 1.0901 - accuracy: 0.5404\n",
      "54/54 [==============================] - 0s 648us/step - loss: 1.0864 - accuracy: 0.5441\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 656us/step - loss: 2.3254 - accuracy: 0.2140\n",
      "54/54 [==============================] - 0s 672us/step - loss: 2.3269 - accuracy: 0.2227\n",
      "36/36 [==============================] - 0s 576us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 547us/step\n",
      "36/36 [==============================] - 0s 568us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 554us/step\n",
      "36/36 [==============================] - 0s 613us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 559us/step\n",
      "36/36 [==============================] - 0s 613us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7677 - accuracy: 0.3018 - val_loss: 1.7262 - val_accuracy: 0.3970\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6863 - accuracy: 0.4123 - val_loss: 1.6020 - val_accuracy: 0.4566\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.5591 - accuracy: 0.4634 - val_loss: 1.4483 - val_accuracy: 0.5101\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4334 - accuracy: 0.4877 - val_loss: 1.3246 - val_accuracy: 0.5329\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3405 - accuracy: 0.4917 - val_loss: 1.2401 - val_accuracy: 0.5486\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2768 - accuracy: 0.5013 - val_loss: 1.1830 - val_accuracy: 0.5425\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2305 - accuracy: 0.5048 - val_loss: 1.1413 - val_accuracy: 0.5390\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1972 - accuracy: 0.5075 - val_loss: 1.1121 - val_accuracy: 0.5443\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1715 - accuracy: 0.5110 - val_loss: 1.0890 - val_accuracy: 0.5495\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1509 - accuracy: 0.5127 - val_loss: 1.0710 - val_accuracy: 0.5574\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 666us/step - loss: 1.1330 - accuracy: 0.5140\n",
      "54/54 [==============================] - 0s 667us/step - loss: 1.1123 - accuracy: 0.5435\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 672us/step - loss: 2.3299 - accuracy: 0.1945\n",
      "54/54 [==============================] - 0s 680us/step - loss: 2.3469 - accuracy: 0.1975\n",
      "36/36 [==============================] - 0s 574us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 527us/step\n",
      "36/36 [==============================] - 0s 637us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 562us/step\n",
      "36/36 [==============================] - 0s 608us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 541us/step\n",
      "36/36 [==============================] - 0s 584us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7812 - accuracy: 0.1686 - val_loss: 1.7570 - val_accuracy: 0.2524\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7203 - accuracy: 0.3103 - val_loss: 1.6481 - val_accuracy: 0.3243\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.5916 - accuracy: 0.4103 - val_loss: 1.4820 - val_accuracy: 0.4952\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4531 - accuracy: 0.4939 - val_loss: 1.3445 - val_accuracy: 0.5337\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3488 - accuracy: 0.5024 - val_loss: 1.2493 - val_accuracy: 0.5557\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2771 - accuracy: 0.5127 - val_loss: 1.1854 - val_accuracy: 0.5539\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2282 - accuracy: 0.5103 - val_loss: 1.1423 - val_accuracy: 0.5539\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1932 - accuracy: 0.5132 - val_loss: 1.1115 - val_accuracy: 0.5451\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1670 - accuracy: 0.5173 - val_loss: 1.0896 - val_accuracy: 0.5443\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1464 - accuracy: 0.5160 - val_loss: 1.0690 - val_accuracy: 0.5565\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 671us/step - loss: 1.1162 - accuracy: 0.5336\n",
      "54/54 [==============================] - 0s 684us/step - loss: 1.1412 - accuracy: 0.5196\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 675us/step - loss: 2.4185 - accuracy: 0.1772\n",
      "54/54 [==============================] - 0s 676us/step - loss: 2.3897 - accuracy: 0.1818\n",
      "36/36 [==============================] - 0s 561us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 498us/step\n",
      "36/36 [==============================] - 0s 601us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7594 - accuracy: 0.2739 - val_loss: 1.7091 - val_accuracy: 0.3523\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6689 - accuracy: 0.3761 - val_loss: 1.5784 - val_accuracy: 0.4619\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.5415 - accuracy: 0.4607 - val_loss: 1.4304 - val_accuracy: 0.4934\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4177 - accuracy: 0.4882 - val_loss: 1.3063 - val_accuracy: 0.5171\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3220 - accuracy: 0.4930 - val_loss: 1.2170 - val_accuracy: 0.5416\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2537 - accuracy: 0.5077 - val_loss: 1.1587 - val_accuracy: 0.5469\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2054 - accuracy: 0.5134 - val_loss: 1.1163 - val_accuracy: 0.5478\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1693 - accuracy: 0.5114 - val_loss: 1.0836 - val_accuracy: 0.5495\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1428 - accuracy: 0.5217 - val_loss: 1.0620 - val_accuracy: 0.5504\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1220 - accuracy: 0.5239 - val_loss: 1.0455 - val_accuracy: 0.5539\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 733us/step - loss: 1.0924 - accuracy: 0.5291\n",
      "54/54 [==============================] - 0s 707us/step - loss: 1.1113 - accuracy: 0.5319\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 714us/step - loss: 2.4542 - accuracy: 0.1649\n",
      "54/54 [==============================] - 0s 694us/step - loss: 2.3807 - accuracy: 0.1835\n",
      "36/36 [==============================] - 0s 618us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 563us/step\n",
      "36/36 [==============================] - 0s 604us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 550us/step\n",
      "36/36 [==============================] - 0s 587us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 566us/step\n",
      "36/36 [==============================] - 0s 597us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 560us/step\n",
      "36/36 [==============================] - 0s 574us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 539us/step\n",
      "36/36 [==============================] - 0s 586us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 521us/step\n",
      "36/36 [==============================] - 0s 582us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7606 - accuracy: 0.2908 - val_loss: 1.7029 - val_accuracy: 0.3225\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6390 - accuracy: 0.3612 - val_loss: 1.5399 - val_accuracy: 0.4461\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4921 - accuracy: 0.4572 - val_loss: 1.3925 - val_accuracy: 0.5162\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3776 - accuracy: 0.4925 - val_loss: 1.2866 - val_accuracy: 0.5259\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2972 - accuracy: 0.5053 - val_loss: 1.2151 - val_accuracy: 0.5206\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2422 - accuracy: 0.5057 - val_loss: 1.1644 - val_accuracy: 0.5346\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2015 - accuracy: 0.5116 - val_loss: 1.1274 - val_accuracy: 0.5355\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1713 - accuracy: 0.5182 - val_loss: 1.0996 - val_accuracy: 0.5355\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1472 - accuracy: 0.5197 - val_loss: 1.0812 - val_accuracy: 0.5355\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1288 - accuracy: 0.5263 - val_loss: 1.0615 - val_accuracy: 0.5451\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 654us/step - loss: 1.1039 - accuracy: 0.5353\n",
      "54/54 [==============================] - 0s 645us/step - loss: 1.1155 - accuracy: 0.5225\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 682us/step - loss: 2.6039 - accuracy: 0.1619\n",
      "54/54 [==============================] - 0s 674us/step - loss: 2.6151 - accuracy: 0.1759\n",
      "36/36 [==============================] - 0s 613us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 547us/step\n",
      "36/36 [==============================] - 0s 604us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 543us/step\n",
      "36/36 [==============================] - 0s 605us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 583us/step\n",
      "36/36 [==============================] - 0s 601us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 583us/step\n",
      "36/36 [==============================] - 0s 586us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 543us/step\n",
      "36/36 [==============================] - 0s 567us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7634 - accuracy: 0.3009 - val_loss: 1.7120 - val_accuracy: 0.3909\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6580 - accuracy: 0.3925 - val_loss: 1.5613 - val_accuracy: 0.4522\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.5152 - accuracy: 0.4474 - val_loss: 1.4062 - val_accuracy: 0.5215\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3930 - accuracy: 0.4947 - val_loss: 1.2913 - val_accuracy: 0.5381\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3058 - accuracy: 0.5046 - val_loss: 1.2136 - val_accuracy: 0.5364\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2461 - accuracy: 0.5079 - val_loss: 1.1598 - val_accuracy: 0.5495\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2026 - accuracy: 0.5140 - val_loss: 1.1232 - val_accuracy: 0.5355\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1720 - accuracy: 0.5239 - val_loss: 1.0946 - val_accuracy: 0.5521\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1483 - accuracy: 0.5239 - val_loss: 1.0731 - val_accuracy: 0.5618\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1300 - accuracy: 0.5226 - val_loss: 1.0593 - val_accuracy: 0.5521\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 643us/step - loss: 1.1017 - accuracy: 0.5396\n",
      "54/54 [==============================] - 0s 632us/step - loss: 1.1244 - accuracy: 0.5114\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 683us/step - loss: 2.6102 - accuracy: 0.1609\n",
      "54/54 [==============================] - 0s 672us/step - loss: 2.5815 - accuracy: 0.1742\n",
      "36/36 [==============================] - 0s 593us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 562us/step\n",
      "36/36 [==============================] - 0s 607us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 561us/step\n",
      "36/36 [==============================] - 0s 591us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 542us/step\n",
      "36/36 [==============================] - 0s 546us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 577us/step\n",
      "36/36 [==============================] - 0s 599us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 550us/step\n",
      "36/36 [==============================] - 0s 657us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 557us/step\n",
      "36/36 [==============================] - 0s 671us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 578us/step\n",
      "36/36 [==============================] - 0s 579us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7620 - accuracy: 0.2520 - val_loss: 1.7116 - val_accuracy: 0.2559\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.6632 - accuracy: 0.2781 - val_loss: 1.5833 - val_accuracy: 0.3252\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.5387 - accuracy: 0.3616 - val_loss: 1.4458 - val_accuracy: 0.4268\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4192 - accuracy: 0.4461 - val_loss: 1.3267 - val_accuracy: 0.4671\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.3185 - accuracy: 0.4711 - val_loss: 1.2250 - val_accuracy: 0.5074\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.2450 - accuracy: 0.4928 - val_loss: 1.1609 - val_accuracy: 0.5074\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1987 - accuracy: 0.4950 - val_loss: 1.1196 - val_accuracy: 0.5337\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1677 - accuracy: 0.5110 - val_loss: 1.0916 - val_accuracy: 0.5592\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1455 - accuracy: 0.5180 - val_loss: 1.0711 - val_accuracy: 0.5478\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1286 - accuracy: 0.5191 - val_loss: 1.0572 - val_accuracy: 0.5346\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 684us/step - loss: 1.1071 - accuracy: 0.5173\n",
      "54/54 [==============================] - 0s 678us/step - loss: 1.1084 - accuracy: 0.5330\n",
      "andr aara h\n",
      "andr aara h\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/x_ayuku/.conda/envs/ip_test/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 681us/step - loss: 2.7663 - accuracy: 0.1689\n",
      "54/54 [==============================] - 0s 681us/step - loss: 2.7708 - accuracy: 0.1718\n",
      "36/36 [==============================] - 0s 572us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 518us/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "17\n",
      "One lap done.\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[2.3660190e-02, 5.5637043e-03, 4.1852985e-04, 9.2936903e-01,\n",
       "         3.1268750e-03, 3.7861764e-02],\n",
       "        [2.3671311e-01, 5.4181833e-02, 3.6915604e-02, 2.8920364e-01,\n",
       "         8.9196399e-02, 2.9378930e-01],\n",
       "        [1.4040254e-01, 6.4718679e-02, 4.7806956e-02, 3.4707069e-01,\n",
       "         1.5054277e-01, 2.4945830e-01],\n",
       "        ...,\n",
       "        [8.7650225e-02, 1.4170025e-01, 3.2211252e-02, 5.5129826e-01,\n",
       "         7.4304737e-02, 1.1283534e-01],\n",
       "        [1.4287345e-01, 2.7509522e-02, 5.7241987e-03, 6.0712254e-01,\n",
       "         2.5111847e-02, 1.9165839e-01],\n",
       "        [1.1115664e-02, 2.8401330e-01, 4.0129647e-01, 6.4057307e-03,\n",
       "         2.8449053e-01, 1.2678274e-02]], dtype=float32),\n",
       " 57018)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_mean_results=[]\n",
    "current_window = data_init.copy()\n",
    "delta=0.1\n",
    "adwin = ADWIN(delta)\n",
    "detected = False\n",
    "retraining_count=0\n",
    "data_window=data_init.copy()\n",
    "\n",
    "\n",
    "\n",
    "num_models=[]\n",
    "while stream.n_remaining_samples()>1:\n",
    "    \n",
    "    y_pred, y_pred_uncertainty = drift_detection(mean_model_weights, data_window.copy())\n",
    "        \n",
    "    incoming_data = stream.next_sample(two_percent)\n",
    "    \n",
    "    data_incoming = pd.DataFrame(incoming_data[0], columns=dataset.columns[:-1])\n",
    "    data_incoming[target_variable]=incoming_data[1]\n",
    "    true_values.append(data_incoming[target_variable])\n",
    "    \n",
    "    y_pred, y_pred_uncertainty = drift_detection(mean_model_weights, data_incoming.copy()) \n",
    "    \n",
    "    \n",
    "    y_pred_uncertainty_total.append(y_pred_uncertainty)\n",
    "    print(len(y_pred_uncertainty))\n",
    "    \n",
    "    detected=False\n",
    "    for i in range(len(data_incoming[target_variable])):\n",
    "        adwin.add_element(y_pred_uncertainty[i])\n",
    "        if adwin.detected_change():\n",
    "            detected = True\n",
    "            break;\n",
    "    \n",
    "    if detected:\n",
    "        print(\"drift has been detecte models must be retrained\")\n",
    "        \n",
    "        data_window = update_train_data(data_window, data_incoming)\n",
    "        \n",
    "        retraining_count+=1\n",
    "        \n",
    "        Models=[]\n",
    "        val_acc=[]\n",
    "        train_acc=[]\n",
    "        test_acc=[]\n",
    "        val_loss=[]\n",
    "        train_loss=[]\n",
    "        ind=0\n",
    "        add_weights=[]\n",
    "\n",
    "        ann_model=get_initial_model(dataset.shape[1]-1, 6) \n",
    "\n",
    "        X_train=data_init.drop(columns=[target_variable])\n",
    "        print(X_train.shape[1])\n",
    "\n",
    "        y_train=to_categorical(data_init[target_variable], num_classes = 6)\n",
    "\n",
    "        ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # metrics=['accuracy']\n",
    "        history = ann_model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "        #print(history.history['f1_m'][-1])\n",
    "\n",
    "\n",
    "        add_weights.append([ann_model.get_weights()])\n",
    "        Models.append([ann_model.get_weights(), 1])\n",
    "\n",
    "\n",
    "        print(len(Models))\n",
    "        #here use only top 5-10 integrally private models.\n",
    "        #add_weights=add_weights[top_5]\n",
    "        A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "        print(np.array(Models).T[1])\n",
    "        print(A)\n",
    "        recommended_models=[]\n",
    "        for i in range(len(A)):\n",
    "            recommended_models.append(add_weights[A[i]])\n",
    "\n",
    "\n",
    "        mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss = epsilon_mean_recommendation(recommended_models, data_init)\n",
    "\n",
    "        \n",
    "        A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "        \n",
    "        num_models.append(len(A))\n",
    "        recommended_models=[]\n",
    "        for i in range(len(A)):\n",
    "            recommended_models.append(add_weights[A[i]])\n",
    "            \n",
    "        mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss = epsilon_mean_recommendation(recommended_models, data_window)\n",
    "        y_pred, y_pred_uncertainty = drift_detection(mean_model_weights, data_incoming.copy())\n",
    "        y_pred_total.append(y_pred)\n",
    "        \n",
    "    else:\n",
    "        y_pred_total.append(y_pred)\n",
    "        print(\"One lap done.\")\n",
    "        continue\n",
    "    print(\"one thing\")\n",
    "print(retraining_count)\n",
    "\n",
    "predictions=[]\n",
    "for i in y_pred_total:\n",
    "    predictions.append(list(np.argmax(i,axis=1)))\n",
    "predictions = list(np.concatenate(predictions))\n",
    "y_pred_total[0], len(predictions)\n",
    "\n",
    "# this is for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c61586a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for i in y_pred_total:\n",
    "    predictions.append(list(np.argmax(i,axis=1)))\n",
    "predictions = list(np.concatenate(predictions))\n",
    "y_pred_total[0], len(predictions)\n",
    "\n",
    "true_values = list(np.concatenate(true_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe90049c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "0.23357536216633343\n",
      "0.08098444642589495\n",
      "16\n",
      "0.22483128374738415\n",
      "0.5577298773121807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, mean_squared_error, accuracy_score, mean_absolute_error, f1_score, matthews_corrcoef, mean_squared_error, mean_squared_log_error, roc_auc_score\n",
    "print(num_models)\n",
    "acc_score = accuracy_score(true_values, predictions)\n",
    "print(acc_score)\n",
    "mcc = matthews_corrcoef(true_values, predictions)\n",
    "print(mcc)\n",
    "f1_score = f1_score(true_values, predictions, average = 'weighted')\n",
    "y_pred_total_test = list(np.concatenate(y_pred_total))\n",
    "auc_score = roc_auc_score(true_values, y_pred_total_test, multi_class='ovo')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(retraining_count)\n",
    "print(f1_score)\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b4b5bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now trying for Differential privacy\n",
    "\n",
    "#now trying for Differentially private models\n",
    "\n",
    "#finding the parameters for DP, will experiment on epsilon = 0.1, 0.5, 1.0 and will run on adwin unlimited label availability\n",
    "#from here onwards the comparison and computation of DP:\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_privacy\n",
    "\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "l2_norm_clip = 1.0\n",
    "noise_multiplier = 0.339\n",
    "num_microbatches = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f528adb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 0.561% and noise_multiplier = 0.338 iterated over 1782 steps satisfies differential privacy with eps = 49.2 and delta = 1e-05.\n",
      "The optimal RDP order is 1.5.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.18264292409218"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_dp_sgd_privacy.compute_dp_sgd_privacy(n=5*two_percent,\n",
    "                                              batch_size=32,\n",
    "                                              noise_multiplier=0.338,\n",
    "                                              epochs=10,\n",
    "                                              delta=1e-5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a9b64e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now trying for DNN\n",
    "optimizer = tensorflow_privacy.DPKerasAdamOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5e10ebc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 0s 2ms/step - loss: 1.7711 - accuracy: 0.2772 - val_loss: 1.6919 - val_accuracy: 0.3734\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.4989 - accuracy: 0.4035 - val_loss: 1.2309 - val_accuracy: 0.4864\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 982us/step - loss: 1.2087 - accuracy: 0.4857 - val_loss: 1.0759 - val_accuracy: 0.5451\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.1253 - accuracy: 0.5039 - val_loss: 1.0400 - val_accuracy: 0.5355\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 981us/step - loss: 1.0873 - accuracy: 0.5116 - val_loss: 1.0176 - val_accuracy: 0.5574\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0674 - accuracy: 0.5215 - val_loss: 1.0032 - val_accuracy: 0.5451\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0550 - accuracy: 0.5235 - val_loss: 1.0010 - val_accuracy: 0.5539\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 972us/step - loss: 1.0442 - accuracy: 0.5305 - val_loss: 0.9896 - val_accuracy: 0.5530\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.0372 - accuracy: 0.5309 - val_loss: 0.9770 - val_accuracy: 0.5548\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 972us/step - loss: 1.0304 - accuracy: 0.5375 - val_loss: 0.9773 - val_accuracy: 0.5592\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "  1/125 [..............................] - ETA: 13s - loss: 0.9888 - accuracy: 0.5312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:56: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 613us/step - loss: 1.0075 - accuracy: 0.5469\n",
      "54/54 [==============================] - 0s 615us/step - loss: 1.0322 - accuracy: 0.5383\n",
      "179/179 [==============================] - 0s 485us/step\n"
     ]
    }
   ],
   "source": [
    "#Now for adwin limited\n",
    "#No training\n",
    "dataset = pd.read_csv(\"./artificial/insects/INSECTS-incremental_balanced_norm.csv\", sep=',')\n",
    "\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "#dataset = pd.DataFrame(scaler.fit_transform(dataset), columns=dataset.columns)\n",
    "#target_variable=\n",
    "#dataset[54] = dataset[54]-1\n",
    "#experiments for ADWIN unlimited\n",
    "\n",
    "#try with no retraining\n",
    "\n",
    "#Now lets see for No training\n",
    "\n",
    "from skmultiflow.data import DataStream\n",
    "stream = DataStream(dataset)\n",
    "\n",
    "two_percent = int(stream.n_remaining_samples()*0.02)\n",
    "five_percent = int(stream.n_remaining_samples()*0.05)\n",
    "initial_data = stream.next_sample(int(stream.n_remaining_samples()*0.10))\n",
    "\n",
    "data_init=pd.DataFrame(initial_data[0], columns=dataset.columns[:-1])\n",
    "data_init['Class']=initial_data[1]\n",
    "target_variable='Class'\n",
    "\n",
    "\n",
    "\n",
    "Models=[]\n",
    "val_acc=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "ind=0\n",
    "add_weights=[]\n",
    "\n",
    "ann_model=get_initial_model_2(dataset.shape[1]-1, 6) \n",
    "\n",
    "X_train=data_init.drop(columns=[target_variable])\n",
    "print(X_train.shape[1])\n",
    "\n",
    "y_train=to_categorical(data_init[target_variable], num_classes = 6)\n",
    "\n",
    "ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # metrics=['accuracy']\n",
    "history = ann_model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "#print(history.history['f1_m'][-1])\n",
    "\n",
    "\n",
    "add_weights.append([ann_model.get_weights()])\n",
    "Models.append([ann_model.get_weights(), 1])\n",
    "\n",
    "\n",
    "print(len(Models))\n",
    "#here use only top 5-10 integrally private models.\n",
    "#add_weights=add_weights[top_5]\n",
    "A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "print(np.array(Models).T[1])\n",
    "print(A)\n",
    "recommended_models=[]\n",
    "for i in range(len(A)):\n",
    "    recommended_models.append(add_weights[A[i]])\n",
    "\n",
    "    \n",
    "mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss = epsilon_mean_recommendation_2(recommended_models, data_init)\n",
    "\n",
    "y_pred_total=[]\n",
    "y_pred_uncertainty_total=[]\n",
    "true_values=[]\n",
    "\n",
    "y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_init.copy())\n",
    "\n",
    "y_pred_total.append(y_pred)\n",
    "y_pred_uncertainty_total.append(y_pred_uncertainty)\n",
    "\n",
    "true_values.append(data_init[target_variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2ca7fe89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 0s 489us/step\n",
      "36/36 [==============================] - 0s 533us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 492us/step\n",
      "36/36 [==============================] - 0s 553us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 508us/step\n",
      "36/36 [==============================] - 0s 577us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7924 - accuracy: 0.1643 - val_loss: 1.7928 - val_accuracy: 0.1665\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7921 - accuracy: 0.1680 - val_loss: 1.7922 - val_accuracy: 0.1656\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7914 - accuracy: 0.1664 - val_loss: 1.7917 - val_accuracy: 0.1656\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7915 - accuracy: 0.1671 - val_loss: 1.7917 - val_accuracy: 0.1656\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7916 - accuracy: 0.1671 - val_loss: 1.7916 - val_accuracy: 0.1656\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7915 - accuracy: 0.1669 - val_loss: 1.7920 - val_accuracy: 0.1648\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7917 - accuracy: 0.1689 - val_loss: 1.7914 - val_accuracy: 0.1560\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7914 - accuracy: 0.1680 - val_loss: 1.7913 - val_accuracy: 0.1656\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7912 - accuracy: 0.1671 - val_loss: 1.7912 - val_accuracy: 0.1656\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7916 - accuracy: 0.1671 - val_loss: 1.7916 - val_accuracy: 0.1656\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "  1/125 [..............................] - ETA: 13s - loss: 1.7996 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 654us/step - loss: 1.7917 - accuracy: 0.1647\n",
      "54/54 [==============================] - 0s 631us/step - loss: 1.7911 - accuracy: 0.1718\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "  1/125 [..............................] - ETA: 13s - loss: 1.7898 - accuracy: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 652us/step - loss: 1.7916 - accuracy: 0.1639\n",
      "54/54 [==============================] - 0s 608us/step - loss: 1.7918 - accuracy: 0.1736\n",
      "36/36 [==============================] - 0s 563us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 504us/step\n",
      "36/36 [==============================] - 0s 608us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7920 - accuracy: 0.1667 - val_loss: 1.7911 - val_accuracy: 0.1656\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7905 - accuracy: 0.1671 - val_loss: 1.7894 - val_accuracy: 0.1656\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7895 - accuracy: 0.1660 - val_loss: 1.7881 - val_accuracy: 0.1656\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7882 - accuracy: 0.1669 - val_loss: 1.7866 - val_accuracy: 0.1656\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7866 - accuracy: 0.1814 - val_loss: 1.7845 - val_accuracy: 0.2095\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7858 - accuracy: 0.1860 - val_loss: 1.7839 - val_accuracy: 0.1656\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7854 - accuracy: 0.1704 - val_loss: 1.7828 - val_accuracy: 0.1849\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7841 - accuracy: 0.1890 - val_loss: 1.7822 - val_accuracy: 0.1805\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7843 - accuracy: 0.1739 - val_loss: 1.7821 - val_accuracy: 0.1718\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7835 - accuracy: 0.1612 - val_loss: 1.7813 - val_accuracy: 0.1394\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "  1/125 [..............................] - ETA: 13s - loss: 1.7800 - accuracy: 0.1875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 636us/step - loss: 1.7828 - accuracy: 0.1416\n",
      "54/54 [==============================] - 0s 640us/step - loss: 1.7826 - accuracy: 0.1479\n",
      "yhn tk\n",
      "1\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 609us/step - loss: 1.7832 - accuracy: 0.1288\n",
      "54/54 [==============================] - 0s 608us/step - loss: 1.7844 - accuracy: 0.1268\n",
      "36/36 [==============================] - 0s 535us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 485us/step\n",
      "36/36 [==============================] - 0s 553us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7926 - accuracy: 0.1594 - val_loss: 1.7923 - val_accuracy: 0.1464\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7917 - accuracy: 0.1625 - val_loss: 1.7912 - val_accuracy: 0.1639\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7901 - accuracy: 0.1684 - val_loss: 1.7883 - val_accuracy: 0.1902\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7891 - accuracy: 0.2075 - val_loss: 1.7879 - val_accuracy: 0.2217\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7882 - accuracy: 0.2318 - val_loss: 1.7865 - val_accuracy: 0.2375\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7876 - accuracy: 0.2467 - val_loss: 1.7863 - val_accuracy: 0.2717\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7871 - accuracy: 0.1974 - val_loss: 1.7860 - val_accuracy: 0.2752\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7865 - accuracy: 0.2502 - val_loss: 1.7849 - val_accuracy: 0.2805\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7853 - accuracy: 0.2353 - val_loss: 1.7837 - val_accuracy: 0.1797\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7841 - accuracy: 0.1963 - val_loss: 1.7828 - val_accuracy: 0.2296\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "  1/125 [..............................] - ETA: 12s - loss: 1.7620 - accuracy: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 621us/step - loss: 1.7837 - accuracy: 0.2263\n",
      "54/54 [==============================] - 0s 599us/step - loss: 1.7841 - accuracy: 0.2274\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "  1/125 [..............................] - ETA: 13s - loss: 1.7859 - accuracy: 0.1875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 625us/step - loss: 1.7826 - accuracy: 0.2233\n",
      "54/54 [==============================] - 0s 594us/step - loss: 1.7818 - accuracy: 0.2215\n",
      "36/36 [==============================] - 0s 543us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 485us/step\n",
      "36/36 [==============================] - 0s 531us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7936 - accuracy: 0.1682 - val_loss: 1.7919 - val_accuracy: 0.1665\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7912 - accuracy: 0.1487 - val_loss: 1.7903 - val_accuracy: 0.1665\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7919 - accuracy: 0.1667 - val_loss: 1.7911 - val_accuracy: 0.1665\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7920 - accuracy: 0.1669 - val_loss: 1.7917 - val_accuracy: 0.1665\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7917 - accuracy: 0.1634 - val_loss: 1.7918 - val_accuracy: 0.1648\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7916 - accuracy: 0.1693 - val_loss: 1.7914 - val_accuracy: 0.1735\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7916 - accuracy: 0.1899 - val_loss: 1.7911 - val_accuracy: 0.1902\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7914 - accuracy: 0.1697 - val_loss: 1.7908 - val_accuracy: 0.1665\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7904 - accuracy: 0.1667 - val_loss: 1.7903 - val_accuracy: 0.1656\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7904 - accuracy: 0.1654 - val_loss: 1.7907 - val_accuracy: 0.1621\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "  1/125 [..............................] - ETA: 12s - loss: 1.7933 - accuracy: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 612us/step - loss: 1.7903 - accuracy: 0.1699\n",
      "54/54 [==============================] - 0s 579us/step - loss: 1.7919 - accuracy: 0.1537\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "  1/125 [..............................] - ETA: 13s - loss: 1.7942 - accuracy: 0.1562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 622us/step - loss: 1.7897 - accuracy: 0.1586\n",
      "54/54 [==============================] - 0s 599us/step - loss: 1.7895 - accuracy: 0.1578\n",
      "36/36 [==============================] - 0s 548us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 480us/step\n",
      "36/36 [==============================] - 0s 571us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7912 - accuracy: 0.1899 - val_loss: 1.7905 - val_accuracy: 0.1665\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7896 - accuracy: 0.1853 - val_loss: 1.7886 - val_accuracy: 0.1665\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7886 - accuracy: 0.1695 - val_loss: 1.7863 - val_accuracy: 0.2156\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7857 - accuracy: 0.1941 - val_loss: 1.7825 - val_accuracy: 0.1893\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7830 - accuracy: 0.2077 - val_loss: 1.7811 - val_accuracy: 0.2174\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7821 - accuracy: 0.1888 - val_loss: 1.7795 - val_accuracy: 0.1727\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7803 - accuracy: 0.1879 - val_loss: 1.7769 - val_accuracy: 0.1858\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7778 - accuracy: 0.2118 - val_loss: 1.7742 - val_accuracy: 0.2734\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7774 - accuracy: 0.2513 - val_loss: 1.7731 - val_accuracy: 0.2182\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7749 - accuracy: 0.2362 - val_loss: 1.7717 - val_accuracy: 0.2901\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "  1/125 [..............................] - ETA: 13s - loss: 1.7853 - accuracy: 0.1875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 645us/step - loss: 1.7743 - accuracy: 0.2762\n",
      "54/54 [==============================] - 0s 596us/step - loss: 1.7730 - accuracy: 0.2735\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "  1/125 [..............................] - ETA: 13s - loss: 1.7719 - accuracy: 0.2812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 634us/step - loss: 1.7790 - accuracy: 0.2233\n",
      "54/54 [==============================] - 0s 589us/step - loss: 1.7790 - accuracy: 0.2221\n",
      "36/36 [==============================] - 0s 560us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 482us/step\n",
      "36/36 [==============================] - 0s 531us/step\n",
      "1140\n",
      "drift has been detecte models must be retrained\n",
      "33\n",
      "Epoch 1/10\n",
      "143/143 [==============================] - 1s 2ms/step - loss: 1.7903 - accuracy: 0.1831 - val_loss: 1.7883 - val_accuracy: 0.2226\n",
      "Epoch 2/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7865 - accuracy: 0.1857 - val_loss: 1.7832 - val_accuracy: 0.1621\n",
      "Epoch 3/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7830 - accuracy: 0.1882 - val_loss: 1.7811 - val_accuracy: 0.2997\n",
      "Epoch 4/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7807 - accuracy: 0.2072 - val_loss: 1.7785 - val_accuracy: 0.1665\n",
      "Epoch 5/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7777 - accuracy: 0.1879 - val_loss: 1.7751 - val_accuracy: 0.1569\n",
      "Epoch 6/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7748 - accuracy: 0.1500 - val_loss: 1.7715 - val_accuracy: 0.1621\n",
      "Epoch 7/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7724 - accuracy: 0.1873 - val_loss: 1.7689 - val_accuracy: 0.3129\n",
      "Epoch 8/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7713 - accuracy: 0.2561 - val_loss: 1.7657 - val_accuracy: 0.2691\n",
      "Epoch 9/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7680 - accuracy: 0.2182 - val_loss: 1.7637 - val_accuracy: 0.1963\n",
      "Epoch 10/10\n",
      "143/143 [==============================] - 0s 1ms/step - loss: 1.7656 - accuracy: 0.1873 - val_loss: 1.7598 - val_accuracy: 0.1867\n",
      "1\n",
      "[1]\n",
      "[0]\n",
      "yhn tk\n",
      "1\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:70: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:71: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 606us/step - loss: 1.7621 - accuracy: 0.1797\n",
      "54/54 [==============================] - 0s 607us/step - loss: 1.7644 - accuracy: 0.1818\n",
      "yhn tk\n",
      "1\n",
      "Done\n",
      "  1/125 [..............................] - ETA: 13s - loss: 1.7497 - accuracy: 0.1562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayushkv/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:81: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 656us/step - loss: 1.7615 - accuracy: 0.1649\n",
      "54/54 [==============================] - 0s 614us/step - loss: 1.7615 - accuracy: 0.1648\n",
      "36/36 [==============================] - 0s 557us/step\n",
      "one thing\n",
      "179/179 [==============================] - 0s 527us/step\n",
      "36/36 [==============================] - 0s 644us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 526us/step\n",
      "36/36 [==============================] - 0s 657us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 488us/step\n",
      "36/36 [==============================] - 0s 535us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 492us/step\n",
      "36/36 [==============================] - 0s 514us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 481us/step\n",
      "36/36 [==============================] - 0s 573us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 498us/step\n",
      "36/36 [==============================] - 0s 562us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 481us/step\n",
      "36/36 [==============================] - 0s 546us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 474us/step\n",
      "36/36 [==============================] - 0s 518us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 485us/step\n",
      "36/36 [==============================] - 0s 520us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 493us/step\n",
      "36/36 [==============================] - 0s 556us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 494us/step\n",
      "36/36 [==============================] - 0s 565us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 498us/step\n",
      "36/36 [==============================] - 0s 574us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 507us/step\n",
      "36/36 [==============================] - 0s 554us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 479us/step\n",
      "36/36 [==============================] - 0s 600us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 535us/step\n",
      "36/36 [==============================] - 0s 661us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 498us/step\n",
      "36/36 [==============================] - 0s 556us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 471us/step\n",
      "36/36 [==============================] - 0s 535us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 549us/step\n",
      "36/36 [==============================] - 0s 635us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 532us/step\n",
      "36/36 [==============================] - 0s 570us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 486us/step\n",
      "36/36 [==============================] - 0s 547us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 473us/step\n",
      "36/36 [==============================] - 0s 517us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 474us/step\n",
      "36/36 [==============================] - 0s 551us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 467us/step\n",
      "36/36 [==============================] - 0s 491us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 465us/step\n",
      "36/36 [==============================] - 0s 505us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 465us/step\n",
      "36/36 [==============================] - 0s 514us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 461us/step\n",
      "36/36 [==============================] - 0s 512us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 477us/step\n",
      "36/36 [==============================] - 0s 518us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 501us/step\n",
      "36/36 [==============================] - 0s 625us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 492us/step\n",
      "36/36 [==============================] - 0s 600us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 446us/step\n",
      "36/36 [==============================] - 0s 505us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 469us/step\n",
      "36/36 [==============================] - 0s 523us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 463us/step\n",
      "36/36 [==============================] - 0s 594us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 479us/step\n",
      "36/36 [==============================] - 0s 511us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 466us/step\n",
      "36/36 [==============================] - 0s 505us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 479us/step\n",
      "36/36 [==============================] - 0s 520us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 462us/step\n",
      "36/36 [==============================] - 0s 552us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 459us/step\n",
      "36/36 [==============================] - 0s 516us/step\n",
      "1140\n",
      "One lap done.\n",
      "179/179 [==============================] - 0s 466us/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "17\n",
      "One lap done.\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "stream_mean_results=[]\n",
    "current_window = data_init.copy()\n",
    "delta=0.1\n",
    "adwin = ADWIN(delta)\n",
    "detected = False\n",
    "retraining_count=0\n",
    "data_window=data_init.copy()\n",
    "\n",
    "\n",
    "\n",
    "num_models=[]\n",
    "while stream.n_remaining_samples()>1:\n",
    "    \n",
    "    y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_window.copy())\n",
    "        \n",
    "    incoming_data = stream.next_sample(two_percent)\n",
    "    \n",
    "    data_incoming = pd.DataFrame(incoming_data[0], columns=dataset.columns[:-1])\n",
    "    data_incoming[target_variable]=incoming_data[1]\n",
    "    true_values.append(data_incoming[target_variable])\n",
    "    \n",
    "    y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_incoming.copy()) \n",
    "    \n",
    "    \n",
    "    y_pred_uncertainty_total.append(y_pred_uncertainty)\n",
    "    print(len(y_pred_uncertainty))\n",
    "    \n",
    "    detected=False\n",
    "    for i in range(len(data_incoming[target_variable])):\n",
    "        adwin.add_element(y_pred_uncertainty[i])\n",
    "        if adwin.detected_change():\n",
    "            detected = True\n",
    "            break;\n",
    "    \n",
    "    if detected:\n",
    "        print(\"drift has been detecte models must be retrained\")\n",
    "        \n",
    "        data_window = update_train_data(data_window, data_incoming)\n",
    "        \n",
    "        retraining_count+=1\n",
    "        \n",
    "        Models=[]\n",
    "        val_acc=[]\n",
    "        train_acc=[]\n",
    "        test_acc=[]\n",
    "        val_loss=[]\n",
    "        train_loss=[]\n",
    "        ind=0\n",
    "        add_weights=[]\n",
    "\n",
    "        ann_model=get_initial_model_2(dataset.shape[1]-1, 6) \n",
    "\n",
    "        X_train=data_init.drop(columns=[target_variable])\n",
    "        print(X_train.shape[1])\n",
    "\n",
    "        y_train=to_categorical(data_init[target_variable], num_classes = 6)\n",
    "\n",
    "        ann_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) # metrics=['accuracy']\n",
    "        history = ann_model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "        #print(history.history['f1_m'][-1])\n",
    "\n",
    "\n",
    "        add_weights.append([ann_model.get_weights()])\n",
    "        Models.append([ann_model.get_weights(), 1])\n",
    "\n",
    "\n",
    "        print(len(Models))\n",
    "        #here use only top 5-10 integrally private models.\n",
    "        #add_weights=add_weights[top_5]\n",
    "        A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "        print(np.array(Models).T[1])\n",
    "        print(A)\n",
    "        recommended_models=[]\n",
    "        for i in range(len(A)):\n",
    "            recommended_models.append(add_weights[A[i]])\n",
    "\n",
    "\n",
    "        mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss = epsilon_mean_recommendation_2(recommended_models, data_init)\n",
    "\n",
    "        \n",
    "        A=np.argsort(np.array(Models).T[1])[::-1][:5]\n",
    "        \n",
    "        num_models.append(len(A))\n",
    "        recommended_models=[]\n",
    "        for i in range(len(A)):\n",
    "            recommended_models.append(add_weights[A[i]])\n",
    "            \n",
    "        mean_model_weights, mean_model_acc, mean_model_loss, mean_model_test_acc, mean_model_test_loss = epsilon_mean_recommendation_2(recommended_models, data_window)\n",
    "        y_pred, y_pred_uncertainty = drift_detection_2(mean_model_weights, data_incoming.copy())\n",
    "        y_pred_total.append(y_pred)\n",
    "        \n",
    "    else:\n",
    "        y_pred_total.append(y_pred)\n",
    "        print(\"One lap done.\")\n",
    "        continue\n",
    "    print(\"one thing\")\n",
    "print(retraining_count)\n",
    "\n",
    "predictions=[]\n",
    "for i in y_pred_total:\n",
    "    predictions.append(list(np.argmax(i,axis=1)))\n",
    "predictions = list(np.concatenate(predictions))\n",
    "y_pred_total[0], len(predictions)\n",
    "\n",
    "# this is for classification\n",
    "true_values = list(np.concatenate(true_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "16fc2667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1]\n",
      "0.22224560665053142\n",
      "0.07429416240382639\n",
      "6\n",
      "0.2006314627319769\n",
      "0.693199885514977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, mean_squared_error, accuracy_score, mean_absolute_error, f1_score, matthews_corrcoef, mean_squared_error, mean_squared_log_error, roc_auc_score\n",
    "print(num_models)\n",
    "acc_score = accuracy_score(true_values, predictions)\n",
    "print(acc_score)\n",
    "mcc = matthews_corrcoef(true_values, predictions)\n",
    "print(mcc)\n",
    "f1_score = f1_score(true_values, predictions, average = 'weighted')\n",
    "y_pred_total_test = list(np.concatenate(y_pred_total))\n",
    "auc_score = roc_auc_score(true_values, y_pred_total_test, multi_class='ovo')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(retraining_count)\n",
    "print(f1_score)\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cbab8a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#here onwards plotting the acc_score for epsilon values and ip models acc_score has been calculate for say epsilon 3 ≈(noise_multiplier 0.65 in compute_sgd)\n",
    "#plt.yticks([0.70, 0.75, 0.80, 0.90,0.95],[\"0.70\",\"0.75\",\"0.80\",\"0.85\",\"0.90\"])\n",
    "epsilon_list = ['0.1', '0.5', '1', '3', '5', '15', '50']\n",
    "\n",
    "plt.ylim([0.15,0.28])\n",
    "\n",
    "plt.xticks([0,1,2,3,4,5,6], epsilon_list)\n",
    "\n",
    "acc_DP = [ 0.2089, 0.2265, 0.2143, 0.2120, 0.2131, 0.2147, 0.2222]\n",
    "ipdd_acc=[0.2101]*len(acc_DP)\n",
    "plt.plot(ipdd_acc, 'r--', label = \"IP\" )\n",
    "plt.plot(acc_DP, label=\"DP\")\n",
    "plt.xlabel(\"epsilon in DP\")\n",
    "plt.legend()\n",
    "plt.savefig(\"Insect_incremental DPvsOnlineIP.pdf\",dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86d7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
